<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>Master the Art of Caching for System Design Interviews: A Complete Guide</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Master the Art of Caching for System Design Interviews: A Complete Guide"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://luke-snaw.github.io//notes/6hmmfse40un0yvyhcfhf1kh/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/14/2023"/><meta property="article:modified_time" content="3/14/2023"/><link rel="canonical" href="https://luke-snaw.github.io//notes/6hmmfse40un0yvyhcfhf1kh/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9d8e0603730b15a3.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/vOE8u-mg___OsOsz4tjEg/_buildManifest.js" defer=""></script><script src="/_next/static/vOE8u-mg___OsOsz4tjEg/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="master-the-art-of-caching-for-system-design-interviews-a-complete-guide">Master the Art of Caching for System Design Interviews: A Complete Guide<a aria-hidden="true" class="anchor-heading icon-link" href="#master-the-art-of-caching-for-system-design-interviews-a-complete-guide"></a></h1>
<blockquote>
<p><a href="https://levelup.gitconnected.com/master-the-art-of-caching-for-system-design-interviews-a-complete-guide-676bb49d194">https://levelup.gitconnected.com/master-the-art-of-caching-for-system-design-interviews-a-complete-guide-676bb49d194</a></p>
</blockquote>
<p>A Comprehensive Caching Guide for Acing System Design Interviews.</p>
<p><img src="/./assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__what-are-where-to-cache.webp"></p>
<p><a href="https://www.designgurus.io/course-play/grokking-the-system-design-interview/doc/638c0b7aac93e7ae59a1b0bd">What are Where to Cache?</a></p>
<p>Caching is an essential technique used in software engineering to improve system performance and user experience. It works by temporarily storing frequently accessed data in a cache, which is faster to access than the original source of the data.</p>
<p>As a software engineer, it’s essential to have a solid understanding of caching and how it works in different types of systems. In this blog, we’ll cover everything you need to know about caching, from its definition and importance to the different types of caching and best practices for implementation.</p>
<p>Whether you’re preparing for a <a href="https://medium.com/gitconnected/system-design-interview-survival-guide-2023-preparation-strategies-and-practical-tips-ba9314e6b9e3">system design interview</a> or looking to optimize your own software system, this guide will provide you with the knowledge and tools you need to succeed.</p>
<blockquote>
<p>Check <a href="https://www.designgurus.io/course/grokking-the-system-design-interview">Grokking the System Design Interview</a> for a list of common system design interview questions and basics concepts.</p>
</blockquote>
<h3 id="a-little-about-me">A little about me<a aria-hidden="true" class="anchor-heading icon-link" href="#a-little-about-me"></a></h3>
<p>As the co-founder of <a href="https://www.designgurus.io/">Design Gurus</a> and the author of the <a href="https://designgurus.io/courses">Grokking</a> series on coding and system design interviews, I have over 20 years of experience in software engineering. Over the course of my career, I have been on both sides of the interview table, having given over 30 interview loops and personally sitting through over 500+ coding and system design interviews.</p>
<p>In this guide, I want to share some of the most valuable lessons I’ve learned about caching and how can you use these to crack any system design interviews.</p>
<p>Let’s start with understanding what caching is and why we need it.</p>
<h2 id="i-what-is-caching">I. What is Caching?<a aria-hidden="true" class="anchor-heading icon-link" href="#i-what-is-caching"></a></h2>
<p>The cache is a high-speed storage layer that sits between the application and the original source of the data, such as a database, a file system, or a remote web service. When data is requested by the application, it is first checked in the cache. If the data is found in the cache, it is returned to the application. If the data is not found in the cache, it is retrieved from its original source, stored in the cache for future use, and returned to the application.</p>
<p>Caching can be used for various types of data, such as web pages, database queries, API responses, images, and videos. The goal of caching is to reduce the number of times data needs to be fetched from its original source, which can result in faster processing and reduced latency.</p>
<p>Caching can be implemented in various ways, including in-memory caching, disk caching, database caching, and CDN caching. In-memory caching stores data in the main memory of the computer, which is faster to access than disk storage. Disk caching stores data on the hard disk, which is slower than main memory but faster than retrieving data from a remote source. Database caching stores frequently accessed data in the database itself, reducing the need to access external storage. CDN caching stores data on a distributed network of servers, reducing the latency of accessing data from remote locations.</p>
<h2 id="ii-why-is-caching-important">II. Why is Caching Important?<a aria-hidden="true" class="anchor-heading icon-link" href="#ii-why-is-caching-important"></a></h2>
<p>Caching plays a critical role in improving system performance and user experience in software engineering. By storing frequently accessed data in a cache, applications can reduce the response time and latency of operations, resulting in faster and more efficient processing. Here are some reasons why caching is important:</p>
<ol>
<li><strong>Improved system performance</strong>: Caching can significantly improve the performance of an application by reducing the number of times data needs to be fetched from its original source. Since cached data can be retrieved faster than from the original source, this results in a significant reduction in processing time, which leads to a more responsive application.</li>
<li><strong>Reduced network load</strong>: Caching can also reduce network load by minimizing the amount of data that needs to be transmitted over the network. Since cached data is stored locally, there is no need to fetch data from the original source, reducing the amount of data that needs to be transferred over the network.</li>
<li><strong>Increased scalability</strong>: Caching can improve the scalability of an application by reducing the load on the original source. By storing frequently accessed data in a cache, the original source is less likely to be overwhelmed with requests, making it more scalable.</li>
<li><strong>Better user experience</strong>: Faster response times and reduced latency can lead to a better user experience. Applications that load quickly and respond to user requests in a timely manner are more likely to be used and preferred by users.</li>
</ol>
<h2 id="iii-types-of-caching">III. Types of Caching<a aria-hidden="true" class="anchor-heading icon-link" href="#iii-types-of-caching"></a></h2>
<p>Caching can be implemented in various ways, depending on the specific use case and the type of data being cached. Here are some of the most common types of caching:</p>
<ol>
<li><strong>In-memory caching</strong>: In-memory caching stores data in the main memory of the computer, which is faster to access than disk storage. In-memory caching is useful for frequently accessed data that can fit into the available memory. This type of caching is commonly used for caching API responses, session data, and web page fragments. To implement in-memory caching, software engineers can use various techniques, including using a cache library like Memcached or Redis, or implementing custom caching logic within the application code.</li>
<li><strong>Disk caching</strong>: Disk caching stores data on the hard disk, which is slower than main memory but faster than retrieving data from a remote source. Disk caching is useful for data that is too large to fit in memory or for data that needs to persist between application restarts. This type of caching is commonly used for caching database queries and file system data.</li>
<li><strong>Database caching</strong>: Database caching stores frequently accessed data in the database itself, reducing the need to access external storage. This type of caching is useful for data that is stored in a database and frequently accessed by multiple users. Database caching can be implemented using a variety of techniques, including database query caching and result set caching.</li>
<li><strong>CDN caching</strong>: CDN caching stores data on a distributed network of servers, reducing the latency of accessing data from remote locations. This type of caching is useful for data that is accessed from multiple locations around the world, such as images, videos, and other static assets. CDN caching is commonly used for content delivery networks and large-scale web applications.</li>
<li><strong>DNS caching</strong>: DNS cache is a type of cache used in the Domain Name System (DNS) to store the results of DNS queries for a period of time. When a user requests to access a website, their computer sends a DNS query to a DNS server to resolve the website’s domain name to an IP address. The DNS server responds with the IP address, and the user’s computer can then access the website using the IP address. DNS caching improves the performance of the DNS system by reducing the number of requests made to DNS servers. When a DNS server receives a request for a domain name, it checks its local cache to see if it has the IP address for that domain name. If the IP address is in the cache, the DNS server can immediately respond with the IP address without having to query other servers. This can significantly reduce the response time for DNS queries and improve the overall performance of the system.</li>
</ol>
<p><img src="/assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__types-of-caching.webp">)</p>
<h2 id="iv-cache-replacement-policies">IV. Cache Replacement Policies<a aria-hidden="true" class="anchor-heading icon-link" href="#iv-cache-replacement-policies"></a></h2>
<p>When implementing caching, it’s important to have a cache replacement policy to determine which items in the cache should be removed when the cache becomes full. Here are some of the most common cache replacement policies:</p>
<ul>
<li><strong>Least Recently Used (LRU):</strong> LRU is a cache replacement policy that removes the least recently used item from the cache when it becomes full. This policy assumes that items that have been accessed more recently are more likely to be accessed again in the future.</li>
<li><strong>Least Frequently Used (LFU):</strong> LFU is a cache replacement policy that removes the least frequently used item from the cache when it becomes full. This policy assumes that items that have been accessed more frequently are more likely to be accessed again in the future.</li>
<li><strong>First In, First Out (FIFO):</strong> FIFO is a cache replacement policy that removes the oldest item from the cache when it becomes full. This policy assumes that the oldest items in the cache are the least likely to be accessed again in the future.</li>
<li><strong>Random Replacement:</strong> Random replacement is a cache replacement policy that removes a random item from the cache when it becomes full. This policy doesn’t make any assumptions about the likelihood of future access and can be useful when the access pattern is unpredictable.</li>
</ul>
<h3 id="comparison-of-different-replacement-policies">Comparison of different replacement policies<a aria-hidden="true" class="anchor-heading icon-link" href="#comparison-of-different-replacement-policies"></a></h3>
<p>Each cache replacement policy has its advantages and disadvantages, and the best policy to use depends on the specific use case. LRU and LFU are generally more effective than FIFO and random replacement since they take into account the access pattern of the cache. However, LRU and LFU can be more expensive to implement since they require maintaining additional data structures to track access patterns. FIFO and random replacement are simpler to implement but may not be as effective in optimizing cache performance. Overall, the cache replacement policy used should be chosen carefully to balance the trade-off between performance and complexity.</p>
<h2 id="v-cache-invalidation-strategies">V. Cache Invalidation Strategies<a aria-hidden="true" class="anchor-heading icon-link" href="#v-cache-invalidation-strategies"></a></h2>
<p>Cache invalidation is the process of removing data from the cache when it is no longer valid. Invalidating the cache is essential to ensure that the data stored in the cache is accurate and up-to-date. Here are some of the most common cache invalidation strategies:</p>
<ul>
<li><strong>Write-through cache:</strong> Under this scheme, data is written into the cache and the corresponding database simultaneously. The cached data allows for fast retrieval and, since the same data gets written in the permanent storage, we will have complete data consistency between the cache and the storage. Also, this scheme ensures that nothing will get lost in case of a crash, power failure, or other system disruptions. Although, write-through minimizes the risk of data loss, since every write operation must be done twice before returning success to the client, this scheme has the disadvantage of higher latency for write operations.</li>
<li><strong>Write-around cache:</strong> This technique is similar to write-through cache, but data is written directly to permanent storage, bypassing the cache. This can reduce the cache being flooded with write operations that will not subsequently be re-read, but has the disadvantage that a read request for recently written data will create a “cache miss” and must be read from slower back-end storage and experience higher latency.</li>
<li><strong>Write-back cache:</strong> Under this scheme, data is written to cache alone, and completion is immediately confirmed to the client. The write to the permanent storage is done based on certain conditions, for example, when the system needs some free space. This results in low-latency and high-throughput for write-intensive applications; however, this speed comes with the risk of data loss in case of a crash or other adverse event because the only copy of the written data is in the cache.</li>
<li><strong>Write-behind cache:</strong> It is quite similar to write-back cache. In this scheme, data is written to the cache and acknowledged to the application immediately, but it is not immediately written to the permanent storage. Instead, the write operation is deferred, and the data is eventually written to the permanent storage at a later time. The main difference between write-back cache and write-behind cache is when the data is written to the permanent storage. In write-back caching, data is only written to the permanent storage when it is necessary for the cache to free up space, while in write-behind caching, data is written to the permanent storage at specified intervals.</li>
</ul>
<p>Overall, the cache invalidation strategy used should be chosen carefully to balance the trade-off between performance and data accuracy. By understanding the different cache invalidation strategies available, software engineers can select the appropriate strategy to optimize cache performance and reduce latency while ensuring that the data stored in the cache is accurate and up-to-date.</p>
<h2 id="vi-cache-invalidations-methods">VI. Cache Invalidations Methods<a aria-hidden="true" class="anchor-heading icon-link" href="#vi-cache-invalidations-methods"></a></h2>
<p>Here are the famous cache invalidation methods:</p>
<ul>
<li><strong>Purge</strong>: The purge method removes cached content for a specific object, URL, or a set of URLs. It’s typically used when there is an update or change to the content and the cached version is no longer valid. When a purge request is received, the cached content is immediately removed, and the next request for the content will be served directly from the origin server.</li>
<li><strong>Refresh</strong>: Fetches requested content from the origin server, even if cached content is available. When a refresh request is received, the cached content is updated with the latest version from the origin server, ensuring that the content is up-to-date. Unlike a purge, a refresh request doesn’t remove the existing cached content; instead, it updates it with the latest version.</li>
<li><strong>Ban</strong>: The ban method invalidates cached content based on specific criteria, such as a URL pattern or header. When a ban request is received, any cached content that matches the specified criteria is immediately removed, and subsequent requests for the content will be served directly from the origin server.</li>
<li><strong>Time-to-live (TTL) expiration</strong>: This method involves setting a time-to-live value for cached content, after which the content is considered stale and must be refreshed. When a request is received for the content, the cache checks the time-to-live value and serves the cached content only if the value hasn’t expired. If the value has expired, the cache fetches the latest version of the content from the origin server and caches it.</li>
<li><strong>Stale-while-revalidate</strong>: This method is used in web browsers and CDNs to serve stale content from the cache while the content is being updated in the background. When a request is received for a piece of content, the cached version is immediately served to the user, and an asynchronous request is made to the origin server to fetch the latest version of the content. Once the latest version is available, the cached version is updated. This method ensures that the user is always served content quickly, even if the cached version is slightly outdated.</li>
</ul>
<p><img src="/./assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__cache-invalidations-methods.webp"></p>
<h2 id="vii-cache-performance-metrics">VII. Cache Performance Metrics<a aria-hidden="true" class="anchor-heading icon-link" href="#vii-cache-performance-metrics"></a></h2>
<p>When implementing caching, it’s important to measure the performance of the cache to ensure that it is effective in reducing latency and improving system performance. Here are some of the most common cache performance metrics:</p>
<ul>
<li><strong>Hit rate:</strong> The hit rate is the percentage of requests that are served by the cache without accessing the original source. A high hit rate indicates that the cache is effective in reducing the number of requests to the original source, while a low hit rate indicates that the cache may not be providing significant performance benefits.</li>
<li><strong>Miss rate:</strong> The miss rate is the percentage of requests that are not served by the cache and need to be fetched from the original source. A high miss rate indicates that the cache may not be caching the right data or that the cache size may not be large enough to store all frequently accessed data.</li>
<li><strong>Cache size:</strong> The cache size is the amount of memory or storage allocated for the cache. The cache size can impact the hit rate and miss rate of the cache. A larger cache size can result in a higher hit rate, but it may also increase the cost and complexity of the caching solution.</li>
<li><strong>Cache latency:</strong> The cache latency is the time it takes to access data from the cache. A lower cache latency indicates that the cache is faster and more effective in reducing latency and improving system performance. The cache latency can be impacted by the caching technology used, the cache size, and the cache replacement and invalidation policies.</li>
</ul>
<h2 id="viii-conclusion">VIII. Conclusion<a aria-hidden="true" class="anchor-heading icon-link" href="#viii-conclusion"></a></h2>
<h3 id="key-take-ways">Key take-ways<a aria-hidden="true" class="anchor-heading icon-link" href="#key-take-ways"></a></h3>
<p>Caching is an essential tool for optimizing system performance and reducing latency in software engineering. By storing frequently accessed data in a cache, the number of requests to the original source can be reduced, resulting in faster response times and improved scalability. Caching is used in a variety of software applications, from web applications to databases to content delivery networks.</p>
<h3 id="future-of-caching-in-distributed-systems">Future of caching in distributed systems<a aria-hidden="true" class="anchor-heading icon-link" href="#future-of-caching-in-distributed-systems"></a></h3>
<p>As distributed systems become more prevalent in software engineering, caching will continue to play a critical role in optimizing system performance. Distributed caching solutions like Redis and Memcached are becoming increasingly popular, allowing data to be cached across multiple servers and data centers. As the use of machine learning and artificial intelligence continues to grow, caching will also be used to optimize the performance of these applications by reducing the time it takes to retrieve and process data.</p>
<p>Take a look at <a href="https://www.designgurus.io/course/grokking-the-system-design-interview"><strong>Grokking the System Design Interview</strong></a> for system design interview questions. To learn software architecture and practice advanced system design interview questions take a look at <a href="https://www.designgurus.io/course/grokking-the-advanced-system-design-interview"><strong>Grokking the Advanced System Design Interview</strong></a>.</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#a-little-about-me" title="A little about me">A little about me</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#i-what-is-caching" title="I. What is Caching?">I. What is Caching?</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ii-why-is-caching-important" title="II. Why is Caching Important?">II. Why is Caching Important?</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iii-types-of-caching" title="III. Types of Caching">III. Types of Caching</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iv-cache-replacement-policies" title="IV. Cache Replacement Policies">IV. Cache Replacement Policies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#comparison-of-different-replacement-policies" title="Comparison of different replacement policies">Comparison of different replacement policies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#v-cache-invalidation-strategies" title="V. Cache Invalidation Strategies">V. Cache Invalidation Strategies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vi-cache-invalidations-methods" title="VI. Cache Invalidations Methods">VI. Cache Invalidations Methods</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vii-cache-performance-metrics" title="VII. Cache Performance Metrics">VII. Cache Performance Metrics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#viii-conclusion" title="VIII. Conclusion">VIII. Conclusion</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#key-take-ways" title="Key take-ways">Key take-ways</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#future-of-caching-in-distributed-systems" title="Future of caching in distributed systems">Future of caching in distributed systems</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"6hmmfse40un0yvyhcfhf1kh","title":"Master the Art of Caching for System Design Interviews: A Complete Guide","desc":"","updated":1678836954537,"created":1678836575925,"custom":{},"fname":"dev.software-engineering.master-the-art-of-caching-for-system-design-interviews-a-complete-guide","type":"note","vault":{"fsPath":"vault"},"contentHash":"f4e1344f8dbb1da0826f6dad3ec4416f","links":[],"anchors":{"a-little-about-me":{"type":"header","text":"A little about me","value":"a-little-about-me","line":24,"column":0,"depth":3},"i-what-is-caching":{"type":"header","text":"I. What is Caching?","value":"i-what-is-caching","line":32,"column":0,"depth":2},"ii-why-is-caching-important":{"type":"header","text":"II. Why is Caching Important?","value":"ii-why-is-caching-important","line":40,"column":0,"depth":2},"iii-types-of-caching":{"type":"header","text":"III. Types of Caching","value":"iii-types-of-caching","line":49,"column":0,"depth":2},"iv-cache-replacement-policies":{"type":"header","text":"IV. Cache Replacement Policies","value":"iv-cache-replacement-policies","line":61,"column":0,"depth":2},"comparison-of-different-replacement-policies":{"type":"header","text":"Comparison of different replacement policies","value":"comparison-of-different-replacement-policies","line":70,"column":0,"depth":3},"v-cache-invalidation-strategies":{"type":"header","text":"V. Cache Invalidation Strategies","value":"v-cache-invalidation-strategies","line":74,"column":0,"depth":2},"vi-cache-invalidations-methods":{"type":"header","text":"VI. Cache Invalidations Methods","value":"vi-cache-invalidations-methods","line":85,"column":0,"depth":2},"vii-cache-performance-metrics":{"type":"header","text":"VII. Cache Performance Metrics","value":"vii-cache-performance-metrics","line":97,"column":0,"depth":2},"viii-conclusion":{"type":"header","text":"VIII. Conclusion","value":"viii-conclusion","line":106,"column":0,"depth":2},"key-take-ways":{"type":"header","text":"Key take-ways","value":"key-take-ways","line":108,"column":0,"depth":3},"future-of-caching-in-distributed-systems":{"type":"header","text":"Future of caching in distributed systems","value":"future-of-caching-in-distributed-systems","line":112,"column":0,"depth":3}},"children":[],"parent":"j0N1aVKxe96dktmyADG9U","data":{}},"body":"\u003ch1 id=\"master-the-art-of-caching-for-system-design-interviews-a-complete-guide\"\u003eMaster the Art of Caching for System Design Interviews: A Complete Guide\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#master-the-art-of-caching-for-system-design-interviews-a-complete-guide\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://levelup.gitconnected.com/master-the-art-of-caching-for-system-design-interviews-a-complete-guide-676bb49d194\"\u003ehttps://levelup.gitconnected.com/master-the-art-of-caching-for-system-design-interviews-a-complete-guide-676bb49d194\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA Comprehensive Caching Guide for Acing System Design Interviews.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/./assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__what-are-where-to-cache.webp\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.designgurus.io/course-play/grokking-the-system-design-interview/doc/638c0b7aac93e7ae59a1b0bd\"\u003eWhat are Where to Cache?\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eCaching is an essential technique used in software engineering to improve system performance and user experience. It works by temporarily storing frequently accessed data in a cache, which is faster to access than the original source of the data.\u003c/p\u003e\n\u003cp\u003eAs a software engineer, it’s essential to have a solid understanding of caching and how it works in different types of systems. In this blog, we’ll cover everything you need to know about caching, from its definition and importance to the different types of caching and best practices for implementation.\u003c/p\u003e\n\u003cp\u003eWhether you’re preparing for a \u003ca href=\"https://medium.com/gitconnected/system-design-interview-survival-guide-2023-preparation-strategies-and-practical-tips-ba9314e6b9e3\"\u003esystem design interview\u003c/a\u003e or looking to optimize your own software system, this guide will provide you with the knowledge and tools you need to succeed.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCheck \u003ca href=\"https://www.designgurus.io/course/grokking-the-system-design-interview\"\u003eGrokking the System Design Interview\u003c/a\u003e for a list of common system design interview questions and basics concepts.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"a-little-about-me\"\u003eA little about me\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#a-little-about-me\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAs the co-founder of \u003ca href=\"https://www.designgurus.io/\"\u003eDesign Gurus\u003c/a\u003e and the author of the \u003ca href=\"https://designgurus.io/courses\"\u003eGrokking\u003c/a\u003e series on coding and system design interviews, I have over 20 years of experience in software engineering. Over the course of my career, I have been on both sides of the interview table, having given over 30 interview loops and personally sitting through over 500+ coding and system design interviews.\u003c/p\u003e\n\u003cp\u003eIn this guide, I want to share some of the most valuable lessons I’ve learned about caching and how can you use these to crack any system design interviews.\u003c/p\u003e\n\u003cp\u003eLet’s start with understanding what caching is and why we need it.\u003c/p\u003e\n\u003ch2 id=\"i-what-is-caching\"\u003eI. What is Caching?\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#i-what-is-caching\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThe cache is a high-speed storage layer that sits between the application and the original source of the data, such as a database, a file system, or a remote web service. When data is requested by the application, it is first checked in the cache. If the data is found in the cache, it is returned to the application. If the data is not found in the cache, it is retrieved from its original source, stored in the cache for future use, and returned to the application.\u003c/p\u003e\n\u003cp\u003eCaching can be used for various types of data, such as web pages, database queries, API responses, images, and videos. The goal of caching is to reduce the number of times data needs to be fetched from its original source, which can result in faster processing and reduced latency.\u003c/p\u003e\n\u003cp\u003eCaching can be implemented in various ways, including in-memory caching, disk caching, database caching, and CDN caching. In-memory caching stores data in the main memory of the computer, which is faster to access than disk storage. Disk caching stores data on the hard disk, which is slower than main memory but faster than retrieving data from a remote source. Database caching stores frequently accessed data in the database itself, reducing the need to access external storage. CDN caching stores data on a distributed network of servers, reducing the latency of accessing data from remote locations.\u003c/p\u003e\n\u003ch2 id=\"ii-why-is-caching-important\"\u003eII. Why is Caching Important?\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ii-why-is-caching-important\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eCaching plays a critical role in improving system performance and user experience in software engineering. By storing frequently accessed data in a cache, applications can reduce the response time and latency of operations, resulting in faster and more efficient processing. Here are some reasons why caching is important:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eImproved system performance\u003c/strong\u003e: Caching can significantly improve the performance of an application by reducing the number of times data needs to be fetched from its original source. Since cached data can be retrieved faster than from the original source, this results in a significant reduction in processing time, which leads to a more responsive application.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReduced network load\u003c/strong\u003e: Caching can also reduce network load by minimizing the amount of data that needs to be transmitted over the network. Since cached data is stored locally, there is no need to fetch data from the original source, reducing the amount of data that needs to be transferred over the network.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIncreased scalability\u003c/strong\u003e: Caching can improve the scalability of an application by reducing the load on the original source. By storing frequently accessed data in a cache, the original source is less likely to be overwhelmed with requests, making it more scalable.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBetter user experience\u003c/strong\u003e: Faster response times and reduced latency can lead to a better user experience. Applications that load quickly and respond to user requests in a timely manner are more likely to be used and preferred by users.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"iii-types-of-caching\"\u003eIII. Types of Caching\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iii-types-of-caching\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eCaching can be implemented in various ways, depending on the specific use case and the type of data being cached. Here are some of the most common types of caching:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eIn-memory caching\u003c/strong\u003e: In-memory caching stores data in the main memory of the computer, which is faster to access than disk storage. In-memory caching is useful for frequently accessed data that can fit into the available memory. This type of caching is commonly used for caching API responses, session data, and web page fragments. To implement in-memory caching, software engineers can use various techniques, including using a cache library like Memcached or Redis, or implementing custom caching logic within the application code.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDisk caching\u003c/strong\u003e: Disk caching stores data on the hard disk, which is slower than main memory but faster than retrieving data from a remote source. Disk caching is useful for data that is too large to fit in memory or for data that needs to persist between application restarts. This type of caching is commonly used for caching database queries and file system data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDatabase caching\u003c/strong\u003e: Database caching stores frequently accessed data in the database itself, reducing the need to access external storage. This type of caching is useful for data that is stored in a database and frequently accessed by multiple users. Database caching can be implemented using a variety of techniques, including database query caching and result set caching.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCDN caching\u003c/strong\u003e: CDN caching stores data on a distributed network of servers, reducing the latency of accessing data from remote locations. This type of caching is useful for data that is accessed from multiple locations around the world, such as images, videos, and other static assets. CDN caching is commonly used for content delivery networks and large-scale web applications.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDNS caching\u003c/strong\u003e: DNS cache is a type of cache used in the Domain Name System (DNS) to store the results of DNS queries for a period of time. When a user requests to access a website, their computer sends a DNS query to a DNS server to resolve the website’s domain name to an IP address. The DNS server responds with the IP address, and the user’s computer can then access the website using the IP address. DNS caching improves the performance of the DNS system by reducing the number of requests made to DNS servers. When a DNS server receives a request for a domain name, it checks its local cache to see if it has the IP address for that domain name. If the IP address is in the cache, the DNS server can immediately respond with the IP address without having to query other servers. This can significantly reduce the response time for DNS queries and improve the overall performance of the system.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__types-of-caching.webp\"\u003e)\u003c/p\u003e\n\u003ch2 id=\"iv-cache-replacement-policies\"\u003eIV. Cache Replacement Policies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iv-cache-replacement-policies\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWhen implementing caching, it’s important to have a cache replacement policy to determine which items in the cache should be removed when the cache becomes full. Here are some of the most common cache replacement policies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLeast Recently Used (LRU):\u003c/strong\u003e LRU is a cache replacement policy that removes the least recently used item from the cache when it becomes full. This policy assumes that items that have been accessed more recently are more likely to be accessed again in the future.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLeast Frequently Used (LFU):\u003c/strong\u003e LFU is a cache replacement policy that removes the least frequently used item from the cache when it becomes full. This policy assumes that items that have been accessed more frequently are more likely to be accessed again in the future.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst In, First Out (FIFO):\u003c/strong\u003e FIFO is a cache replacement policy that removes the oldest item from the cache when it becomes full. This policy assumes that the oldest items in the cache are the least likely to be accessed again in the future.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRandom Replacement:\u003c/strong\u003e Random replacement is a cache replacement policy that removes a random item from the cache when it becomes full. This policy doesn’t make any assumptions about the likelihood of future access and can be useful when the access pattern is unpredictable.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"comparison-of-different-replacement-policies\"\u003eComparison of different replacement policies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#comparison-of-different-replacement-policies\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eEach cache replacement policy has its advantages and disadvantages, and the best policy to use depends on the specific use case. LRU and LFU are generally more effective than FIFO and random replacement since they take into account the access pattern of the cache. However, LRU and LFU can be more expensive to implement since they require maintaining additional data structures to track access patterns. FIFO and random replacement are simpler to implement but may not be as effective in optimizing cache performance. Overall, the cache replacement policy used should be chosen carefully to balance the trade-off between performance and complexity.\u003c/p\u003e\n\u003ch2 id=\"v-cache-invalidation-strategies\"\u003eV. Cache Invalidation Strategies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#v-cache-invalidation-strategies\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eCache invalidation is the process of removing data from the cache when it is no longer valid. Invalidating the cache is essential to ensure that the data stored in the cache is accurate and up-to-date. Here are some of the most common cache invalidation strategies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWrite-through cache:\u003c/strong\u003e Under this scheme, data is written into the cache and the corresponding database simultaneously. The cached data allows for fast retrieval and, since the same data gets written in the permanent storage, we will have complete data consistency between the cache and the storage. Also, this scheme ensures that nothing will get lost in case of a crash, power failure, or other system disruptions. Although, write-through minimizes the risk of data loss, since every write operation must be done twice before returning success to the client, this scheme has the disadvantage of higher latency for write operations.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWrite-around cache:\u003c/strong\u003e This technique is similar to write-through cache, but data is written directly to permanent storage, bypassing the cache. This can reduce the cache being flooded with write operations that will not subsequently be re-read, but has the disadvantage that a read request for recently written data will create a “cache miss” and must be read from slower back-end storage and experience higher latency.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWrite-back cache:\u003c/strong\u003e Under this scheme, data is written to cache alone, and completion is immediately confirmed to the client. The write to the permanent storage is done based on certain conditions, for example, when the system needs some free space. This results in low-latency and high-throughput for write-intensive applications; however, this speed comes with the risk of data loss in case of a crash or other adverse event because the only copy of the written data is in the cache.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWrite-behind cache:\u003c/strong\u003e It is quite similar to write-back cache. In this scheme, data is written to the cache and acknowledged to the application immediately, but it is not immediately written to the permanent storage. Instead, the write operation is deferred, and the data is eventually written to the permanent storage at a later time. The main difference between write-back cache and write-behind cache is when the data is written to the permanent storage. In write-back caching, data is only written to the permanent storage when it is necessary for the cache to free up space, while in write-behind caching, data is written to the permanent storage at specified intervals.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOverall, the cache invalidation strategy used should be chosen carefully to balance the trade-off between performance and data accuracy. By understanding the different cache invalidation strategies available, software engineers can select the appropriate strategy to optimize cache performance and reduce latency while ensuring that the data stored in the cache is accurate and up-to-date.\u003c/p\u003e\n\u003ch2 id=\"vi-cache-invalidations-methods\"\u003eVI. Cache Invalidations Methods\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vi-cache-invalidations-methods\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHere are the famous cache invalidation methods:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePurge\u003c/strong\u003e: The purge method removes cached content for a specific object, URL, or a set of URLs. It’s typically used when there is an update or change to the content and the cached version is no longer valid. When a purge request is received, the cached content is immediately removed, and the next request for the content will be served directly from the origin server.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRefresh\u003c/strong\u003e: Fetches requested content from the origin server, even if cached content is available. When a refresh request is received, the cached content is updated with the latest version from the origin server, ensuring that the content is up-to-date. Unlike a purge, a refresh request doesn’t remove the existing cached content; instead, it updates it with the latest version.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBan\u003c/strong\u003e: The ban method invalidates cached content based on specific criteria, such as a URL pattern or header. When a ban request is received, any cached content that matches the specified criteria is immediately removed, and subsequent requests for the content will be served directly from the origin server.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTime-to-live (TTL) expiration\u003c/strong\u003e: This method involves setting a time-to-live value for cached content, after which the content is considered stale and must be refreshed. When a request is received for the content, the cache checks the time-to-live value and serves the cached content only if the value hasn’t expired. If the value has expired, the cache fetches the latest version of the content from the origin server and caches it.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStale-while-revalidate\u003c/strong\u003e: This method is used in web browsers and CDNs to serve stale content from the cache while the content is being updated in the background. When a request is received for a piece of content, the cached version is immediately served to the user, and an asynchronous request is made to the origin server to fetch the latest version of the content. Once the latest version is available, the cached version is updated. This method ensures that the user is always served content quickly, even if the cached version is slightly outdated.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/./assets/images/software-engineering/master-the-art-of-caching-for-system-design-interviews__cache-invalidations-methods.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"vii-cache-performance-metrics\"\u003eVII. Cache Performance Metrics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vii-cache-performance-metrics\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWhen implementing caching, it’s important to measure the performance of the cache to ensure that it is effective in reducing latency and improving system performance. Here are some of the most common cache performance metrics:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHit rate:\u003c/strong\u003e The hit rate is the percentage of requests that are served by the cache without accessing the original source. A high hit rate indicates that the cache is effective in reducing the number of requests to the original source, while a low hit rate indicates that the cache may not be providing significant performance benefits.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMiss rate:\u003c/strong\u003e The miss rate is the percentage of requests that are not served by the cache and need to be fetched from the original source. A high miss rate indicates that the cache may not be caching the right data or that the cache size may not be large enough to store all frequently accessed data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCache size:\u003c/strong\u003e The cache size is the amount of memory or storage allocated for the cache. The cache size can impact the hit rate and miss rate of the cache. A larger cache size can result in a higher hit rate, but it may also increase the cost and complexity of the caching solution.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCache latency:\u003c/strong\u003e The cache latency is the time it takes to access data from the cache. A lower cache latency indicates that the cache is faster and more effective in reducing latency and improving system performance. The cache latency can be impacted by the caching technology used, the cache size, and the cache replacement and invalidation policies.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"viii-conclusion\"\u003eVIII. Conclusion\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#viii-conclusion\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"key-take-ways\"\u003eKey take-ways\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#key-take-ways\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eCaching is an essential tool for optimizing system performance and reducing latency in software engineering. By storing frequently accessed data in a cache, the number of requests to the original source can be reduced, resulting in faster response times and improved scalability. Caching is used in a variety of software applications, from web applications to databases to content delivery networks.\u003c/p\u003e\n\u003ch3 id=\"future-of-caching-in-distributed-systems\"\u003eFuture of caching in distributed systems\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#future-of-caching-in-distributed-systems\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAs distributed systems become more prevalent in software engineering, caching will continue to play a critical role in optimizing system performance. Distributed caching solutions like Redis and Memcached are becoming increasingly popular, allowing data to be cached across multiple servers and data centers. As the use of machine learning and artificial intelligence continues to grow, caching will also be used to optimize the performance of these applications by reducing the time it takes to retrieve and process data.\u003c/p\u003e\n\u003cp\u003eTake a look at \u003ca href=\"https://www.designgurus.io/course/grokking-the-system-design-interview\"\u003e\u003cstrong\u003eGrokking the System Design Interview\u003c/strong\u003e\u003c/a\u003e for system design interview questions. To learn software architecture and practice advanced system design interview questions take a look at \u003ca href=\"https://www.designgurus.io/course/grokking-the-advanced-system-design-interview\"\u003e\u003cstrong\u003eGrokking the Advanced System Design Interview\u003c/strong\u003e\u003c/a\u003e.\u003c/p\u003e","noteIndex":{"id":"Iy0MoL0KnL55Br3AfTS2C","title":"Luke","desc":"","updated":1761796791487,"created":1644449449778,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"4e745570ca97988a0362cb939b760952","links":[{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"life-tips","position":{"start":{"line":41,"column":5,"offset":2603},"end":{"line":41,"column":29,"offset":2627},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"life-tips","anchorHeader":"wodenokoto"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2025","alias":"What I read in 2025","position":{"start":{"line":70,"column":3,"offset":4333},"end":{"line":70,"column":54,"offset":4384},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2025"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2024","alias":"2024","position":{"start":{"line":71,"column":5,"offset":4389},"end":{"line":71,"column":41,"offset":4425},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2024"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2023","alias":"2023","position":{"start":{"line":72,"column":5,"offset":4430},"end":{"line":72,"column":41,"offset":4466},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2023"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2022","alias":"2022","position":{"start":{"line":73,"column":5,"offset":4471},"end":{"line":73,"column":41,"offset":4507},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2022"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-struggled-brag-in","position":{"start":{"line":79,"column":3,"offset":4643},"end":{"line":79,"column":39,"offset":4679},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-struggled-brag-in"}}],"anchors":{"what-i-read-in-past":{"type":"header","text":"What I read in past","value":"what-i-read-in-past","line":74,"column":0,"depth":2}},"children":["zd4mq442jike0pr0wba1u3m","6hzeqsofq67gdk88flxlkhp","778ijii93yu5uwnrwmn5zi4","g1fngdjl25nes6fs3lip602","ZbdkdApFqLdks4Moq92R9","uoc5hhki3o4py15cesddu8q","9qf7j06jtdkm6rnx9ymvwb0","5zn10cvj7ajy2gh2is5nqmg","4qo9ma0z0yu1czns6pxl7y5","ok0e729ho7o09xetujkxc0m","GR5x8HnNFEN6fU2UBSEIK","yirtnlj8q24yutcf3ss1xqy","eq0wc6t7wl2wv221yb68ro4","7x2fnv4j6gxts08qk0jguny","ettkt3iClONnxpbGwBVLl","7l4knev6v613tbuoskvmbdg","hvh5bud6yp7dc89tuh95tr9","4fvoqrplw0cweo554usbjos","f8qsfql0a9v8thpeo82udfa","1swsbrhqi9jk41v9eodyi5q","SQqYupi6EFddTerBA8RRD","hjNeNc1F2JUh0lTWanH4h","qf0l4wbrc9jgooyzexmbq5v","uur1lkol353z9vfeqb3n5bv","cd9n1czq3ursgkby985wkmm","k1sr43vwnfqztwc0s43pkcf","wfde75rhdvq2yfa2zy2q6rv","rjcmdv60jokmbw6zoq8u2ef","ujapvww8o6v3kpmlhtryq4k","pkwewou9d5e8ystswn1j2b4"],"parent":null,"data":{},"body":"\nHi there 👋. I'm a Front-end developer.\n\n---\n\n- 단순함과 꾸준함은 가장 쉬우면서도 지키기 어려운 원칙.\n\n- 🥱 -\u003e 🤔💡🌱 - [On The Death of Daydreaming](https://www.afterbabel.com/p/on-the-death-of-daydreaming)\n  - boredom -\u003e easy fun -\u003e art -\u003e profit?\n\n\u003e I've often described my motivation for building software to others using imagery: I like to go find a secluded beach, build a large, magnificent sand castle, and then walk away. Will anyone notice? Probably not. Will the waves eventually destroy it? Yep. Did I still get immense satisfaction? Absolutely. - [aliasxneo](https://news.ycombinator.com/item?id=41497113)\n\n\u003e We love to see the process, not just the result. The imperfections in your work can be beautiful if they show your struggle for perfection, not a lack of care. - [ralphammer](https://ralphammer.com/is-perfection-boring/)\n\n\u003e Simplicity, even if it sacrifices some ideal functionality has better survival characteristics than the-right-thing. - [The Rise of Worse is Better](https://www.dreamsongs.com/RiseOfWorseIsBetter.html)\n\n\u003e [Roberto Blake was talking about making 100 crappy videos](https://www.youtube.com/watch?v=OnUBaQ1Sp_E) to get better over time. Putting in the reps and improving a little bit each time.\n\u003e\n\u003e Putting in the work without expecting any external reward at first (eg views, followers, likes, etc) will pay off in the long run. - [100 Scrappy Things](https://www.florin-pop.com/blog/100-scrappy-things/)\n\n\u003e Make the difficult habitual, the habitual easy, and the easy beautiful. - [Constantin S. Stanislavski](https://www.goodreads.com/quotes/7102271-make-the-difficult-habitual-the-habitual-easy-and-the-easy)\n\n\u003e A good match is a **structured** dance, where players aim to **score** while they are following well-defined **rules**. This **freedom within a structure** is what makes it fun. - [ralphammer](https://ralphammer.com/how-to-get-started/)\n\n- [Pivot Points](https://longform.asmartbear.com/pivot-points/)\n\n  - non-judgmental aspects of personality that can be strengths in some contexts and weaknesses in others\n  - Pivot Points are fixed in the short term\n\n- [Hedged Bets](https://longform.asmartbear.com/predict-the-future/#hedged-bets)\n  - trading slightly less maximum upside for predictable, net-positive outcomes.\n\n\u003e “Motivation often comes after starting, not before. Action produces momentum.”\n\u003e [When you start a new habit, it should take less than two minutes to do.](https://jamesclear.com/how-to-stop-procrastinating)\n\u003e\n\u003e - James Clear\n\n\u003e Focus is more about **not** keeping busy when you need to wait for something.  \n\u003e Eat the boredom for a minute.\n\u003e\n\u003e - [[life-tips#wodenokoto]]\n\n\u003e [4 minutes run hard enough to push heart rate to 90%, 3 minutes recover, repeat 4 times](https://news.ycombinator.com/item?id=34213181)\n\u003e\n\u003e - https://www.ntnu.edu/cerg/advice\n\u003e - [Get running with Couch to 5K](https://www.nhs.uk/live-well/exercise/running-and-aerobic-exercises/get-running-with-couch-to-5k/)\n\n\u003e [recommended routine - bodyweightfitness](https://www.reddit.com/r/bodyweightfitness/wiki/kb/recommended_routine/) - I Don't Have This Much Time!\n\u003e\n\u003e - Don't workout at all (saves anywhere from 20 to 60 minutes, but really, really, really, really, really, really, really, really, really not recommended)\n\n\u003e 도무지 읽히지 않는 책 앞에서 내가 택한 방법은 펼쳐진 페이지 앞에서 멍때리기이다. 다르게 표현하면 이렇다. 펼쳐진 두 페이지 앞에서 오래 머물기.\n\u003e\n\u003e 책을 펼쳐놓는 것으로 충분하다. 읽지 못해도 좋다. 매일 정해진 진도를 나가야 하는 학교 수업이 아니니까. 하지만 읽지 않아도 괜찮다고 해서 펼쳐두지조차 않으면 곤란하다. 가능한 한 자주 책을 펼쳐두도록 하자. 전혀 읽지 않고 멍하니 바라보고 있다가 다시 덮게 되더라도\n\u003e\n\u003e - 막막한 독서. 시로군. P.10~13\n\n\u003e I think it should be everyone's primary focus to sleep well, drink water, get outside, get active, and eat generally decently. I hate to say it, but if you're not eating a good amount of vegetables and fruit, decent protein, sleep, etc, no amount of XYZ will catch up to that detriment. - [CE02](https://news.ycombinator.com/item?id=35056071)\n\n\u003e My real battle is doing good versus doing nothing. - [Deirdre Sullivan](https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral)\n\n[Kind Engineering](https://kind.engineering/) - How To Engineer Kindness\n\n\u003e Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. - [Teller](https://www.goodreads.com/quotes/6641527-sometimes-magic-is-just-someone-spending-more-time-on-something)\n\n---\n\n## What I read in past\n\n- [[What I read in 2025|journal.what-i-read-in.2025]]\n  - [[2024|journal.what-i-read-in.2024]]\n  - [[2023|journal.what-i-read-in.2023]]\n  - [[2022|journal.what-i-read-in.2022]]\n- 📝 [Gists](https://gist.github.com/Luke-SNAW)\n- 📜 [Journals](https://luke-snaw.github.io/Luke-SNAW__netlify-CMS.github.io/)\n\n---\n\n- [[journal.what-i-struggled-brag-in]]\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":false,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.115.0","enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Luke SNAW","description":"Personal knowledge space"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","siteUrl":"https://luke-snaw.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"6hmmfse40un0yvyhcfhf1kh"},"buildId":"vOE8u-mg___OsOsz4tjEg","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>REST, GraphQL or RPC — A Decision Paralysis</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="REST, GraphQL or RPC — A Decision Paralysis"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://luke-snaw.github.io//notes/6h87a35ua3cfe1urbwxm13z/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="11/15/2023"/><meta property="article:modified_time" content="11/15/2023"/><link rel="canonical" href="https://luke-snaw.github.io//notes/6h87a35ua3cfe1urbwxm13z/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9d8e0603730b15a3.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/vOE8u-mg___OsOsz4tjEg/_buildManifest.js" defer=""></script><script src="/_next/static/vOE8u-mg___OsOsz4tjEg/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="rest-graphql-or-rpc--a-decision-paralysis">REST, GraphQL or RPC — A Decision Paralysis<a aria-hidden="true" class="anchor-heading icon-link" href="#rest-graphql-or-rpc--a-decision-paralysis"></a></h1>
<blockquote>
<p><a href="https://itnext.io/rest-graphql-or-rpc-a-decision-paralysis-0acaa84b5a27">https://itnext.io/rest-graphql-or-rpc-a-decision-paralysis-0acaa84b5a27</a></p>
</blockquote>
<p>...</p>
<h2 id="conclusions">Conclusions<a aria-hidden="true" class="anchor-heading icon-link" href="#conclusions"></a></h2>
<p>API design is a difficult choice that should be driven by a product discovery phase, where you understand the innate nature of your application, and other actors in the system.</p>
<p>Finger to the wind.</p>
<p>Use <strong>REST</strong> if:</p>
<ul>
<li>you are building an API to interact with your database using CRUD operations</li>
<li>your data model is not heavy on relations</li>
<li>you have a limited number of user roles and access requirements</li>
</ul>
<p>Use <strong>GraphQL</strong> If:</p>
<ul>
<li>you are building a gateway to connect multiple data sources or services</li>
<li>your data model is heavy on relations and represents a graph</li>
<li>you have high-granularity access requirements</li>
<li>you are building an API targeted mostly at front-end applications</li>
<li>you have a large number of API clients with varying data requirements</li>
</ul>
<p>Use <strong>RPC</strong> if:</p>
<ul>
<li>you want to be flexible in naming and routing conventions</li>
<li>you want to build semantic, easy to read APIs</li>
<li>you need to address diverging, volatile, or complex use cases</li>
<li>your services interact outside of the HTTP protocol</li>
<li>you want to build a robust future-proof API decoupled from implementation and data storage concerns</li>
</ul>
<p>If you ask for my personal opinion, I think the future is RPC. I love GraphQL for front-end development, but I don’t think it’s an ideal solution for cross-service communication, and once you tip your toes into it it bites your foot off, and makes things so much harder to reason about. By all means, use GraphQL as a proxy for your read-model, but don’t bring it into a mix as part of your internal services. And as for the REST, let it rest.</p>
<hr>
<p>Ever since AJAX capabilities landed in our browsers some 20+ years ago, developers around the world had been busy pushing these technologies to their limits, engineering creative ways of challenging the foundations of the original internet, and transforming it from a web of static pages to a web of dynamic data flows.</p>
<p>Application programming interfaces (APIs) that power all this data exchange have gone through many iterations, and it’s unsurprising that in 2023 many development teams struggle with decisions about the design and implementation of their APIs. With a variety of programming languages, transfer protocols, and infrastructure architectures, finding a way to define reliable contracts for data transfer, and more so to implement and maintain them in the face of changing requirements, is no easy feat.</p>
<p>Dealing with APIs on a daily basis, and observing the discussions around their design in my professional circles, it appeared to me it would be useful to put down some of my thoughts in writing. With <strong>REST</strong>, <strong>GraphQL</strong> and <strong>RPC</strong> being the most commonly discussed design patterns, I will focus on those and summarise some of my thoughts and experiences. Having worked with all 3 of them, I realise there is no silver bullet, and I think we are a long way away from having a common ground, similar to W3C standards, which helped bring sense and structure to browser technologies.</p>
<p>Before we start, let me clarify some of the assumptions:</p>
<ul>
<li>In a way, treating these 3 paradigms as equals is like comparing apples to oranges. After all, GraphQL is just a query language specification and could be instrumented in a way that is very similar to an RPC gateway. On the query side of things, it is also very similar to REST with it’s focus on resources, and in fact nothing prevents you from sending GraphQL documents as part of your REST calls, and use field resolvers as part of your controller implementation. So, for the sake of this article, I will be thinking of GraphQL as an implementation of the specification, i.e. a server akin Apollo capable of receiving and serving data over HTTP.</li>
<li>Speaking of RPC, I am not referring to any specific implementation, such as <a href="https://grpc.io/">gRPC</a>, but rather a paradigm of using procedure calls instead of operating on resources with unique addresses in the network, as is common in REST. Even though I intend to draw parallels with other transfer protocols, for the purposes of this article, API will stand to mean data transfer over HTTP. I will put aside networking considerations to focus on actual API design rather than mechanics of data moving over the wire. As such, it’s best to think of an RPC implementation similar to <a href="https://en.wikipedia.org/wiki/JSON-RPC">JSON-RPC</a> or <a href="https://trpc.io/">tRPC</a> rather than gRPC (with its use of HTTP/2 for bidirectional streaming of binary data).</li>
</ul>
<p>Let’s look at the various aspects of API design that need to be considered when making a decision and see how the 3 patterns hold up against these requirements.</p>
<h2 id="schema-definition">Schema Definition<a aria-hidden="true" class="anchor-heading icon-link" href="#schema-definition"></a></h2>
<p>Ability to express APIs in abstract terms using a schema definition language (SDL) is an important consideration to make when choosing our API design. SDLs allow us to detach our design from implementation details, focus on our data model, and express a contract in a way that is interoperable throughout a variety of clients that could be interacting with our API in the future. SDLs make it easier to build tooling to automate some of otherwise painstakingly manual processes, e.g. by generating client SDKs or types for our data transfer objects.</p>
<p>Working without an SDL is a deal breaker, as you end up having to maintain a set of documentation in some random format that will be difficult to keep up to date, evolve and communicate to API clients.</p>
<p>When evaluating an SDL consider what your development workflow is going to look like:</p>
<ul>
<li><strong>Schema-first approach</strong> is practical for larger teams that deal with organisational complexity. Various teams can work together on defining the contract before moving forward with the actual implementation. This approach requires more time in planning and communication, but as a result allows the teams to work independently and in parallel, not having to deal with varying implementation schedules. This also results in better code quality as such a development flow requires mocks and tests to be feasible, perhaps even pushing development towards TDD. An added benefit of schema-first approach is that it’s agnostic to actual implementation details — underlying technology can always be swapped without affecting the workflow or impacting the clients. Using this approach however does require that everyone learn to speak a new language, so the syntax and usability are quite important considerations.</li>
<li><strong>Code-first approach</strong> is more practical for smaller teams that want to maintain agility, while having some level of contractual safety between clients and benefiting from the tooling within the SDL ecosystem. Code-first approach is tightly coupled with the tooling chosen for the development, and it comes with a risk of a costly effort that would be required to switch to a schema-first approach some time in the future, e.g. when the tools are no longer maintained by their authors, or the growing organisational complexity prevents the team from collaborating efficiently.</li>
</ul>
<p><strong>GraphQL</strong> in its essence is an SDL specification, which makes it a good candidate for expressing APIs. It has a built-in support for defining procedures (queries and mutations), input and response object types.</p>
<p><strong>REST</strong> and <strong>RPC</strong> are abstract concepts and do not have a standard SDL, but there are several general purpose frameworks that can be used to describe HTTP-based APIs.</p>
<ul>
<li><a href="https://www.openapis.org/">OpenAPI</a> (formerly Swagger) is the most common SDL specification that allows API authors to express HTTP requests and responses in YAML or JSON. OpenAPI ecosystem features a number of <a href="https://openapi.tools/">cool development tools</a><a href="https://openapi-generator.tech/">.</a></li>
<li><a href="https://www.asyncapi.com/">AsyncAPI</a> is another option to consider for <strong>RPC</strong> and other systems that focus on exchanging messages rather than resources. Its syntax is similar to OpenAPI, but it can better express the needs that go beyond the HTTP protocol.</li>
</ul>
<p>APIs expressed through SDLs also help us address type safety and serialisation concerns, making contracts enforceable throughout our stack. There are several serialisation and validation patterns that we can build on top of our specs.</p>
<ul>
<li><a href="https://protobuf.dev/">Protocol Buffers</a> is a platform and language neutral mechanism to serialize structured data. Models expressed in OpenAPI can be exported into protobuf format with <a href="https://github.com/google/gnostic">gnostic</a> making it easier to reliably exchange data between the server and the clients.</li>
<li><a href="https://json-schema.org/">JSON-Schema</a> is another standard for expressing serialisable data, as well as validation requirements for such data. OpenAPI specs could be converted to JSON-Schema using <a href="https://github.com/openapi-contrib/openapi-schema-to-json-schema">converters</a>. It’s an interesting approach if you want to validate your data at various stages of the request lifecycle.</li>
<li><a href="https://modelina.org/">Modelina</a> and other tools can be used to generate models from OpenAPI, AsyncAPI, and JSON-Schema.</li>
</ul>
<p>When defining your schema, you may also want to explore existing conventions that ensure that your API design is as compatible as possible with other systems you may want to integrate with in the future.</p>
<ul>
<li><a href="https://www.jsonrpc.org/specification">JSON-RPC</a> is a convention for structuring your RPC messages.</li>
<li><a href="https://cloudevents.io/">cloudevents</a> is a broader attempt to find a common language when documenting events in various formats and can be useful for various RPC considerations.</li>
<li>Consider various filtering, sorting, and pagination conventions that already exist, e.g. <a href="https://datatracker.ietf.org/doc/html/draft-ietf-scim-api-12#section-3.2.2.2">SCIM</a>, <a href="https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html">OData</a>, <a href="https://portal.ogc.org/files/96288#cql-core">CQL</a>.</li>
</ul>
<p>Other things to keep in mind when dealing with SDL:</p>
<ul>
<li>does it allow you to describe your resources in a manner that would allow any client to easily understand the logic, resources and relationships</li>
<li>does it allow you to express authentication requirements and accessibility of resources based on client roles/permissions</li>
<li>does it support all the data types (scalars, enums and complex unions) that your application would require</li>
<li>does it have the tooling necessary to serialise data in a format suitable for the HTTP (e.g. URL query and JSON) and other protocols</li>
<li>does it allow you to express your data model, resources and procedures beyond the HTTP protocol, i.e. you would prefer to use the same SDL to describe data transfer in other communication protocols (such message queues, or even command line interfaces)</li>
</ul>
<p>The great thing about the SDL is that it can serve as documentation for your API, both internally and externally. Making the schema accessible to the clients makes it possible for them to introspect the schema to discover the available resources within your API. There are wonderful GUI playgrounds that allow you to explore and interact with GraphQL (e.g. <a href="https://studio.apollographql.com/sandbox/explorer/?">Apollo Studio)</a> and OpenAPI (e.g. <a href="https://swagger.io/tools/swagger-ui/">Swagger UI)</a> schemas. And of course they integrate well with our beloved <a href="https://www.postman.com/">Postman</a>, allowing us to create collections from schema definitions, and even export collections into some of the common SDLs.</p>
<h2 id="data-model">Data Model<a aria-hidden="true" class="anchor-heading icon-link" href="#data-model"></a></h2>
<p>A decision about API design can not be made without a good understanding of the specifics and complexity of the underlying data model, and the needs of the clients in accessing the resources.</p>
<h3 id="object-relational-complexity">Object-relational complexity<a aria-hidden="true" class="anchor-heading icon-link" href="#object-relational-complexity"></a></h3>
<p>Relational model complexity is a major concern in API design, as traversing complex relational models via an API can be difficult. Relations that exist between your domain entities could be a deciding factor in favour or against a specific approach.</p>
<p>In a standard <strong>REST</strong> implementation, each resource has it’s own unique network address. You can access a resource with a straightforward <code>GET</code> request, e.g. <code>GET /users/1</code>. Things get murkier when you try to represent collections and relations, e.g. to get a list of user’s friends you would go to <code>GET /users/1/friends</code>, then however it gets ambiguous if you want to get a specific friend: it’s quite unclear whether you access it via <code>GET /users/1/friends/friendship-1</code> or <code>GET /friendships/friendship-1</code> or <code>GET /users/2</code>. It is also unclear where you should put your nested documents, e.g. should a user address be returned as part of the user resource, or should it be it’s own resource living on the <code>GET /user/1/addresses</code> edge. Such ambiguity plaques development teams with endless decisions about domain boundaries and their representation in the <code>REST</code> graph. Compromises are made between domain model uniformity and performance, making it hard for API clients to know exactly where to look.</p>
<p>Aside from that, <strong>REST</strong> places the burden of traversing the graph on the API client. If you ever tried to resolve a list of second-degree relations, you know what a nightmare it is, with a cascade of hundreds, if not thousands, of API requests. On top of it, if you are dealing with bidirectional relations, you have to account for node repetition as well as circularity, making it the responsibility of the client to implement some form of caching and deduplication to avoid infinite loops.</p>
<p>In order to alleviate some of this pain, REST API authors resort to creative solutions (a.k.a hacks) that allow relations to be resolved when a resource is requested. For example, Stripe API uses <code>expand</code> parameter. This does address the traversal concerns, but leads to non-deterministic response types, which again have to be dealt with by the API client, forcing it to do lots of type juggling and coercion.</p>
<p>With the emergence of social networks and their complex social graphs, <strong>REST</strong> had become quite unmanageable. <strong>GraphQL</strong>, as the name suggests, was created by Facebook as a way of traversing a complex social graph, representing an entirety of human society with its six degrees of separation. Facebook was trying to solve a problem inherent to social complexity with a multitude of actors and multidirectional relationships between them, and you should keep that in mind when evaluating whether or not your API design might benefit from it.</p>
<p><strong>GraphQL</strong> is brilliant in its simplicity. By letting the client specify precisely what data it needs and fetch it in a single request, it shifts the responsibility of traversing and stitching the graph to the server. Embedding types and relations within the schema design, it can use field resolvers to extract the necessary data and traverse the query of any complexity. This doesn’t always come cheap, and leads to additional problems and tooling (e.g. data loaders to address the n+1 problems), but allows the server to use any number of data stores to aggregate properties and relations, making API clients agnostic to such implementation details.</p>
<p>At their core, both <strong>REST</strong> and <strong>GraphQL</strong> are focused on resources and their representation. This is usually tightly coupled with how we represent entities in our databases. In a sense, these entities always exist in their platonic form, regardless of who the observer is. This can be problematic in certain systems, where not all clients are created equal. Having a static schema or a graph that doesn’t account for use cases and requester roles can lead to all kind of issues in the design. Presume our employee model has a salary property which can only be accessed by an accountant role — how do we represent and implement this in our API design? Do we make the property optional? If it’s optional how do we know what the lack of a value represents (there is no data in the storage or there is no accessible data for this requester). Do we create another edge in REST that throws an HTTP error? Do we send null or an error in GraphQL? This ambiguity can lead to additional complexity and uncertainty on the client-side, and should be factored in at the API design stage.</p>
<p>Resource-centric approach to our API design tends to make us think about our APIs in terms of our data storage model. While it’s justified in some cases, it can be problematic if we couple our API too tightly with our databases. All too often, we reuse our ORM models as our API models, and rely on tools such as <a href="https://hasura.io/">Hasura</a>, <a href="https://www.prisma.io/graphql">Prisma GraphQL</a>, <a href="https://postgrest.org/en/stable/index.html">PostgREST</a>, and many others to interface directly with our database via API. These tools can save a great deal of time, but they blur the lines between the architectural layers, and make our API clients susceptible to breaking changes. Depending on how and where the clients are used, such an approach poses a risk to data integrity, and requires a solution to rectifying race conditions of running data and schema migrations, generating and tagging new SDK versions, and propagating the changes to all the clients. API versioning becomes an issue if data storage engine does not support any versioning. Aside from that complex access controls become a pain point requiring us to hook into these tools to manage roles and permissions.</p>
<p><strong>RPC</strong> on the other hand is unopinionated about resources and their representation. It allows API authors to move away from trying to reproduce the data model and instead focus on use cases — procedures can be tailored towards specific needs of the clients and actors in the system. Unlike REST, where the client hardly has any say in what it gets, and GraphQL, where the client can indiscriminately request as much data as it wants (vis Cambridge Analytica), RPC can accommodate various requirements arising from different API applications. RPC servers can be instrumented in a way that rips the best from all worlds — from resolvers to untangle the graph to routing middleware to manage the request/response flow to isomorphic route and query level permission controls. RPC API can be built around immutable contracts and evolve over time to address changing requirements in a backward compatible manner. RPC allows us to separate API concerns from data persistence/storage concerns and other implementation details, leading to a more future-proof API design that doesn’t have to change every time the data schema changes.</p>
<p>While GraphQL is a good solution for a larger API surface, where the needs of the clients can not be well predicted, RPC could be a good alternative for smaller projects — essentially, instead of making the client write queries and enumerate all fields that have to be returned to the client, the response type could be explicitly defined as part of the RPC schema. In essence, the same could be said about REST, but that goes against the nature of the paradigm that dictates that each resource should be available at its own network locator.</p>
<h3 id="updating-data">Updating Data<a aria-hidden="true" class="anchor-heading icon-link" href="#updating-data"></a></h3>
<p>Let’s be honest, when it comes to updating data via <strong>REST</strong>, it’s a pain in the ass. Different HTTP methods that are supposed to make things transparent, instead raise all kinds of questions:</p>
<ul>
<li>what method should be used to soft-delete or archive a resource? Should it be a <code>DELETE</code> request with some flag, or <code>POST</code> request with an action name (in effect making it an RPC request?), or should it be <code>PATCH</code> request updating the <code>deleted</code> or <code>archived</code> property of an object?</li>
<li>what about partial updates? Should we use <code>PUT</code> or <code>PATCH</code>? What about updates that have specific side effects, e.g. changing account email? Should they still go into a <code>PATCH</code> request, or be sent as <code>POST</code> with an action name?</li>
<li>what about granularity of partial updates where certain actors are only allowed to make certain changes? How do we split and describe this logic in our REST API design?</li>
<li>what about logic that does not really have any resources attached to it? Where should, for example, the various steps of the password reset flow live? Should they be in the root of the REST API or some edge of the API?</li>
<li>what happens with nested documents? What if those nested updates require transactional safety?</li>
</ul>
<p>The fact is, whenever you build an SDK around the REST API, you end up using procedure calls to describe the various actions that it performs, e.g. <code>deleteUser()</code> or <code>capturePayment()</code> rather than operating with get/post/put/patch/delete methods directly. My personal opinion is that REST is no longer suitable for modern day application design — requirements are far too complex to embed them into opinionated resource-centric API design.</p>
<p>Procedure calls are more suited for the complexity of modern day applications, allowing API designers to address specific use cases rather than trying to accommodate every possible scenario in a limited set of RESTful endpoints. Changing user password, is not the same as changing user email, or opting a user into a newsletter. All three may be part of the same resource, but hardly ever would you update a password and subscribe a user to the newsletter in the same request. All of these procedures have distinct side effects, and may require custom validation and permission checks.</p>
<p>RPC fits in nicely with CQRS principles. You can think of procedure calls as queries and commands, which make transport protocol considerations irrelevant. HTTP controllers receive and validate payloads, and then pass them on to query and command busses. This makes it easy to reuse procedure calls for any other transport — from command line to message queue to chatbots to whatever else that can receive a procedure call.</p>
<p>GraphQL mutations are in fact RPC. Aside from a terrible name that makes me think of unpredictable gene mutations and lockdowns, it is very flexible. The question however remains, what is to be considered a mutation — sending emails or downloading documents are procedures that don’t really mutate anything, so should they be part of the graph at all?</p>
<p>Another important thing to consider in the context of API design is whether or not data updates are synchronous or asynchronous. In distributed systems, synchronicity might not always be an option, so you should plan ahead to figure out a way to communicate persistence events to the API client, and how those are going to be reflected in API schema and documentation. Where your clients live will determine what technology you can use for that: webhooks, WebSockets, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events">Server-Side Events</a>, push notifications or something else. Here is an <a href="https://github.com/wso2/reference-architecture/blob/master/event-driven-api-architecture.md">interesting read</a> on the subject of asynchronous event-driven APIs.</p>
<p>Speaking of distributed systems, we should also consider what implications using GraphQL might have. On one hand GraphQL is well suited for aggregating data from various sources and can be used as a gateway to your microservices. On the other hand, however, mixing GraphQL with other API designs across the stack (or even having multiple GraphQL servers) might become unwieldy. You will need to think about ways to stitch or federate your servers to ensure the integrity of the graph.</p>
<h3 id="data-types">Data Types<a aria-hidden="true" class="anchor-heading icon-link" href="#data-types"></a></h3>
<p>When it comes to API design there are a few considerations to make with regards to types of serialisable data that the API is going to transmit:</p>
<ul>
<li>how are you going to communicate serialisation requirements for custom scalar types</li>
<li>how are you going to express mixed types and <code>oneOf</code> logic, and how will you discriminate such union types</li>
</ul>
<p>Not all scalars are created equal. Having an API schema littered with <code>string</code> and <code>number</code> types is nothing short of a nightmare. A contract should be explicit about the requirements — API clients should not be second guessing what <code>{ contact: string }</code> means, especially if there is validation attached to that property:</p>
<ul>
<li>use string identities, e.g. <code>UUID</code>, <code>Email</code>, <code>IPv6</code>, <code>ISBN</code> etc, and be explicit about custom string patterns</li>
<li>use integer identities, e.g. <code>Year</code>, <code>Timestamp</code> etc, and be explicit about ranges for custom integers</li>
<li>use float identities, e.g. <code>Lat</code>, <code>Long</code> etc, and be explicit about ranges and precision for custom floats</li>
<li>use enums to express finite lists of scalar options</li>
<li>adopt a single date format, i.e. ISO Date string or Unix timestamp</li>
</ul>
<p>Both GraphQL and OpenAPI support scalar type refinements, but they leave serialisation concerns to the servers and clients, so be sure to account for custom scalar type serialisation in your implementation. GraphQL, unlike OpenAPI, does not offer a native approach to documenting validation requirements at the schema-level, so be ready for some runtime error handling. There are some attempts to use non-standard directives to express <a href="https://github.com/confuser/graphql-constraint-directive/blob/master/README.md">validation constraints</a> and <a href="https://github.com/Saeris/graphql-directives#formatdate">formatting requirements</a>, but you will need to instrument them yourself.</p>
<p>Another important aspect of modelling data in API design is mixed types. Presume your API is going to serve a catalogue of items available in a library. You may have to deal with books, magazines, films, cassettes, CDs etc, all with their own data model. Depending on the design, your API clients may need to discriminate between these models to infer the correct type to build the logic around it.</p>
<p>OpenAPI spec comes with built-in support for unions of any types. GraphQL on the other hand isn’t so useful when it comes to discriminated unions and mixed types. Mixed scalar types are a no go. While GraphQL supports unions, they should all share the same interface, and should not have overlapping fields of varying types — you will have to work around these constraints and it’s not always possible, so you end up with a scalar <code>JSON</code> type, which isn’t that great for type safety.</p>
<p>These limitations are most evident when you work with structured/rich text. If you are working with a Headless CMS that ships a flavour of structured text, e.g. <a href="https://github.com/portabletext/portabletext">PortableText</a> or <a href="https://docs.slatejs.org/concepts/10-serializing#plaintext">Slate</a>, you will need to think of how to represent these content models in your API schema.</p>
<h3 id="filtering-sorting-and-pagination">Filtering, Sorting and Pagination<a aria-hidden="true" class="anchor-heading icon-link" href="#filtering-sorting-and-pagination"></a></h3>
<p>A standard oversight when designing an API is a standardised approach to filtering, sorting and pagination. As we start with a small dataset we fail to foresee the future with millions of records, and neglect these concerns, which later leads to rebuilding the API schema to accommodate the new requirements.</p>
<p>There is no one standard approach to these concerns and different APIs address them in different ways. Take a look at <a href="https://datatracker.ietf.org/doc/html/draft-ietf-scim-api-12#section-3.2.2.2">SCIM</a>, <a href="https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html">OData</a>, <a href="https://portal.ogc.org/files/96288#cql-core">CQL</a> for some ideas.</p>
<p>When it comes to filtering, I draw inspiration from <a href="https://www.prisma.io/docs/reference/api-reference/prisma-client-reference#filter-conditions-and-operators">Prisma.io</a>. They have designed a beautiful approach to querying the database, but their approach can as well be applicable to API design. Because these filters are serialisable, they can be easily integrated with HTTP requests, and will cover a wide range of requirements for filtering large datasets.</p>
<p>Pagination design is often dictated by the underlying data model, as well as the amount of traffic the database receives. Datasets that change often might benefit from cursor-based approach, while others can exist quite happily with an offset approach. Here is <a href="https://ignaciochiazzo.medium.com/paginating-requests-in-apis-d4883d4c1c4c">an interesting article</a> on the subject.</p>
<p>One thing to note here is how we draw a line between <code>GET</code> and <code>POST</code> requests. Rooted in REST and early-day HTTP principles, this dogmatic allocation of <code>GET</code> requests for queries, and <code>POST</code> requests for data updates, make working with large filters a headache. If you look at pros of REST approach, it boasts cacheability, but let’s be honest, what was the last time your relied on browser cache or CDN for your API requests. The idea that using URL query parameters instead of body payload would somehow make the world a better place is frankly outdated. URL serialisation sucks. URL length is limited. So, let’s just dispose of this dogma, and use <code>POST</code> requests with JSON payloads for all API requests. That’s pretty much what GraphQL clients end up doing as they encounter URL query length limitations. Think of it in RPC terms — you are not getting the data, but you are posting a procedure to the server and receive an answer from it.</p>
<h2 id="environment--tooling">Environment &#x26; Tooling<a aria-hidden="true" class="anchor-heading icon-link" href="#environment--tooling"></a></h2>
<p>An API design decision can not be made without taking into account what server technologies will be used to serve it, and what clients will be used to access it.</p>
<p>Because REST has evolved alongside the HTTP protocol, it is based on a set of universal standards. The stack is really quite irrelevant — all server and client technologies are able to communicate over HTTP, and the tooling around orchestrating a REST server is quite rich, regardless what programming language or server infrastructure you choose.</p>
<p>RPC implementations vary. There are various frameworks that bring their own ideas to the table. There is <a href="https://grpc.io/">gRPC</a> that is environment-agnostic, but is quite nuanced with regards to its bi-directional communication and use of Protocol Buffers. There is <a href="https://trpc.io/">tRPC</a> with its full-stack TypeScript implementation that borrows from REST and GraphQL to create one of the most loved API tools. There is <a href="https://zeroc.com/">ZeroC</a> and <a href="https://unum-cloud.github.io/ucall/">UCall</a> and many others. Ultimately, nothing is stopping you from using REST tooling to build RPC APIs — get rid of the brain fart that the REST is and just give all your queries and commands proper names and send them over the wire using standard HTTP tooling. You can namespace your procedures with URL segments, similar to REST, but you don’t have to bake in resource IDs into the URL structure and deal with complexity of HTTP methods.</p>
<p>When it comes to GraphQL, the idea behind it is brilliantly simple:</p>
<ul>
<li>each client defines the data it needs using a query language designed specifically for expressing graph nodes in a very simple form</li>
<li>the server parses the query, and passes each requested field through a resolver that has access to the root node and can access various data stores and/or external services to compute the return value</li>
</ul>
<p>The problem with introducing a new language, however, is that it needs a lexer, which can parse the query into a more standard form that can be digested by various server technologies. As most API clients live in the browser, GraphQL tooling evolved around the needs of front-end applications, in a JavaScript ecosystem with browser compatibility in mind. While it makes GraphQL a very pleasant experience on the front-end, the tooling around server to server communication is very much lacking — from bootstrapping a client and figuring out caching and other nuances like fragmentation to writing and parsing queries that can be used by the said client. Even though GraphQL is designed for standard HTTP protocol, the problem is that GraphQL in itself is not standard and might not be the best choice for a versatile API design.</p>
<h2 id="observability--scalability">Observability &#x26; Scalability<a aria-hidden="true" class="anchor-heading icon-link" href="#observability--scalability"></a></h2>
<p>API health and performance are important metrics that allow us to make conclusions about our API design. Ability to observe these metrics continuously and react to latency and performance issues, as well as runtime errors, should be a motivating factor in our decision-making.</p>
<p>While single point of entry APIs offer simplicity, they are quite a headache in terms of observability and scalability. Figuring out the health of your GraphQL or JSON-RPC APIs is quite a challenge without extra instrumentation. While REST is most likely to provide you with detailed logs of what resources were accessed, how many times, and how long it took to process the request, getting the same stats for APIs that have a single endpoint is quite impossible. Instead you end up with millions of log entries for the same endpoint, and unless you make an effort to provision extra logging with operation/method names, you would have no idea what those requests were. Things are even worse with GraphQL that doesn’t believe in HTTP status codes, so all requests end up with 200 status code, so tracing and debugging really turns into adventure every single time.</p>
<p>Using a single point of entry is also a DevOps problem. Depending on the environment, you may want to provision more resources for API endpoints that have higher latency or require more computational resources, but instead you are forced to scale the entire API server with an entirety of its dependencies and the impact of its memory footprint.</p>
<p>A single point of entry also makes it difficult to rip the benefits of reverse proxies that can reroute specific requests, help with caching, observability, load balancing, encryption, access control and other concerns.</p>
<h2 id="error-handling">Error Handling<a aria-hidden="true" class="anchor-heading icon-link" href="#error-handling"></a></h2>
<p>HTTP codes are too generic. As I <a href="https://medium.com/itnext/graceful-error-handling-in-rest-driven-web-applications-d4209b4937aa">wrote some years ago</a>, APIs should be able to communicate problems to the clients, and subsequently the users. Whatever API design you chose, make sure you build a standardised approach to communicating errors to the client and contextualising them.</p>
<p>GraphQL’s error handling is a blessing and a curse. On one hand, it is very verbose, and can report errors from individual field resolvers. On the other hand, it makes debugging and error handling a pain — by merging success and error states into a single response it makes it so much harder for the clients to differentiate between network errors, invariants, schema validation issues, and actual success responses. According to the specification, partial success responses are in fact possible even if individual resolvers report errors, so it is quite cumbersome to try an reconcile null field values with errors (unless the GraphQL server prevents partial responses, as is the case with Apollo). So, give some consideration to how your server deals with errors, and how your clients are going to make sense of them.</p>
<p>As mentioned earlier, you may want to instrument additional tooling to help you with tracing errors in systems that have a single point of entry.</p>
<h2 id="versioning">Versioning<a aria-hidden="true" class="anchor-heading icon-link" href="#versioning"></a></h2>
<p>Whether or not your API requires versioning is largely a usage problem. If your API is consumed in house and you are able to evolve APIs while keeping clients up to date, it might not be an issue. If you are distributing your APIs externally, you might want to consider some form of versioning.</p>
<p>If your API exists largely as a proxy to your database model, versioning can be somewhat of an acute problem. Once the database schema changes, there isn’t really a way to maintain backwards compatibility, especially if your API is autogenerated from database models. So, give it some thought, when chosing your tooling.</p>
<p>As mentioned earlier, RPC could be an interesting option for decoupling the storage model from the API model, giving you more flexibility. You can evolve your API without necessarily versioning it by introducing new procedures and deprecating the old ones. GraphQL tends to brush off versioning, leaning into the same approach — add new fields and deprecate the old ones. The difference is that however with RPC you have more control over request routing and can still introduce versioning. With GraphQL your versioning capabilities are limited — you may need to spin up a different container that serves the older version of the graph. Besides you want to get rid of dead and outdated code from time to time, so some way of communicating breaking changes to the clients would have been a plus.</p>
<h2 id="access-controls">Access Controls<a aria-hidden="true" class="anchor-heading icon-link" href="#access-controls"></a></h2>
<p>You may want to invest some time giving access requirements a thought. Whether or not you require route/procedure level, resource level, or field level access can have a great impact on the your choice of API design.</p>
<p>Should resource-level checks be sufficient, you still need to consider, whether representation of the resource is identical for all users. Should you need higher granularity in access controls, you may need to find a way to communicate these requirements to the clients. Whatever route you take on the server (preventing access to the whole resource, or nulling the field value, or communicating an error on field access), it will be the responsibility of the client to deal with the fallout.</p>
<p>GraphQL is quite handy if you need field level access, though it does lack SDL level standars for documenting access requirements (aside from non-standard directives). REST API might not be an ideal solution for applications that need high levels granularity, as it prevents you from branching resource representation. RPC might offer some flexibility in designing the API with your particular requirements in mind.</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#conclusions" title="Conclusions">Conclusions</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#schema-definition" title="Schema Definition">Schema Definition</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#data-model" title="Data Model">Data Model</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#object-relational-complexity" title="Object-relational complexity">Object-relational complexity</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#updating-data" title="Updating Data">Updating Data</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#data-types" title="Data Types">Data Types</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#filtering-sorting-and-pagination" title="Filtering, Sorting and Pagination">Filtering, Sorting and Pagination</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#environment--tooling" title="Environment &amp; Tooling">Environment &amp; Tooling</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#observability--scalability" title="Observability &amp; Scalability">Observability &amp; Scalability</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#error-handling" title="Error Handling">Error Handling</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#versioning" title="Versioning">Versioning</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#access-controls" title="Access Controls">Access Controls</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"6h87a35ua3cfe1urbwxm13z","title":"REST, GraphQL or RPC — A Decision Paralysis","desc":"","updated":1700030407664,"created":1700030307444,"custom":{},"fname":"dev.back-end.rest-graphql-or-rpc-a-decision-paralysis","type":"note","vault":{"fsPath":"vault"},"contentHash":"f896c3b7f67e5948ac1972ccbc16eb09","links":[],"anchors":{"conclusions":{"type":"header","text":"Conclusions","value":"conclusions","line":12,"column":0,"depth":2},"schema-definition":{"type":"header","text":"Schema Definition","value":"schema-definition","line":57,"column":0,"depth":2},"data-model":{"type":"header","text":"Data Model","value":"data-model","line":97,"column":0,"depth":2},"object-relational-complexity":{"type":"header","text":"Object-relational complexity","value":"object-relational-complexity","line":101,"column":0,"depth":3},"updating-data":{"type":"header","text":"Updating Data","value":"updating-data","line":123,"column":0,"depth":3},"data-types":{"type":"header","text":"Data Types","value":"data-types","line":145,"column":0,"depth":3},"filtering-sorting-and-pagination":{"type":"header","text":"Filtering, Sorting and Pagination","value":"filtering-sorting-and-pagination","line":168,"column":0,"depth":3},"environment--tooling":{"type":"header","text":"Environment \u0026 Tooling","value":"environment--tooling","line":180,"column":0,"depth":2},"observability--scalability":{"type":"header","text":"Observability \u0026 Scalability","value":"observability--scalability","line":195,"column":0,"depth":2},"error-handling":{"type":"header","text":"Error Handling","value":"error-handling","line":205,"column":0,"depth":2},"versioning":{"type":"header","text":"Versioning","value":"versioning","line":213,"column":0,"depth":2},"access-controls":{"type":"header","text":"Access Controls","value":"access-controls","line":221,"column":0,"depth":2}},"children":[],"parent":"6w36dgapan7eummy1q6jpx1","data":{}},"body":"\u003ch1 id=\"rest-graphql-or-rpc--a-decision-paralysis\"\u003eREST, GraphQL or RPC — A Decision Paralysis\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#rest-graphql-or-rpc--a-decision-paralysis\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://itnext.io/rest-graphql-or-rpc-a-decision-paralysis-0acaa84b5a27\"\u003ehttps://itnext.io/rest-graphql-or-rpc-a-decision-paralysis-0acaa84b5a27\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e...\u003c/p\u003e\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#conclusions\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAPI design is a difficult choice that should be driven by a product discovery phase, where you understand the innate nature of your application, and other actors in the system.\u003c/p\u003e\n\u003cp\u003eFinger to the wind.\u003c/p\u003e\n\u003cp\u003eUse \u003cstrong\u003eREST\u003c/strong\u003e if:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eyou are building an API to interact with your database using CRUD operations\u003c/li\u003e\n\u003cli\u003eyour data model is not heavy on relations\u003c/li\u003e\n\u003cli\u003eyou have a limited number of user roles and access requirements\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUse \u003cstrong\u003eGraphQL\u003c/strong\u003e If:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eyou are building a gateway to connect multiple data sources or services\u003c/li\u003e\n\u003cli\u003eyour data model is heavy on relations and represents a graph\u003c/li\u003e\n\u003cli\u003eyou have high-granularity access requirements\u003c/li\u003e\n\u003cli\u003eyou are building an API targeted mostly at front-end applications\u003c/li\u003e\n\u003cli\u003eyou have a large number of API clients with varying data requirements\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUse \u003cstrong\u003eRPC\u003c/strong\u003e if:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eyou want to be flexible in naming and routing conventions\u003c/li\u003e\n\u003cli\u003eyou want to build semantic, easy to read APIs\u003c/li\u003e\n\u003cli\u003eyou need to address diverging, volatile, or complex use cases\u003c/li\u003e\n\u003cli\u003eyour services interact outside of the HTTP protocol\u003c/li\u003e\n\u003cli\u003eyou want to build a robust future-proof API decoupled from implementation and data storage concerns\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you ask for my personal opinion, I think the future is RPC. I love GraphQL for front-end development, but I don’t think it’s an ideal solution for cross-service communication, and once you tip your toes into it it bites your foot off, and makes things so much harder to reason about. By all means, use GraphQL as a proxy for your read-model, but don’t bring it into a mix as part of your internal services. And as for the REST, let it rest.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eEver since AJAX capabilities landed in our browsers some 20+ years ago, developers around the world had been busy pushing these technologies to their limits, engineering creative ways of challenging the foundations of the original internet, and transforming it from a web of static pages to a web of dynamic data flows.\u003c/p\u003e\n\u003cp\u003eApplication programming interfaces (APIs) that power all this data exchange have gone through many iterations, and it’s unsurprising that in 2023 many development teams struggle with decisions about the design and implementation of their APIs. With a variety of programming languages, transfer protocols, and infrastructure architectures, finding a way to define reliable contracts for data transfer, and more so to implement and maintain them in the face of changing requirements, is no easy feat.\u003c/p\u003e\n\u003cp\u003eDealing with APIs on a daily basis, and observing the discussions around their design in my professional circles, it appeared to me it would be useful to put down some of my thoughts in writing. With \u003cstrong\u003eREST\u003c/strong\u003e, \u003cstrong\u003eGraphQL\u003c/strong\u003e and \u003cstrong\u003eRPC\u003c/strong\u003e being the most commonly discussed design patterns, I will focus on those and summarise some of my thoughts and experiences. Having worked with all 3 of them, I realise there is no silver bullet, and I think we are a long way away from having a common ground, similar to W3C standards, which helped bring sense and structure to browser technologies.\u003c/p\u003e\n\u003cp\u003eBefore we start, let me clarify some of the assumptions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIn a way, treating these 3 paradigms as equals is like comparing apples to oranges. After all, GraphQL is just a query language specification and could be instrumented in a way that is very similar to an RPC gateway. On the query side of things, it is also very similar to REST with it’s focus on resources, and in fact nothing prevents you from sending GraphQL documents as part of your REST calls, and use field resolvers as part of your controller implementation. So, for the sake of this article, I will be thinking of GraphQL as an implementation of the specification, i.e. a server akin Apollo capable of receiving and serving data over HTTP.\u003c/li\u003e\n\u003cli\u003eSpeaking of RPC, I am not referring to any specific implementation, such as \u003ca href=\"https://grpc.io/\"\u003egRPC\u003c/a\u003e, but rather a paradigm of using procedure calls instead of operating on resources with unique addresses in the network, as is common in REST. Even though I intend to draw parallels with other transfer protocols, for the purposes of this article, API will stand to mean data transfer over HTTP. I will put aside networking considerations to focus on actual API design rather than mechanics of data moving over the wire. As such, it’s best to think of an RPC implementation similar to \u003ca href=\"https://en.wikipedia.org/wiki/JSON-RPC\"\u003eJSON-RPC\u003c/a\u003e or \u003ca href=\"https://trpc.io/\"\u003etRPC\u003c/a\u003e rather than gRPC (with its use of HTTP/2 for bidirectional streaming of binary data).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet’s look at the various aspects of API design that need to be considered when making a decision and see how the 3 patterns hold up against these requirements.\u003c/p\u003e\n\u003ch2 id=\"schema-definition\"\u003eSchema Definition\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#schema-definition\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAbility to express APIs in abstract terms using a schema definition language (SDL) is an important consideration to make when choosing our API design. SDLs allow us to detach our design from implementation details, focus on our data model, and express a contract in a way that is interoperable throughout a variety of clients that could be interacting with our API in the future. SDLs make it easier to build tooling to automate some of otherwise painstakingly manual processes, e.g. by generating client SDKs or types for our data transfer objects.\u003c/p\u003e\n\u003cp\u003eWorking without an SDL is a deal breaker, as you end up having to maintain a set of documentation in some random format that will be difficult to keep up to date, evolve and communicate to API clients.\u003c/p\u003e\n\u003cp\u003eWhen evaluating an SDL consider what your development workflow is going to look like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSchema-first approach\u003c/strong\u003e is practical for larger teams that deal with organisational complexity. Various teams can work together on defining the contract before moving forward with the actual implementation. This approach requires more time in planning and communication, but as a result allows the teams to work independently and in parallel, not having to deal with varying implementation schedules. This also results in better code quality as such a development flow requires mocks and tests to be feasible, perhaps even pushing development towards TDD. An added benefit of schema-first approach is that it’s agnostic to actual implementation details — underlying technology can always be swapped without affecting the workflow or impacting the clients. Using this approach however does require that everyone learn to speak a new language, so the syntax and usability are quite important considerations.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCode-first approach\u003c/strong\u003e is more practical for smaller teams that want to maintain agility, while having some level of contractual safety between clients and benefiting from the tooling within the SDL ecosystem. Code-first approach is tightly coupled with the tooling chosen for the development, and it comes with a risk of a costly effort that would be required to switch to a schema-first approach some time in the future, e.g. when the tools are no longer maintained by their authors, or the growing organisational complexity prevents the team from collaborating efficiently.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGraphQL\u003c/strong\u003e in its essence is an SDL specification, which makes it a good candidate for expressing APIs. It has a built-in support for defining procedures (queries and mutations), input and response object types.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eREST\u003c/strong\u003e and \u003cstrong\u003eRPC\u003c/strong\u003e are abstract concepts and do not have a standard SDL, but there are several general purpose frameworks that can be used to describe HTTP-based APIs.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.openapis.org/\"\u003eOpenAPI\u003c/a\u003e (formerly Swagger) is the most common SDL specification that allows API authors to express HTTP requests and responses in YAML or JSON. OpenAPI ecosystem features a number of \u003ca href=\"https://openapi.tools/\"\u003ecool development tools\u003c/a\u003e\u003ca href=\"https://openapi-generator.tech/\"\u003e.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.asyncapi.com/\"\u003eAsyncAPI\u003c/a\u003e is another option to consider for \u003cstrong\u003eRPC\u003c/strong\u003e and other systems that focus on exchanging messages rather than resources. Its syntax is similar to OpenAPI, but it can better express the needs that go beyond the HTTP protocol.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAPIs expressed through SDLs also help us address type safety and serialisation concerns, making contracts enforceable throughout our stack. There are several serialisation and validation patterns that we can build on top of our specs.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://protobuf.dev/\"\u003eProtocol Buffers\u003c/a\u003e is a platform and language neutral mechanism to serialize structured data. Models expressed in OpenAPI can be exported into protobuf format with \u003ca href=\"https://github.com/google/gnostic\"\u003egnostic\u003c/a\u003e making it easier to reliably exchange data between the server and the clients.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://json-schema.org/\"\u003eJSON-Schema\u003c/a\u003e is another standard for expressing serialisable data, as well as validation requirements for such data. OpenAPI specs could be converted to JSON-Schema using \u003ca href=\"https://github.com/openapi-contrib/openapi-schema-to-json-schema\"\u003econverters\u003c/a\u003e. It’s an interesting approach if you want to validate your data at various stages of the request lifecycle.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://modelina.org/\"\u003eModelina\u003c/a\u003e and other tools can be used to generate models from OpenAPI, AsyncAPI, and JSON-Schema.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen defining your schema, you may also want to explore existing conventions that ensure that your API design is as compatible as possible with other systems you may want to integrate with in the future.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.jsonrpc.org/specification\"\u003eJSON-RPC\u003c/a\u003e is a convention for structuring your RPC messages.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloudevents.io/\"\u003ecloudevents\u003c/a\u003e is a broader attempt to find a common language when documenting events in various formats and can be useful for various RPC considerations.\u003c/li\u003e\n\u003cli\u003eConsider various filtering, sorting, and pagination conventions that already exist, e.g. \u003ca href=\"https://datatracker.ietf.org/doc/html/draft-ietf-scim-api-12#section-3.2.2.2\"\u003eSCIM\u003c/a\u003e, \u003ca href=\"https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html\"\u003eOData\u003c/a\u003e, \u003ca href=\"https://portal.ogc.org/files/96288#cql-core\"\u003eCQL\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOther things to keep in mind when dealing with SDL:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edoes it allow you to describe your resources in a manner that would allow any client to easily understand the logic, resources and relationships\u003c/li\u003e\n\u003cli\u003edoes it allow you to express authentication requirements and accessibility of resources based on client roles/permissions\u003c/li\u003e\n\u003cli\u003edoes it support all the data types (scalars, enums and complex unions) that your application would require\u003c/li\u003e\n\u003cli\u003edoes it have the tooling necessary to serialise data in a format suitable for the HTTP (e.g. URL query and JSON) and other protocols\u003c/li\u003e\n\u003cli\u003edoes it allow you to express your data model, resources and procedures beyond the HTTP protocol, i.e. you would prefer to use the same SDL to describe data transfer in other communication protocols (such message queues, or even command line interfaces)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe great thing about the SDL is that it can serve as documentation for your API, both internally and externally. Making the schema accessible to the clients makes it possible for them to introspect the schema to discover the available resources within your API. There are wonderful GUI playgrounds that allow you to explore and interact with GraphQL (e.g. \u003ca href=\"https://studio.apollographql.com/sandbox/explorer/?\"\u003eApollo Studio)\u003c/a\u003e and OpenAPI (e.g. \u003ca href=\"https://swagger.io/tools/swagger-ui/\"\u003eSwagger UI)\u003c/a\u003e schemas. And of course they integrate well with our beloved \u003ca href=\"https://www.postman.com/\"\u003ePostman\u003c/a\u003e, allowing us to create collections from schema definitions, and even export collections into some of the common SDLs.\u003c/p\u003e\n\u003ch2 id=\"data-model\"\u003eData Model\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#data-model\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eA decision about API design can not be made without a good understanding of the specifics and complexity of the underlying data model, and the needs of the clients in accessing the resources.\u003c/p\u003e\n\u003ch3 id=\"object-relational-complexity\"\u003eObject-relational complexity\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#object-relational-complexity\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eRelational model complexity is a major concern in API design, as traversing complex relational models via an API can be difficult. Relations that exist between your domain entities could be a deciding factor in favour or against a specific approach.\u003c/p\u003e\n\u003cp\u003eIn a standard \u003cstrong\u003eREST\u003c/strong\u003e implementation, each resource has it’s own unique network address. You can access a resource with a straightforward \u003ccode\u003eGET\u003c/code\u003e request, e.g. \u003ccode\u003eGET /users/1\u003c/code\u003e. Things get murkier when you try to represent collections and relations, e.g. to get a list of user’s friends you would go to \u003ccode\u003eGET /users/1/friends\u003c/code\u003e, then however it gets ambiguous if you want to get a specific friend: it’s quite unclear whether you access it via \u003ccode\u003eGET /users/1/friends/friendship-1\u003c/code\u003e or \u003ccode\u003eGET /friendships/friendship-1\u003c/code\u003e or \u003ccode\u003eGET /users/2\u003c/code\u003e. It is also unclear where you should put your nested documents, e.g. should a user address be returned as part of the user resource, or should it be it’s own resource living on the \u003ccode\u003eGET /user/1/addresses\u003c/code\u003e edge. Such ambiguity plaques development teams with endless decisions about domain boundaries and their representation in the \u003ccode\u003eREST\u003c/code\u003e graph. Compromises are made between domain model uniformity and performance, making it hard for API clients to know exactly where to look.\u003c/p\u003e\n\u003cp\u003eAside from that, \u003cstrong\u003eREST\u003c/strong\u003e places the burden of traversing the graph on the API client. If you ever tried to resolve a list of second-degree relations, you know what a nightmare it is, with a cascade of hundreds, if not thousands, of API requests. On top of it, if you are dealing with bidirectional relations, you have to account for node repetition as well as circularity, making it the responsibility of the client to implement some form of caching and deduplication to avoid infinite loops.\u003c/p\u003e\n\u003cp\u003eIn order to alleviate some of this pain, REST API authors resort to creative solutions (a.k.a hacks) that allow relations to be resolved when a resource is requested. For example, Stripe API uses \u003ccode\u003eexpand\u003c/code\u003e parameter. This does address the traversal concerns, but leads to non-deterministic response types, which again have to be dealt with by the API client, forcing it to do lots of type juggling and coercion.\u003c/p\u003e\n\u003cp\u003eWith the emergence of social networks and their complex social graphs, \u003cstrong\u003eREST\u003c/strong\u003e had become quite unmanageable. \u003cstrong\u003eGraphQL\u003c/strong\u003e, as the name suggests, was created by Facebook as a way of traversing a complex social graph, representing an entirety of human society with its six degrees of separation. Facebook was trying to solve a problem inherent to social complexity with a multitude of actors and multidirectional relationships between them, and you should keep that in mind when evaluating whether or not your API design might benefit from it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGraphQL\u003c/strong\u003e is brilliant in its simplicity. By letting the client specify precisely what data it needs and fetch it in a single request, it shifts the responsibility of traversing and stitching the graph to the server. Embedding types and relations within the schema design, it can use field resolvers to extract the necessary data and traverse the query of any complexity. This doesn’t always come cheap, and leads to additional problems and tooling (e.g. data loaders to address the n+1 problems), but allows the server to use any number of data stores to aggregate properties and relations, making API clients agnostic to such implementation details.\u003c/p\u003e\n\u003cp\u003eAt their core, both \u003cstrong\u003eREST\u003c/strong\u003e and \u003cstrong\u003eGraphQL\u003c/strong\u003e are focused on resources and their representation. This is usually tightly coupled with how we represent entities in our databases. In a sense, these entities always exist in their platonic form, regardless of who the observer is. This can be problematic in certain systems, where not all clients are created equal. Having a static schema or a graph that doesn’t account for use cases and requester roles can lead to all kind of issues in the design. Presume our employee model has a salary property which can only be accessed by an accountant role — how do we represent and implement this in our API design? Do we make the property optional? If it’s optional how do we know what the lack of a value represents (there is no data in the storage or there is no accessible data for this requester). Do we create another edge in REST that throws an HTTP error? Do we send null or an error in GraphQL? This ambiguity can lead to additional complexity and uncertainty on the client-side, and should be factored in at the API design stage.\u003c/p\u003e\n\u003cp\u003eResource-centric approach to our API design tends to make us think about our APIs in terms of our data storage model. While it’s justified in some cases, it can be problematic if we couple our API too tightly with our databases. All too often, we reuse our ORM models as our API models, and rely on tools such as \u003ca href=\"https://hasura.io/\"\u003eHasura\u003c/a\u003e, \u003ca href=\"https://www.prisma.io/graphql\"\u003ePrisma GraphQL\u003c/a\u003e, \u003ca href=\"https://postgrest.org/en/stable/index.html\"\u003ePostgREST\u003c/a\u003e, and many others to interface directly with our database via API. These tools can save a great deal of time, but they blur the lines between the architectural layers, and make our API clients susceptible to breaking changes. Depending on how and where the clients are used, such an approach poses a risk to data integrity, and requires a solution to rectifying race conditions of running data and schema migrations, generating and tagging new SDK versions, and propagating the changes to all the clients. API versioning becomes an issue if data storage engine does not support any versioning. Aside from that complex access controls become a pain point requiring us to hook into these tools to manage roles and permissions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRPC\u003c/strong\u003e on the other hand is unopinionated about resources and their representation. It allows API authors to move away from trying to reproduce the data model and instead focus on use cases — procedures can be tailored towards specific needs of the clients and actors in the system. Unlike REST, where the client hardly has any say in what it gets, and GraphQL, where the client can indiscriminately request as much data as it wants (vis Cambridge Analytica), RPC can accommodate various requirements arising from different API applications. RPC servers can be instrumented in a way that rips the best from all worlds — from resolvers to untangle the graph to routing middleware to manage the request/response flow to isomorphic route and query level permission controls. RPC API can be built around immutable contracts and evolve over time to address changing requirements in a backward compatible manner. RPC allows us to separate API concerns from data persistence/storage concerns and other implementation details, leading to a more future-proof API design that doesn’t have to change every time the data schema changes.\u003c/p\u003e\n\u003cp\u003eWhile GraphQL is a good solution for a larger API surface, where the needs of the clients can not be well predicted, RPC could be a good alternative for smaller projects — essentially, instead of making the client write queries and enumerate all fields that have to be returned to the client, the response type could be explicitly defined as part of the RPC schema. In essence, the same could be said about REST, but that goes against the nature of the paradigm that dictates that each resource should be available at its own network locator.\u003c/p\u003e\n\u003ch3 id=\"updating-data\"\u003eUpdating Data\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#updating-data\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eLet’s be honest, when it comes to updating data via \u003cstrong\u003eREST\u003c/strong\u003e, it’s a pain in the ass. Different HTTP methods that are supposed to make things transparent, instead raise all kinds of questions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ewhat method should be used to soft-delete or archive a resource? Should it be a \u003ccode\u003eDELETE\u003c/code\u003e request with some flag, or \u003ccode\u003ePOST\u003c/code\u003e request with an action name (in effect making it an RPC request?), or should it be \u003ccode\u003ePATCH\u003c/code\u003e request updating the \u003ccode\u003edeleted\u003c/code\u003e or \u003ccode\u003earchived\u003c/code\u003e property of an object?\u003c/li\u003e\n\u003cli\u003ewhat about partial updates? Should we use \u003ccode\u003ePUT\u003c/code\u003e or \u003ccode\u003ePATCH\u003c/code\u003e? What about updates that have specific side effects, e.g. changing account email? Should they still go into a \u003ccode\u003ePATCH\u003c/code\u003e request, or be sent as \u003ccode\u003ePOST\u003c/code\u003e with an action name?\u003c/li\u003e\n\u003cli\u003ewhat about granularity of partial updates where certain actors are only allowed to make certain changes? How do we split and describe this logic in our REST API design?\u003c/li\u003e\n\u003cli\u003ewhat about logic that does not really have any resources attached to it? Where should, for example, the various steps of the password reset flow live? Should they be in the root of the REST API or some edge of the API?\u003c/li\u003e\n\u003cli\u003ewhat happens with nested documents? What if those nested updates require transactional safety?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe fact is, whenever you build an SDK around the REST API, you end up using procedure calls to describe the various actions that it performs, e.g. \u003ccode\u003edeleteUser()\u003c/code\u003e or \u003ccode\u003ecapturePayment()\u003c/code\u003e rather than operating with get/post/put/patch/delete methods directly. My personal opinion is that REST is no longer suitable for modern day application design — requirements are far too complex to embed them into opinionated resource-centric API design.\u003c/p\u003e\n\u003cp\u003eProcedure calls are more suited for the complexity of modern day applications, allowing API designers to address specific use cases rather than trying to accommodate every possible scenario in a limited set of RESTful endpoints. Changing user password, is not the same as changing user email, or opting a user into a newsletter. All three may be part of the same resource, but hardly ever would you update a password and subscribe a user to the newsletter in the same request. All of these procedures have distinct side effects, and may require custom validation and permission checks.\u003c/p\u003e\n\u003cp\u003eRPC fits in nicely with CQRS principles. You can think of procedure calls as queries and commands, which make transport protocol considerations irrelevant. HTTP controllers receive and validate payloads, and then pass them on to query and command busses. This makes it easy to reuse procedure calls for any other transport — from command line to message queue to chatbots to whatever else that can receive a procedure call.\u003c/p\u003e\n\u003cp\u003eGraphQL mutations are in fact RPC. Aside from a terrible name that makes me think of unpredictable gene mutations and lockdowns, it is very flexible. The question however remains, what is to be considered a mutation — sending emails or downloading documents are procedures that don’t really mutate anything, so should they be part of the graph at all?\u003c/p\u003e\n\u003cp\u003eAnother important thing to consider in the context of API design is whether or not data updates are synchronous or asynchronous. In distributed systems, synchronicity might not always be an option, so you should plan ahead to figure out a way to communicate persistence events to the API client, and how those are going to be reflected in API schema and documentation. Where your clients live will determine what technology you can use for that: webhooks, WebSockets, \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events\"\u003eServer-Side Events\u003c/a\u003e, push notifications or something else. Here is an \u003ca href=\"https://github.com/wso2/reference-architecture/blob/master/event-driven-api-architecture.md\"\u003einteresting read\u003c/a\u003e on the subject of asynchronous event-driven APIs.\u003c/p\u003e\n\u003cp\u003eSpeaking of distributed systems, we should also consider what implications using GraphQL might have. On one hand GraphQL is well suited for aggregating data from various sources and can be used as a gateway to your microservices. On the other hand, however, mixing GraphQL with other API designs across the stack (or even having multiple GraphQL servers) might become unwieldy. You will need to think about ways to stitch or federate your servers to ensure the integrity of the graph.\u003c/p\u003e\n\u003ch3 id=\"data-types\"\u003eData Types\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#data-types\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWhen it comes to API design there are a few considerations to make with regards to types of serialisable data that the API is going to transmit:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ehow are you going to communicate serialisation requirements for custom scalar types\u003c/li\u003e\n\u003cli\u003ehow are you going to express mixed types and \u003ccode\u003eoneOf\u003c/code\u003e logic, and how will you discriminate such union types\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNot all scalars are created equal. Having an API schema littered with \u003ccode\u003estring\u003c/code\u003e and \u003ccode\u003enumber\u003c/code\u003e types is nothing short of a nightmare. A contract should be explicit about the requirements — API clients should not be second guessing what \u003ccode\u003e{ contact: string }\u003c/code\u003e means, especially if there is validation attached to that property:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003euse string identities, e.g. \u003ccode\u003eUUID\u003c/code\u003e, \u003ccode\u003eEmail\u003c/code\u003e, \u003ccode\u003eIPv6\u003c/code\u003e, \u003ccode\u003eISBN\u003c/code\u003e etc, and be explicit about custom string patterns\u003c/li\u003e\n\u003cli\u003euse integer identities, e.g. \u003ccode\u003eYear\u003c/code\u003e, \u003ccode\u003eTimestamp\u003c/code\u003e etc, and be explicit about ranges for custom integers\u003c/li\u003e\n\u003cli\u003euse float identities, e.g. \u003ccode\u003eLat\u003c/code\u003e, \u003ccode\u003eLong\u003c/code\u003e etc, and be explicit about ranges and precision for custom floats\u003c/li\u003e\n\u003cli\u003euse enums to express finite lists of scalar options\u003c/li\u003e\n\u003cli\u003eadopt a single date format, i.e. ISO Date string or Unix timestamp\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBoth GraphQL and OpenAPI support scalar type refinements, but they leave serialisation concerns to the servers and clients, so be sure to account for custom scalar type serialisation in your implementation. GraphQL, unlike OpenAPI, does not offer a native approach to documenting validation requirements at the schema-level, so be ready for some runtime error handling. There are some attempts to use non-standard directives to express \u003ca href=\"https://github.com/confuser/graphql-constraint-directive/blob/master/README.md\"\u003evalidation constraints\u003c/a\u003e and \u003ca href=\"https://github.com/Saeris/graphql-directives#formatdate\"\u003eformatting requirements\u003c/a\u003e, but you will need to instrument them yourself.\u003c/p\u003e\n\u003cp\u003eAnother important aspect of modelling data in API design is mixed types. Presume your API is going to serve a catalogue of items available in a library. You may have to deal with books, magazines, films, cassettes, CDs etc, all with their own data model. Depending on the design, your API clients may need to discriminate between these models to infer the correct type to build the logic around it.\u003c/p\u003e\n\u003cp\u003eOpenAPI spec comes with built-in support for unions of any types. GraphQL on the other hand isn’t so useful when it comes to discriminated unions and mixed types. Mixed scalar types are a no go. While GraphQL supports unions, they should all share the same interface, and should not have overlapping fields of varying types — you will have to work around these constraints and it’s not always possible, so you end up with a scalar \u003ccode\u003eJSON\u003c/code\u003e type, which isn’t that great for type safety.\u003c/p\u003e\n\u003cp\u003eThese limitations are most evident when you work with structured/rich text. If you are working with a Headless CMS that ships a flavour of structured text, e.g. \u003ca href=\"https://github.com/portabletext/portabletext\"\u003ePortableText\u003c/a\u003e or \u003ca href=\"https://docs.slatejs.org/concepts/10-serializing#plaintext\"\u003eSlate\u003c/a\u003e, you will need to think of how to represent these content models in your API schema.\u003c/p\u003e\n\u003ch3 id=\"filtering-sorting-and-pagination\"\u003eFiltering, Sorting and Pagination\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#filtering-sorting-and-pagination\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eA standard oversight when designing an API is a standardised approach to filtering, sorting and pagination. As we start with a small dataset we fail to foresee the future with millions of records, and neglect these concerns, which later leads to rebuilding the API schema to accommodate the new requirements.\u003c/p\u003e\n\u003cp\u003eThere is no one standard approach to these concerns and different APIs address them in different ways. Take a look at \u003ca href=\"https://datatracker.ietf.org/doc/html/draft-ietf-scim-api-12#section-3.2.2.2\"\u003eSCIM\u003c/a\u003e, \u003ca href=\"https://docs.oasis-open.org/odata/odata/v4.01/odata-v4.01-part2-url-conventions.html\"\u003eOData\u003c/a\u003e, \u003ca href=\"https://portal.ogc.org/files/96288#cql-core\"\u003eCQL\u003c/a\u003e for some ideas.\u003c/p\u003e\n\u003cp\u003eWhen it comes to filtering, I draw inspiration from \u003ca href=\"https://www.prisma.io/docs/reference/api-reference/prisma-client-reference#filter-conditions-and-operators\"\u003ePrisma.io\u003c/a\u003e. They have designed a beautiful approach to querying the database, but their approach can as well be applicable to API design. Because these filters are serialisable, they can be easily integrated with HTTP requests, and will cover a wide range of requirements for filtering large datasets.\u003c/p\u003e\n\u003cp\u003ePagination design is often dictated by the underlying data model, as well as the amount of traffic the database receives. Datasets that change often might benefit from cursor-based approach, while others can exist quite happily with an offset approach. Here is \u003ca href=\"https://ignaciochiazzo.medium.com/paginating-requests-in-apis-d4883d4c1c4c\"\u003ean interesting article\u003c/a\u003e on the subject.\u003c/p\u003e\n\u003cp\u003eOne thing to note here is how we draw a line between \u003ccode\u003eGET\u003c/code\u003e and \u003ccode\u003ePOST\u003c/code\u003e requests. Rooted in REST and early-day HTTP principles, this dogmatic allocation of \u003ccode\u003eGET\u003c/code\u003e requests for queries, and \u003ccode\u003ePOST\u003c/code\u003e requests for data updates, make working with large filters a headache. If you look at pros of REST approach, it boasts cacheability, but let’s be honest, what was the last time your relied on browser cache or CDN for your API requests. The idea that using URL query parameters instead of body payload would somehow make the world a better place is frankly outdated. URL serialisation sucks. URL length is limited. So, let’s just dispose of this dogma, and use \u003ccode\u003ePOST\u003c/code\u003e requests with JSON payloads for all API requests. That’s pretty much what GraphQL clients end up doing as they encounter URL query length limitations. Think of it in RPC terms — you are not getting the data, but you are posting a procedure to the server and receive an answer from it.\u003c/p\u003e\n\u003ch2 id=\"environment--tooling\"\u003eEnvironment \u0026#x26; Tooling\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#environment--tooling\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAn API design decision can not be made without taking into account what server technologies will be used to serve it, and what clients will be used to access it.\u003c/p\u003e\n\u003cp\u003eBecause REST has evolved alongside the HTTP protocol, it is based on a set of universal standards. The stack is really quite irrelevant — all server and client technologies are able to communicate over HTTP, and the tooling around orchestrating a REST server is quite rich, regardless what programming language or server infrastructure you choose.\u003c/p\u003e\n\u003cp\u003eRPC implementations vary. There are various frameworks that bring their own ideas to the table. There is \u003ca href=\"https://grpc.io/\"\u003egRPC\u003c/a\u003e that is environment-agnostic, but is quite nuanced with regards to its bi-directional communication and use of Protocol Buffers. There is \u003ca href=\"https://trpc.io/\"\u003etRPC\u003c/a\u003e with its full-stack TypeScript implementation that borrows from REST and GraphQL to create one of the most loved API tools. There is \u003ca href=\"https://zeroc.com/\"\u003eZeroC\u003c/a\u003e and \u003ca href=\"https://unum-cloud.github.io/ucall/\"\u003eUCall\u003c/a\u003e and many others. Ultimately, nothing is stopping you from using REST tooling to build RPC APIs — get rid of the brain fart that the REST is and just give all your queries and commands proper names and send them over the wire using standard HTTP tooling. You can namespace your procedures with URL segments, similar to REST, but you don’t have to bake in resource IDs into the URL structure and deal with complexity of HTTP methods.\u003c/p\u003e\n\u003cp\u003eWhen it comes to GraphQL, the idea behind it is brilliantly simple:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eeach client defines the data it needs using a query language designed specifically for expressing graph nodes in a very simple form\u003c/li\u003e\n\u003cli\u003ethe server parses the query, and passes each requested field through a resolver that has access to the root node and can access various data stores and/or external services to compute the return value\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe problem with introducing a new language, however, is that it needs a lexer, which can parse the query into a more standard form that can be digested by various server technologies. As most API clients live in the browser, GraphQL tooling evolved around the needs of front-end applications, in a JavaScript ecosystem with browser compatibility in mind. While it makes GraphQL a very pleasant experience on the front-end, the tooling around server to server communication is very much lacking — from bootstrapping a client and figuring out caching and other nuances like fragmentation to writing and parsing queries that can be used by the said client. Even though GraphQL is designed for standard HTTP protocol, the problem is that GraphQL in itself is not standard and might not be the best choice for a versatile API design.\u003c/p\u003e\n\u003ch2 id=\"observability--scalability\"\u003eObservability \u0026#x26; Scalability\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#observability--scalability\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAPI health and performance are important metrics that allow us to make conclusions about our API design. Ability to observe these metrics continuously and react to latency and performance issues, as well as runtime errors, should be a motivating factor in our decision-making.\u003c/p\u003e\n\u003cp\u003eWhile single point of entry APIs offer simplicity, they are quite a headache in terms of observability and scalability. Figuring out the health of your GraphQL or JSON-RPC APIs is quite a challenge without extra instrumentation. While REST is most likely to provide you with detailed logs of what resources were accessed, how many times, and how long it took to process the request, getting the same stats for APIs that have a single endpoint is quite impossible. Instead you end up with millions of log entries for the same endpoint, and unless you make an effort to provision extra logging with operation/method names, you would have no idea what those requests were. Things are even worse with GraphQL that doesn’t believe in HTTP status codes, so all requests end up with 200 status code, so tracing and debugging really turns into adventure every single time.\u003c/p\u003e\n\u003cp\u003eUsing a single point of entry is also a DevOps problem. Depending on the environment, you may want to provision more resources for API endpoints that have higher latency or require more computational resources, but instead you are forced to scale the entire API server with an entirety of its dependencies and the impact of its memory footprint.\u003c/p\u003e\n\u003cp\u003eA single point of entry also makes it difficult to rip the benefits of reverse proxies that can reroute specific requests, help with caching, observability, load balancing, encryption, access control and other concerns.\u003c/p\u003e\n\u003ch2 id=\"error-handling\"\u003eError Handling\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#error-handling\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHTTP codes are too generic. As I \u003ca href=\"https://medium.com/itnext/graceful-error-handling-in-rest-driven-web-applications-d4209b4937aa\"\u003ewrote some years ago\u003c/a\u003e, APIs should be able to communicate problems to the clients, and subsequently the users. Whatever API design you chose, make sure you build a standardised approach to communicating errors to the client and contextualising them.\u003c/p\u003e\n\u003cp\u003eGraphQL’s error handling is a blessing and a curse. On one hand, it is very verbose, and can report errors from individual field resolvers. On the other hand, it makes debugging and error handling a pain — by merging success and error states into a single response it makes it so much harder for the clients to differentiate between network errors, invariants, schema validation issues, and actual success responses. According to the specification, partial success responses are in fact possible even if individual resolvers report errors, so it is quite cumbersome to try an reconcile null field values with errors (unless the GraphQL server prevents partial responses, as is the case with Apollo). So, give some consideration to how your server deals with errors, and how your clients are going to make sense of them.\u003c/p\u003e\n\u003cp\u003eAs mentioned earlier, you may want to instrument additional tooling to help you with tracing errors in systems that have a single point of entry.\u003c/p\u003e\n\u003ch2 id=\"versioning\"\u003eVersioning\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#versioning\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWhether or not your API requires versioning is largely a usage problem. If your API is consumed in house and you are able to evolve APIs while keeping clients up to date, it might not be an issue. If you are distributing your APIs externally, you might want to consider some form of versioning.\u003c/p\u003e\n\u003cp\u003eIf your API exists largely as a proxy to your database model, versioning can be somewhat of an acute problem. Once the database schema changes, there isn’t really a way to maintain backwards compatibility, especially if your API is autogenerated from database models. So, give it some thought, when chosing your tooling.\u003c/p\u003e\n\u003cp\u003eAs mentioned earlier, RPC could be an interesting option for decoupling the storage model from the API model, giving you more flexibility. You can evolve your API without necessarily versioning it by introducing new procedures and deprecating the old ones. GraphQL tends to brush off versioning, leaning into the same approach — add new fields and deprecate the old ones. The difference is that however with RPC you have more control over request routing and can still introduce versioning. With GraphQL your versioning capabilities are limited — you may need to spin up a different container that serves the older version of the graph. Besides you want to get rid of dead and outdated code from time to time, so some way of communicating breaking changes to the clients would have been a plus.\u003c/p\u003e\n\u003ch2 id=\"access-controls\"\u003eAccess Controls\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#access-controls\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eYou may want to invest some time giving access requirements a thought. Whether or not you require route/procedure level, resource level, or field level access can have a great impact on the your choice of API design.\u003c/p\u003e\n\u003cp\u003eShould resource-level checks be sufficient, you still need to consider, whether representation of the resource is identical for all users. Should you need higher granularity in access controls, you may need to find a way to communicate these requirements to the clients. Whatever route you take on the server (preventing access to the whole resource, or nulling the field value, or communicating an error on field access), it will be the responsibility of the client to deal with the fallout.\u003c/p\u003e\n\u003cp\u003eGraphQL is quite handy if you need field level access, though it does lack SDL level standars for documenting access requirements (aside from non-standard directives). REST API might not be an ideal solution for applications that need high levels granularity, as it prevents you from branching resource representation. RPC might offer some flexibility in designing the API with your particular requirements in mind.\u003c/p\u003e","noteIndex":{"id":"Iy0MoL0KnL55Br3AfTS2C","title":"Luke","desc":"","updated":1761796791487,"created":1644449449778,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"4e745570ca97988a0362cb939b760952","links":[{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"life-tips","position":{"start":{"line":41,"column":5,"offset":2603},"end":{"line":41,"column":29,"offset":2627},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"life-tips","anchorHeader":"wodenokoto"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2025","alias":"What I read in 2025","position":{"start":{"line":70,"column":3,"offset":4333},"end":{"line":70,"column":54,"offset":4384},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2025"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2024","alias":"2024","position":{"start":{"line":71,"column":5,"offset":4389},"end":{"line":71,"column":41,"offset":4425},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2024"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2023","alias":"2023","position":{"start":{"line":72,"column":5,"offset":4430},"end":{"line":72,"column":41,"offset":4466},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2023"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2022","alias":"2022","position":{"start":{"line":73,"column":5,"offset":4471},"end":{"line":73,"column":41,"offset":4507},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2022"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-struggled-brag-in","position":{"start":{"line":79,"column":3,"offset":4643},"end":{"line":79,"column":39,"offset":4679},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-struggled-brag-in"}}],"anchors":{"what-i-read-in-past":{"type":"header","text":"What I read in past","value":"what-i-read-in-past","line":74,"column":0,"depth":2}},"children":["zd4mq442jike0pr0wba1u3m","6hzeqsofq67gdk88flxlkhp","778ijii93yu5uwnrwmn5zi4","g1fngdjl25nes6fs3lip602","ZbdkdApFqLdks4Moq92R9","uoc5hhki3o4py15cesddu8q","9qf7j06jtdkm6rnx9ymvwb0","5zn10cvj7ajy2gh2is5nqmg","4qo9ma0z0yu1czns6pxl7y5","ok0e729ho7o09xetujkxc0m","GR5x8HnNFEN6fU2UBSEIK","yirtnlj8q24yutcf3ss1xqy","eq0wc6t7wl2wv221yb68ro4","7x2fnv4j6gxts08qk0jguny","ettkt3iClONnxpbGwBVLl","7l4knev6v613tbuoskvmbdg","hvh5bud6yp7dc89tuh95tr9","4fvoqrplw0cweo554usbjos","f8qsfql0a9v8thpeo82udfa","1swsbrhqi9jk41v9eodyi5q","SQqYupi6EFddTerBA8RRD","hjNeNc1F2JUh0lTWanH4h","qf0l4wbrc9jgooyzexmbq5v","uur1lkol353z9vfeqb3n5bv","cd9n1czq3ursgkby985wkmm","k1sr43vwnfqztwc0s43pkcf","wfde75rhdvq2yfa2zy2q6rv","rjcmdv60jokmbw6zoq8u2ef","ujapvww8o6v3kpmlhtryq4k","pkwewou9d5e8ystswn1j2b4"],"parent":null,"data":{},"body":"\nHi there 👋. I'm a Front-end developer.\n\n---\n\n- 단순함과 꾸준함은 가장 쉬우면서도 지키기 어려운 원칙.\n\n- 🥱 -\u003e 🤔💡🌱 - [On The Death of Daydreaming](https://www.afterbabel.com/p/on-the-death-of-daydreaming)\n  - boredom -\u003e easy fun -\u003e art -\u003e profit?\n\n\u003e I've often described my motivation for building software to others using imagery: I like to go find a secluded beach, build a large, magnificent sand castle, and then walk away. Will anyone notice? Probably not. Will the waves eventually destroy it? Yep. Did I still get immense satisfaction? Absolutely. - [aliasxneo](https://news.ycombinator.com/item?id=41497113)\n\n\u003e We love to see the process, not just the result. The imperfections in your work can be beautiful if they show your struggle for perfection, not a lack of care. - [ralphammer](https://ralphammer.com/is-perfection-boring/)\n\n\u003e Simplicity, even if it sacrifices some ideal functionality has better survival characteristics than the-right-thing. - [The Rise of Worse is Better](https://www.dreamsongs.com/RiseOfWorseIsBetter.html)\n\n\u003e [Roberto Blake was talking about making 100 crappy videos](https://www.youtube.com/watch?v=OnUBaQ1Sp_E) to get better over time. Putting in the reps and improving a little bit each time.\n\u003e\n\u003e Putting in the work without expecting any external reward at first (eg views, followers, likes, etc) will pay off in the long run. - [100 Scrappy Things](https://www.florin-pop.com/blog/100-scrappy-things/)\n\n\u003e Make the difficult habitual, the habitual easy, and the easy beautiful. - [Constantin S. Stanislavski](https://www.goodreads.com/quotes/7102271-make-the-difficult-habitual-the-habitual-easy-and-the-easy)\n\n\u003e A good match is a **structured** dance, where players aim to **score** while they are following well-defined **rules**. This **freedom within a structure** is what makes it fun. - [ralphammer](https://ralphammer.com/how-to-get-started/)\n\n- [Pivot Points](https://longform.asmartbear.com/pivot-points/)\n\n  - non-judgmental aspects of personality that can be strengths in some contexts and weaknesses in others\n  - Pivot Points are fixed in the short term\n\n- [Hedged Bets](https://longform.asmartbear.com/predict-the-future/#hedged-bets)\n  - trading slightly less maximum upside for predictable, net-positive outcomes.\n\n\u003e “Motivation often comes after starting, not before. Action produces momentum.”\n\u003e [When you start a new habit, it should take less than two minutes to do.](https://jamesclear.com/how-to-stop-procrastinating)\n\u003e\n\u003e - James Clear\n\n\u003e Focus is more about **not** keeping busy when you need to wait for something.  \n\u003e Eat the boredom for a minute.\n\u003e\n\u003e - [[life-tips#wodenokoto]]\n\n\u003e [4 minutes run hard enough to push heart rate to 90%, 3 minutes recover, repeat 4 times](https://news.ycombinator.com/item?id=34213181)\n\u003e\n\u003e - https://www.ntnu.edu/cerg/advice\n\u003e - [Get running with Couch to 5K](https://www.nhs.uk/live-well/exercise/running-and-aerobic-exercises/get-running-with-couch-to-5k/)\n\n\u003e [recommended routine - bodyweightfitness](https://www.reddit.com/r/bodyweightfitness/wiki/kb/recommended_routine/) - I Don't Have This Much Time!\n\u003e\n\u003e - Don't workout at all (saves anywhere from 20 to 60 minutes, but really, really, really, really, really, really, really, really, really not recommended)\n\n\u003e 도무지 읽히지 않는 책 앞에서 내가 택한 방법은 펼쳐진 페이지 앞에서 멍때리기이다. 다르게 표현하면 이렇다. 펼쳐진 두 페이지 앞에서 오래 머물기.\n\u003e\n\u003e 책을 펼쳐놓는 것으로 충분하다. 읽지 못해도 좋다. 매일 정해진 진도를 나가야 하는 학교 수업이 아니니까. 하지만 읽지 않아도 괜찮다고 해서 펼쳐두지조차 않으면 곤란하다. 가능한 한 자주 책을 펼쳐두도록 하자. 전혀 읽지 않고 멍하니 바라보고 있다가 다시 덮게 되더라도\n\u003e\n\u003e - 막막한 독서. 시로군. P.10~13\n\n\u003e I think it should be everyone's primary focus to sleep well, drink water, get outside, get active, and eat generally decently. I hate to say it, but if you're not eating a good amount of vegetables and fruit, decent protein, sleep, etc, no amount of XYZ will catch up to that detriment. - [CE02](https://news.ycombinator.com/item?id=35056071)\n\n\u003e My real battle is doing good versus doing nothing. - [Deirdre Sullivan](https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral)\n\n[Kind Engineering](https://kind.engineering/) - How To Engineer Kindness\n\n\u003e Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. - [Teller](https://www.goodreads.com/quotes/6641527-sometimes-magic-is-just-someone-spending-more-time-on-something)\n\n---\n\n## What I read in past\n\n- [[What I read in 2025|journal.what-i-read-in.2025]]\n  - [[2024|journal.what-i-read-in.2024]]\n  - [[2023|journal.what-i-read-in.2023]]\n  - [[2022|journal.what-i-read-in.2022]]\n- 📝 [Gists](https://gist.github.com/Luke-SNAW)\n- 📜 [Journals](https://luke-snaw.github.io/Luke-SNAW__netlify-CMS.github.io/)\n\n---\n\n- [[journal.what-i-struggled-brag-in]]\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":false,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.115.0","enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Luke SNAW","description":"Personal knowledge space"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","siteUrl":"https://luke-snaw.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"6h87a35ua3cfe1urbwxm13z"},"buildId":"vOE8u-mg___OsOsz4tjEg","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
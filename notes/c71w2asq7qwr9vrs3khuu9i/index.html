<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>How finishing what you start makes teams more productive and predictable</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="How finishing what you start makes teams more productive and predictable"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://luke-snaw.github.io//notes/c71w2asq7qwr9vrs3khuu9i/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/26/2022"/><meta property="article:modified_time" content="7/26/2022"/><link rel="canonical" href="https://luke-snaw.github.io//notes/c71w2asq7qwr9vrs3khuu9i/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9d8e0603730b15a3.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/wirstT2ztC8OQsbzKjhvw/_buildManifest.js" defer=""></script><script src="/_next/static/wirstT2ztC8OQsbzKjhvw/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="how-finishing-what-you-start-makes-teams-more-productive-and-predictable">How finishing what you start makes teams more productive and predictable<a aria-hidden="true" class="anchor-heading icon-link" href="#how-finishing-what-you-start-makes-teams-more-productive-and-predictable"></a></h1>
<blockquote>
<p><a href="https://lucasfcosta.com/2022/07/19/finish-what-you-start.html">https://lucasfcosta.com/2022/07/19/finish-what-you-start.html</a></p>
</blockquote>
<p>Let’s be honest. When you read this post’s title, you thought it was obvious. Yet, most people don’t follow this simple piece of advice. You know that too, and that’s probably what led you here.</p>
<p>What you <em>don’t</em> know is <em>why</em> so many people won’t finish what they start and <strong>how to illustrate and quantify the impact of unfinished work</strong>. That’s what I’ll explain in this post.</p>
<p>First, I’ll expound on the reasons why finishing one piece of work before starting the next makes products better, cycle times shorter, and teams more productive.</p>
<p>Then, I’ll expose why some teams choose to work on multiple tasks concurrently despite that approach being suboptimal most of the time. In this section, I’ll also explain when to batch tasks, when not to, and what you should do instead.</p>
<p>Finally, I’ll use a few Monte Carlo simulations and cumulative flow diagrams to demonstrate how unfinished work makes teams unpredictable — statistically speaking.</p>
<p>At the end of this post, I have included a small summary for you to paste on Slack or Microsoft Teams and <strong>convince your team to stop starting and start finishing</strong>.</p>
<blockquote>
<p>If you’re reading on a phone, click images to expand them.</p>
</blockquote>
<h2 id="how-finishing-what-you-start-increases-productivity">How finishing what you start increases productivity<a aria-hidden="true" class="anchor-heading icon-link" href="#how-finishing-what-you-start-increases-productivity"></a></h2>
<p>I like burgers. Do you? I don’t like them when they’re cold, though, and it makes me unhappy to wait too long for one.</p>
<p>When I’m the only person at the burger shop, it’s not a challenge for its cooks to assemble a burger quickly and for waiters to deliver it to me while it’s still hot.</p>
<p>Here’s what happens when I’m the only person in the shop.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/one-burger-flow.png"><img src="/assets/finish-what-you-start/one-burger-flow.png" alt="The production process of a single burger."></a></p>
<p><em>The production process of a single burger.</em></p>
<p>In this case, considering each burger demands four steps of preparation, and each step takes one minute, my burger gets to me in four minutes.</p>
<p>When <em>you</em> arrive at this burger shop, the cook’s job gets a bit more difficult. Now, they have to choose between preparing our burgers concurrently or one at a time (serially).</p>
<p>To illustrate these approaches, I’ll assume there’s a single cook and that they can only prepare one burger at a time. We’ll revisit this assumption later. For now, bear with me.</p>
<p>First, let’s see what happens when the cook prepares one burger at a time.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/two-burger-flow-sequential.png"><img src="/assets/finish-what-you-start/two-burger-flow-sequential.png" alt="Preparing burgers in series causes both their cycle-times to be the same."></a></p>
<p><em>Preparing burgers in series causes both their cycle-times to be the same.</em></p>
<p>Assuming I ordered only a bit before you, my burger still takes four minutes. Yours, however, takes eight.</p>
<p>Now, let’s compare the serial to the concurrent approach. In the image below, you’ll see what happens when the cook tries to prepare our burgers concurrently.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/two-burger-flow-concurrent.png"><img src="/assets/finish-what-you-start/two-burger-flow-concurrent.png" alt="Preparing burgers concurrently elongates the burgers&#x27; cycle times."></a></p>
<p><em>Preparing burgers concurrently elongates the burgers' cycle times.</em></p>
<p>This time, you still had to wait the same amount of time for your burger, but I’ve had to wait almost twice as long for mine! Outrageous.</p>
<p>To make matters worse, let me show what happens if a friend of yours comes in, places an order, and the cook decides to take the same shortsighted approach to burger-making.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/three-burger-flow-concurrent.png"><img src="/assets/finish-what-you-start/three-burger-flow-concurrent.png" alt="The more burgers the cook prepares concurrently, the longer cycle times become."></a></p>
<p><em>The more burgers the cook prepares concurrently, the longer cycle times become.</em></p>
<p>In this scenario, I took ten minutes to taste my burger, and you took twelve. Thanks to your friend, I had to wait an extra six minutes, and you had to wait for an extra three.</p>
<p>Such a disappointing burger-preparing performance demands vigorous action to be taken.</p>
<p>Personally, I’d prefer to educate the cook rather than kick you and your friend out of the shop because I believe every hard-working engineer deserves a succulent burger on a Friday night.</p>
<p>Here’s what we’ll do. First, we’ll illustrate what would’ve happened had the cook decided to prepare each of our burgers in series. Then, we’ll enter the kitchen, hand them the schematics, and explain the optimal approach.</p>
<p>Come join my table, grab a pen, and let’s get drawing.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/three-burger-flow-serial.png"><img src="/assets/finish-what-you-start/three-burger-flow-serial.png" alt="Preparing three burgers in series ensures that all burgers&#x27; cycle times remain equal, and that the first two will be delivered earlier."></a></p>
<p><em>Preparing three burgers in series ensures that all burgers' cycle times remain equal, and that the first two will be delivered earlier.</em></p>
<p>As our drawing shows, had the cook prepared our three burgers in series, you and I would have had to wait the same amount of time for our burgers as before — 4 and 8 minutes. Your friend’s burger would still have taken twelve minutes, but that’s what they deserve for being late for dinner.</p>
<p>Now, before showing our drawing to the cook, let’s take a moment to compare burger-making with the equally noble activity of software development.</p>
<p>Imagine you have features A and B in your backlog, for example.</p>
<p>If each feature takes three units of time to deliver, working on them in parallel makes A take two units of time longer to deliver than it would have taken had you finished it before starting B.</p>
<p>Furthermore, working on these features concurrently demands B’s specifications to be written earlier than they would have been otherwise.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/features-concurrent.png"><img src="/assets/finish-what-you-start/features-concurrent.png" alt="Working on features concurrently causes features to take longer."></a></p>
<p><em>Working on features concurrently causes features to take longer.</em></p>
<p>On the other hand, if you finish A before starting B, you’ll deliver A earlier, and you’ll buy yourself more time to work on B’s specifications. During that time, you can collect more information to boost B’s chance of success.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/features-in-series.png"><img src="/assets/finish-what-you-start/features-in-series.png" alt="Working on features in series shortens each feature&#x27;s cycle time, and allows the first to be delivered earlier."></a></p>
<p><em>Working on features in series shortens each feature's cycle time, and allows the first to be delivered earlier.</em></p>
<p>As you can see, <strong>in the software industry, both tasks take longer to deliver whenever you start a new feature before finishing the first. Moreover, the first task will be delivered later than it could have been.</strong></p>
<p>Furthermore, the likelihood of the second feature succeeding is smaller because you were working on top of specifications that were older than they could have been. Had you waited a bit longer, you’d have had more time to digest customer feedback and incorporate new information into the second feature’s specification.</p>
<p>That’s what just-in-time means: <strong>instead of starting each feature as early as possible, you start it as late as you can afford to</strong>, and incorporate as much feedback and information into the spec in the meantime.</p>
<p>This same effect happens when a critical bug appears. <a href="https://lucasfcosta.com/2022/07/15/long-term-plans-dont-work.html">As I’ve previously explained</a>, such urgent work stops you from finishing your current task, delays it, and causes all other tasks in progress to take longer <em>on average</em>.</p>
<p>We can summarise this behaviour using <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>, which, when expressed in terms of throughput (deliveries per unit of time), looks like this:</p>
<p>Avg. Cycle Time\=Avg. Work In ProgressAvg. Throughput {Avg.\ Cycle\ Time} = \cfrac{Avg.\ Work\ In\ Progress}{Avg.\ Throughput} Avg. Cycle Time\=Avg. ThroughputAvg. Work In Progress​</p>
<p>As I’ve explained using the burger shop example, and as Little’s Law dictates, cycle times elongate when work in progress increases and throughput remains the same. It’s a straightforward mathematical fact. Nonetheless, many managers are unaware of it.</p>
<p>Despite the simple mathematics, when some managers see that work is taking longer to finish, they start <em>more</em> work hoping that starting tasks earlier causes them to finish earlier. This attitude leads to the exact <em>opposite</em> of the result they’d like to achieve: it <em>increases</em> cycle times.</p>
<p><strong>If you wish to keep cycle-times low, you should limit work in progress</strong>.</p>
<p>You can argue with me, your team, or your manager as much as you want, but you can’t argue with mathematics. <strong>Limit work in progress</strong>.</p>
<h3 id="the-cost-of-context-switching">The cost of context switching<a aria-hidden="true" class="anchor-heading icon-link" href="#the-cost-of-context-switching"></a></h3>
<p>There’s yet a third crucial aspect to consider in the world of software development: the cost of context switching.</p>
<p>When preparing burgers, it’s effortless to shift from working on one burger to another. When writing software, on the other hand, context-switching incurs a high cost.</p>
<p>Working on tasks concurrently delays their cycle times not only because of the interleaving activities but also because every time an engineer has to switch context, they take more time to get back into a “flow state”.</p>
<p>Here’s a more accurate representation of what happens when working on software development tasks concurrently:</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/features-concurrent-context-switch.png"><img src="/assets/finish-what-you-start/features-concurrent-context-switch.png" alt="There&#x27;s a cost for switching from working on a feature to working on another."></a></p>
<p><em>There's a cost for switching from working on a feature to working on another.</em></p>
<p>Enough talking. Let’s bring our plan into the kitchen.</p>
<h2 id="when-to-start-without-having-finished">When to start without having finished<a aria-hidden="true" class="anchor-heading icon-link" href="#when-to-start-without-having-finished"></a></h2>
<p>You and I delve into the kitchen with our drawing in our hands, the power of mathematics under our arms and tell the cook:</p>
<blockquote>
<p>“Hey, look, here’s why you should prepare one burger at a time” <em>*points to drawing*</em></p>
</blockquote>
<p>The cook seems abhorred and goes on to explain:</p>
<blockquote>
<p>No matter how rare you like your patties, they all take significant time to prepare.<br>
It’s quicker for me to prepare them in larger batches than to wait for one patty to be ready before I toss another on the grill.</p>
</blockquote>
<p>The cook has a point. Neither you nor I know anything about the craft of burger-making; how could we expect to be right?</p>
<p>Nevertheless, there’s a lesson to be taught here — one about batch sizes and transaction costs.</p>
<p>Whenever it’s expensive to move a work product, in this case, a patty, from one stage of the production process to the next, that transition will happen less often so that you can pay the transaction cost only once by moving multiple items at a time.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/small-batches-vs-large-batches-patties.png"><img src="/assets/finish-what-you-start/small-batches-vs-large-batches-patties.png" alt="When it&#x27;s costly to move items from one stage to the next, items batch-up."></a></p>
<p><em>When it's costly to move items from one stage to the next, items batch-up.</em></p>
<p>That’s why you don’t buy a single egg whenever you go to the supermarket. Going to the supermarket has a significant transaction cost, so you purchase eggs in larger batches. In fact, the farther from your home the supermarket is, the more likely it is for the batch of eggs you bring home to be larger.</p>
<p>It’s only when the cost of keeping the patties in the grill exceeds the cost of sending them to the counter that the cook will do so.</p>
<p>To summarise: whenever a transaction’s cost goes up, that transaction happens less frequently.</p>
<p>Furthermore, if the cost of holding items at a particular stage of the process is lower than the cost of pushing those items forward, it’s better to hold them.</p>
<p>That’s also the reason why <a href="https://martinfowler.com/bliki/FrequencyReducesDifficulty.html">Martin Fowler and Jez Humble</a> advocate that <a href="https://www.goodreads.com/quotes/1314241-if-it-hurts-do-it-more-frequently-and-bring-the">“if something is painful, you should do it more often”</a>, especially when it comes to deploying software. If you’re forced to do something often, you’ll naturally gravitate towards decreasing the cost of doing it.</p>
<p>You can notice the same effect happens with automated tests. If you have to manually test your software for a few hours before you ship it, you’ll hold changes for longer and test larger batches at once.</p>
<p>In the software industry, there are several problems with large batch transferrals:</p>
<ol>
<li>They delay feedback because features take longer to get to customers</li>
<li>They make it more difficult to trace bugs because the delta between each version is larger</li>
<li>They increase the overhead of change management because they make versioning and automatic rollbacks more difficult to do</li>
</ol>
<p>These problems exponentially increase the costs of holding software tasks as opposed to pushing them forward.</p>
<p>The reason many people fail to acknowledge and act upon transaction costs in the software industry is that they compare software — a design process — to manufacturing processes.</p>
<p>In manufacturing, the cost of holding pieces in a factory is linear. The holding cost for a piece is just the cost of keeping it in storage multiplied by the number of days it will be there. On the other hand, in software development, when holding a particular piece of work, you’ll experience a negative compounding effect due to the lack of feeback, the larger deltas between versions, and the overall harm to the overall system reliability.</p>
<p>Now that we understand the burger and the software variations of the problem, we can make a recommendation to both cooks and software engineers alike:</p>
<p><strong>Reducing transaction costs enables small batches. Small batches, in turn, reduce average cycle times, diminish risk, and enhance reliability</strong>.</p>
<p><strong>You should only start without having finished when transaction costs are high, and it wouldn’t make economic sense to spend time decreasing them, either because you have agreed to a particular delivery date or because you don’t have the capital to invest.</strong></p>
<p>That said, I’d be careful to avoid falling into a situation where “you’re too busy draining the flood to be able to fix the leak”. The earlier you decrease transaction costs, the earlier you’ll be reaping the benefits from having done it.</p>
<h2 id="how-finishing-what-you-start-makes-teams-more-predictable">How finishing what you start makes teams more predictable<a aria-hidden="true" class="anchor-heading icon-link" href="#how-finishing-what-you-start-makes-teams-more-predictable"></a></h2>
<p>Despite coming into the kitchen to offer unsolicited advice, you and I have become good friends with the cook. Now, it’s time for them to teach us a thing or two about how we can deliver software more predictably.</p>
<p>In the burger shop’s kitchen, there’s a limit to how many patties you can put on the grill. Furthermore, zero burgers are in progress at the end of the day. “These constraints allow me to provide burger-eaters with predictable delivery times”, — says the cook.</p>
<p>To understand why those constraints help the cook, let’s plot the burger shop’s arrivals and departures using <a href="https://en.wikipedia.org/wiki/Cumulative_flow_diagram">a cumulative flow diagram</a>.</p>
<p>First, let’s plot a cumulative flow diagram illustrating what happens when the cook prepares many burgers at once — a large batch.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/cfd-large-batches.png"><img src="/assets/finish-what-you-start/cfd-large-batches.png" alt="With large batches, there&#x27;s more variability in cycle times."></a></p>
<p><em>With large batches, there's more variability in cycle times.</em></p>
<p>As the diagram shows, a customer who arrives early waits for a long time for their burger, while a customer who comes later waits much less. In other words, there’s a significant amount of variability in the time customers have to wait until they get their burger — shown by the area in blue.</p>
<p>Now, let’s see what happens when the cook prepares fewer burgers at a time.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/cfd-small-batches.png"><img src="/assets/finish-what-you-start/cfd-small-batches.png" alt="Smaller batches decrease cycle time variability."></a></p>
<p><em>Smaller batches decrease cycle time variability.</em></p>
<p>This time, a customer who arrived early doesn’t have to wait much longer than the customer who came later. As shown by the area in blue, there’s less variability in the time it takes for customers to get burgers.</p>
<p>After looking at these two diagrams, we can conclude that the larger the batch size, the more variability there is in waiting times.</p>
<p>Additionally, if batch sizes vary, not only will the waiting time within a particular batch of customers be more variable, but also distinct batches of customers will see different waiting times. Customers who arrive earlier may see cycle times from 1 to 10 minutes, while customers who come later might see their burgers taking anywhere from 1 to 30 minutes, for example.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/cfd-different-batch-sizes.png"><img src="/assets/finish-what-you-start/cfd-different-batch-sizes.png" alt="If batch sizes also vary over time, distinct batches of customers see different variations of cycle time."></a></p>
<p><em>If batch sizes also vary over time, distinct batches of customers see different variations of cycle time.</em></p>
<p>That’s why the cook mentioned it’s helpful to limit how many burgers they can fit on a grill: it makes batch sizes uniform.</p>
<p>The same principle is valid for software development. The larger your batch sizes — the more tasks you work on in parallel — the more variability in cycle times you will see.</p>
<p>In the software industry, however, we don’t have a “finite grill”. In other words, there’s no physical upper cap on how many tasks can be in progress at a time. Therefore, you must be adamant about creating work in progress limits yourself.</p>
<p><strong>The lower you make WIP limits and stick to them, the less variability you’ll see in cycle times</strong>.</p>
<p>Besides making your cycle-times unpredictable, the lack of WIP limits will also impact your ability to do forecasts.</p>
<p>Imagine, for example, that your team tends to work on many tasks concurrently. In that case, most days they’ll split their attention between tasks. Then, there will be a day in which they’ll complete all those tasks, doing a large batch transferral.</p>
<p>Let’s simulate such a team assuming that their throughput over ten days looks like the following:</p>
<pre><code>// Each item represents the number of tasks delivered that day
const TEN_DAY_THROUGHPUT = [ 0, 0, 0, 0, 5, 0, 0, 0, 5, 0 ];
</code></pre>
<p>If we go ahead and <a href="https://lucasfcosta.com/2021/09/20/monte-carlo-forecasts.html">use a Monte Carlo algorithm to simulate how many tasks this team can deliver</a> in 30 days, we’ll obtain the following histogram.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/histogram-concurrent-team.png"><img src="/assets/finish-what-you-start/histogram-concurrent-team.png" alt="Teams that deliver many tasks at once are less predictable because there&#x27;s a wider range of possible outcomes when simulating their performance."></a></p>
<p><em>Teams that deliver many tasks at once are less predictable because there's a wider range of possible outcomes when simulating their performance.</em></p>
<p>In this histogram, you can see a significant number of possible outcomes for this team: they may deliver anywhere from 0 to 90 tasks. Furthermore, there are plenty of likely scenarios in this distribution.</p>
<p>Now, let’s change the throughput samples we used in our simulation. <strong>This time, we’ll consider the team working on one task at a time, delivering in more regular intervals</strong>, instead of working on plenty of tasks in parallel and delivering them all on the same day.</p>
<pre><code>// Each item represents the number of tasks delivered that day
const TEN_DAY_THROUGHPUT = [1, 1, 1, 1, 1, 2, 0, 1, 1, 1];
</code></pre>
<p>Please notice that the team still delivered the same amount of tasks in those ten days. The only difference between these teams is that the second delivered tasks more uniformly.</p>
<p>Simulating such a team’s performance yields the histogram below.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/histogram-serial-team.png"><img src="/assets/finish-what-you-start/histogram-serial-team.png" alt="Teams which consistently deliver a small number of tasks are more preditable because there&#x27;s a smaller range of possible outcomes when simulating their performance."></a></p>
<p><em>Teams that deliver many tasks at once are less predictable because there's a wider range of possible outcomes when simulating their performance.</em></p>
<p>If you compare these two histograms, you’ll see that the second histogram’s distribution has fewer possible outcomes — 20 to 41 tasks instead of 0 to 90 —and results are more clustered towards the centre. In other words, its standard deviation is smaller.</p>
<p>To make my point even more obvious, let’s see what happens if we assume the team always delivers one task each day.</p>
<pre><code>// Each item represents the number of tasks delivered that day
const TEN_DAY_THROUGHPUT = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1];
</code></pre>
<p>Assuming our team will remain hyper-consistent, there’s only one possible outcome in the next 30 days: they’ll deliver 30 tasks.</p>
<p><a href="https://lucasfcosta.com/assets/finish-what-you-start/histogram-uniform-team.png"><img src="/assets/finish-what-you-start/histogram-uniform-team.png" alt="A team which always delivers the same number of tasks each day will yield a &#x22;deterministic&#x22; forecast (days times throughput)."></a></p>
<p><em>A team which always delivers the same number of tasks each day will yield a "deterministic" forecast (days * throughput).</em></p>
<p>The comparison between those three histograms leads to the conclusion that teams which deliver tasks more uniformly are more predictable, even if they deliver the same number of tasks within the period we’re using as the sample for our simulations.</p>
<h2 id="putting-it-all-together">Putting it all together<a aria-hidden="true" class="anchor-heading icon-link" href="#putting-it-all-together"></a></h2>
<p>When you start a new task before finishing the previous, average cycle times will increase. That happens because you’ll increase the number of items in progress but maintain the same throughput.</p>
<p>Little Law illustrates this behaviour by establishing a clear relationship between cycle time, work in progress, and throughput.</p>
<p>Avg. Cycle Time\=Avg. Work In ProgressAvg. Throughput {Avg.\ Cycle\ Time} = \cfrac{Avg.\ Work\ In\ Progress}{Avg.\ Throughput} Avg. Cycle Time\=Avg. ThroughputAvg. Work In Progress​</p>
<p>Additionally, there’s a cost to context-switching when it comes to software development tasks.</p>
<p>Teams which start tasks earlier than they should must also write specifications earlier. Therefore, they’ll waste an opportunity to gather feedback, digest it, and incorporate it into a feature’s specification, diminishing its chance of success.</p>
<p>Many times, teams will have multiple tasks in progress because moving a task from one stage to the next is costly. Consequently, these teams will attempt to transfer tasks from one stage to another in large batches to pay this high transaction cost only once.</p>
<p>The problem with large batch transferrals in the software industry is that the cost of holding these tasks increases exponentially because their specifications perish, and change deltas increase, making it more difficult to find bugs. This increase in deltas also complicates change management, harming the system’s reliability.</p>
<p>One last benefit of working on smaller batches of tasks at a time is that it makes teams more predictable. Delivering the same number of tasks uniformly is better than delivering multiple tasks at once because it makes cycle times uniform too. In turn, those uniform cycle times help you make better forecasts, as there will be fewer possible outcomes when simulating (or estimating) the team’s performance.</p>
<h2 id="further-reading">Further reading<a aria-hidden="true" class="anchor-heading icon-link" href="#further-reading"></a></h2>
<ul>
<li><a href="https://www.amazon.co.uk/dp/B00K7OWG7O">The Principles of Product Development Flow: Second Generation Lean Product Development</a> — <a href="http://reinertsenassociates.com/about/">Donald G. Reinertsen</a></li>
<li><a href="https://www.amazon.com/dp/B013ZQ5TUQ">Actionable Agile Metrics for Predictability</a> — <a href="https://twitter.com/danvacanti">Daniel Vacanti</a></li>
<li><a href="https://www.amazon.co.uk/dp/B084WVMKLC">When Will It Be Done?: Lean-Agile Forecasting to Answer Your Customers’ Most Important Question</a> — <a href="https://twitter.com/danvacanti">Daniel Vacanti</a></li>
<li><a href="https://lucasfcosta.com/2022/06/12/measure-queues-not-cycle-time.html">How high capacity utilisation hurts a team’s performance</a> — <a href="https://twitter.com/thewizardlucas">Lucas da Costa</a></li>
<li><a href="https://lucasfcosta.com/2022/07/15/long-term-plans-dont-work.html">Why long-term plans don’t work and how to fix them</a> — <a href="https://twitter.com/thewizardlucas">Lucas da Costa</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#how-finishing-what-you-start-increases-productivity" title="How finishing what you start increases productivity">How finishing what you start increases productivity</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#the-cost-of-context-switching" title="The cost of context switching">The cost of context switching</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#when-to-start-without-having-finished" title="When to start without having finished">When to start without having finished</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#how-finishing-what-you-start-makes-teams-more-predictable" title="How finishing what you start makes teams more predictable">How finishing what you start makes teams more predictable</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#putting-it-all-together" title="Putting it all together">Putting it all together</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#further-reading" title="Further reading">Further reading</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"c71w2asq7qwr9vrs3khuu9i","title":"How finishing what you start makes teams more productive and predictable","desc":"","updated":1658821805731,"created":1658821773315,"custom":{},"fname":"dev.management.How finishing what you start makes teams more productive and predictable","type":"note","vault":{"fsPath":"vault"},"contentHash":"716f8013d9a4eef0f480e2f9d0e744e8","links":[],"anchors":{"how-finishing-what-you-start-increases-productivity":{"type":"header","text":"How finishing what you start increases productivity","value":"how-finishing-what-you-start-increases-productivity","line":24,"column":0,"depth":2},"the-cost-of-context-switching":{"type":"header","text":"The cost of context switching","value":"the-cost-of-context-switching","line":118,"column":0,"depth":3},"when-to-start-without-having-finished":{"type":"header","text":"When to start without having finished","value":"when-to-start-without-having-finished","line":134,"column":0,"depth":2},"how-finishing-what-you-start-makes-teams-more-predictable":{"type":"header","text":"How finishing what you start makes teams more predictable","value":"how-finishing-what-you-start-makes-teams-more-predictable","line":187,"column":0,"depth":2},"putting-it-all-together":{"type":"header","text":"Putting it all together","value":"putting-it-all-together","line":278,"column":0,"depth":2},"further-reading":{"type":"header","text":"Further reading","value":"further-reading","line":296,"column":0,"depth":2}},"children":[],"parent":"DzhURBGkXODQEX6gf3JVg","data":{}},"body":"\u003ch1 id=\"how-finishing-what-you-start-makes-teams-more-productive-and-predictable\"\u003eHow finishing what you start makes teams more productive and predictable\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#how-finishing-what-you-start-makes-teams-more-productive-and-predictable\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/2022/07/19/finish-what-you-start.html\"\u003ehttps://lucasfcosta.com/2022/07/19/finish-what-you-start.html\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet’s be honest. When you read this post’s title, you thought it was obvious. Yet, most people don’t follow this simple piece of advice. You know that too, and that’s probably what led you here.\u003c/p\u003e\n\u003cp\u003eWhat you \u003cem\u003edon’t\u003c/em\u003e know is \u003cem\u003ewhy\u003c/em\u003e so many people won’t finish what they start and \u003cstrong\u003ehow to illustrate and quantify the impact of unfinished work\u003c/strong\u003e. That’s what I’ll explain in this post.\u003c/p\u003e\n\u003cp\u003eFirst, I’ll expound on the reasons why finishing one piece of work before starting the next makes products better, cycle times shorter, and teams more productive.\u003c/p\u003e\n\u003cp\u003eThen, I’ll expose why some teams choose to work on multiple tasks concurrently despite that approach being suboptimal most of the time. In this section, I’ll also explain when to batch tasks, when not to, and what you should do instead.\u003c/p\u003e\n\u003cp\u003eFinally, I’ll use a few Monte Carlo simulations and cumulative flow diagrams to demonstrate how unfinished work makes teams unpredictable — statistically speaking.\u003c/p\u003e\n\u003cp\u003eAt the end of this post, I have included a small summary for you to paste on Slack or Microsoft Teams and \u003cstrong\u003econvince your team to stop starting and start finishing\u003c/strong\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIf you’re reading on a phone, click images to expand them.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"how-finishing-what-you-start-increases-productivity\"\u003eHow finishing what you start increases productivity\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#how-finishing-what-you-start-increases-productivity\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eI like burgers. Do you? I don’t like them when they’re cold, though, and it makes me unhappy to wait too long for one.\u003c/p\u003e\n\u003cp\u003eWhen I’m the only person at the burger shop, it’s not a challenge for its cooks to assemble a burger quickly and for waiters to deliver it to me while it’s still hot.\u003c/p\u003e\n\u003cp\u003eHere’s what happens when I’m the only person in the shop.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/one-burger-flow.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/one-burger-flow.png\" alt=\"The production process of a single burger.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThe production process of a single burger.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this case, considering each burger demands four steps of preparation, and each step takes one minute, my burger gets to me in four minutes.\u003c/p\u003e\n\u003cp\u003eWhen \u003cem\u003eyou\u003c/em\u003e arrive at this burger shop, the cook’s job gets a bit more difficult. Now, they have to choose between preparing our burgers concurrently or one at a time (serially).\u003c/p\u003e\n\u003cp\u003eTo illustrate these approaches, I’ll assume there’s a single cook and that they can only prepare one burger at a time. We’ll revisit this assumption later. For now, bear with me.\u003c/p\u003e\n\u003cp\u003eFirst, let’s see what happens when the cook prepares one burger at a time.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/two-burger-flow-sequential.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/two-burger-flow-sequential.png\" alt=\"Preparing burgers in series causes both their cycle-times to be the same.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003ePreparing burgers in series causes both their cycle-times to be the same.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAssuming I ordered only a bit before you, my burger still takes four minutes. Yours, however, takes eight.\u003c/p\u003e\n\u003cp\u003eNow, let’s compare the serial to the concurrent approach. In the image below, you’ll see what happens when the cook tries to prepare our burgers concurrently.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/two-burger-flow-concurrent.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/two-burger-flow-concurrent.png\" alt=\"Preparing burgers concurrently elongates the burgers\u0026#x27; cycle times.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003ePreparing burgers concurrently elongates the burgers' cycle times.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis time, you still had to wait the same amount of time for your burger, but I’ve had to wait almost twice as long for mine! Outrageous.\u003c/p\u003e\n\u003cp\u003eTo make matters worse, let me show what happens if a friend of yours comes in, places an order, and the cook decides to take the same shortsighted approach to burger-making.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/three-burger-flow-concurrent.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/three-burger-flow-concurrent.png\" alt=\"The more burgers the cook prepares concurrently, the longer cycle times become.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThe more burgers the cook prepares concurrently, the longer cycle times become.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this scenario, I took ten minutes to taste my burger, and you took twelve. Thanks to your friend, I had to wait an extra six minutes, and you had to wait for an extra three.\u003c/p\u003e\n\u003cp\u003eSuch a disappointing burger-preparing performance demands vigorous action to be taken.\u003c/p\u003e\n\u003cp\u003ePersonally, I’d prefer to educate the cook rather than kick you and your friend out of the shop because I believe every hard-working engineer deserves a succulent burger on a Friday night.\u003c/p\u003e\n\u003cp\u003eHere’s what we’ll do. First, we’ll illustrate what would’ve happened had the cook decided to prepare each of our burgers in series. Then, we’ll enter the kitchen, hand them the schematics, and explain the optimal approach.\u003c/p\u003e\n\u003cp\u003eCome join my table, grab a pen, and let’s get drawing.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/three-burger-flow-serial.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/three-burger-flow-serial.png\" alt=\"Preparing three burgers in series ensures that all burgers\u0026#x27; cycle times remain equal, and that the first two will be delivered earlier.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003ePreparing three burgers in series ensures that all burgers' cycle times remain equal, and that the first two will be delivered earlier.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAs our drawing shows, had the cook prepared our three burgers in series, you and I would have had to wait the same amount of time for our burgers as before — 4 and 8 minutes. Your friend’s burger would still have taken twelve minutes, but that’s what they deserve for being late for dinner.\u003c/p\u003e\n\u003cp\u003eNow, before showing our drawing to the cook, let’s take a moment to compare burger-making with the equally noble activity of software development.\u003c/p\u003e\n\u003cp\u003eImagine you have features A and B in your backlog, for example.\u003c/p\u003e\n\u003cp\u003eIf each feature takes three units of time to deliver, working on them in parallel makes A take two units of time longer to deliver than it would have taken had you finished it before starting B.\u003c/p\u003e\n\u003cp\u003eFurthermore, working on these features concurrently demands B’s specifications to be written earlier than they would have been otherwise.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/features-concurrent.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/features-concurrent.png\" alt=\"Working on features concurrently causes features to take longer.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eWorking on features concurrently causes features to take longer.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eOn the other hand, if you finish A before starting B, you’ll deliver A earlier, and you’ll buy yourself more time to work on B’s specifications. During that time, you can collect more information to boost B’s chance of success.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/features-in-series.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/features-in-series.png\" alt=\"Working on features in series shortens each feature\u0026#x27;s cycle time, and allows the first to be delivered earlier.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eWorking on features in series shortens each feature's cycle time, and allows the first to be delivered earlier.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, \u003cstrong\u003ein the software industry, both tasks take longer to deliver whenever you start a new feature before finishing the first. Moreover, the first task will be delivered later than it could have been.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFurthermore, the likelihood of the second feature succeeding is smaller because you were working on top of specifications that were older than they could have been. Had you waited a bit longer, you’d have had more time to digest customer feedback and incorporate new information into the second feature’s specification.\u003c/p\u003e\n\u003cp\u003eThat’s what just-in-time means: \u003cstrong\u003einstead of starting each feature as early as possible, you start it as late as you can afford to\u003c/strong\u003e, and incorporate as much feedback and information into the spec in the meantime.\u003c/p\u003e\n\u003cp\u003eThis same effect happens when a critical bug appears. \u003ca href=\"https://lucasfcosta.com/2022/07/15/long-term-plans-dont-work.html\"\u003eAs I’ve previously explained\u003c/a\u003e, such urgent work stops you from finishing your current task, delays it, and causes all other tasks in progress to take longer \u003cem\u003eon average\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eWe can summarise this behaviour using \u003ca href=\"https://en.wikipedia.org/wiki/Little%27s_law\"\u003eLittle’s Law\u003c/a\u003e, which, when expressed in terms of throughput (deliveries per unit of time), looks like this:\u003c/p\u003e\n\u003cp\u003eAvg. Cycle Time\\=Avg. Work In ProgressAvg. Throughput {Avg.\\ Cycle\\ Time} = \\cfrac{Avg.\\ Work\\ In\\ Progress}{Avg.\\ Throughput} Avg. Cycle Time\\=Avg. ThroughputAvg. Work In Progress​\u003c/p\u003e\n\u003cp\u003eAs I’ve explained using the burger shop example, and as Little’s Law dictates, cycle times elongate when work in progress increases and throughput remains the same. It’s a straightforward mathematical fact. Nonetheless, many managers are unaware of it.\u003c/p\u003e\n\u003cp\u003eDespite the simple mathematics, when some managers see that work is taking longer to finish, they start \u003cem\u003emore\u003c/em\u003e work hoping that starting tasks earlier causes them to finish earlier. This attitude leads to the exact \u003cem\u003eopposite\u003c/em\u003e of the result they’d like to achieve: it \u003cem\u003eincreases\u003c/em\u003e cycle times.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIf you wish to keep cycle-times low, you should limit work in progress\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eYou can argue with me, your team, or your manager as much as you want, but you can’t argue with mathematics. \u003cstrong\u003eLimit work in progress\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3 id=\"the-cost-of-context-switching\"\u003eThe cost of context switching\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#the-cost-of-context-switching\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThere’s yet a third crucial aspect to consider in the world of software development: the cost of context switching.\u003c/p\u003e\n\u003cp\u003eWhen preparing burgers, it’s effortless to shift from working on one burger to another. When writing software, on the other hand, context-switching incurs a high cost.\u003c/p\u003e\n\u003cp\u003eWorking on tasks concurrently delays their cycle times not only because of the interleaving activities but also because every time an engineer has to switch context, they take more time to get back into a “flow state”.\u003c/p\u003e\n\u003cp\u003eHere’s a more accurate representation of what happens when working on software development tasks concurrently:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/features-concurrent-context-switch.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/features-concurrent-context-switch.png\" alt=\"There\u0026#x27;s a cost for switching from working on a feature to working on another.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThere's a cost for switching from working on a feature to working on another.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eEnough talking. Let’s bring our plan into the kitchen.\u003c/p\u003e\n\u003ch2 id=\"when-to-start-without-having-finished\"\u003eWhen to start without having finished\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#when-to-start-without-having-finished\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eYou and I delve into the kitchen with our drawing in our hands, the power of mathematics under our arms and tell the cook:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“Hey, look, here’s why you should prepare one burger at a time” \u003cem\u003e*points to drawing*\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe cook seems abhorred and goes on to explain:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNo matter how rare you like your patties, they all take significant time to prepare.\u003cbr\u003e\nIt’s quicker for me to prepare them in larger batches than to wait for one patty to be ready before I toss another on the grill.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe cook has a point. Neither you nor I know anything about the craft of burger-making; how could we expect to be right?\u003c/p\u003e\n\u003cp\u003eNevertheless, there’s a lesson to be taught here — one about batch sizes and transaction costs.\u003c/p\u003e\n\u003cp\u003eWhenever it’s expensive to move a work product, in this case, a patty, from one stage of the production process to the next, that transition will happen less often so that you can pay the transaction cost only once by moving multiple items at a time.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/small-batches-vs-large-batches-patties.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/small-batches-vs-large-batches-patties.png\" alt=\"When it\u0026#x27;s costly to move items from one stage to the next, items batch-up.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eWhen it's costly to move items from one stage to the next, items batch-up.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThat’s why you don’t buy a single egg whenever you go to the supermarket. Going to the supermarket has a significant transaction cost, so you purchase eggs in larger batches. In fact, the farther from your home the supermarket is, the more likely it is for the batch of eggs you bring home to be larger.\u003c/p\u003e\n\u003cp\u003eIt’s only when the cost of keeping the patties in the grill exceeds the cost of sending them to the counter that the cook will do so.\u003c/p\u003e\n\u003cp\u003eTo summarise: whenever a transaction’s cost goes up, that transaction happens less frequently.\u003c/p\u003e\n\u003cp\u003eFurthermore, if the cost of holding items at a particular stage of the process is lower than the cost of pushing those items forward, it’s better to hold them.\u003c/p\u003e\n\u003cp\u003eThat’s also the reason why \u003ca href=\"https://martinfowler.com/bliki/FrequencyReducesDifficulty.html\"\u003eMartin Fowler and Jez Humble\u003c/a\u003e advocate that \u003ca href=\"https://www.goodreads.com/quotes/1314241-if-it-hurts-do-it-more-frequently-and-bring-the\"\u003e“if something is painful, you should do it more often”\u003c/a\u003e, especially when it comes to deploying software. If you’re forced to do something often, you’ll naturally gravitate towards decreasing the cost of doing it.\u003c/p\u003e\n\u003cp\u003eYou can notice the same effect happens with automated tests. If you have to manually test your software for a few hours before you ship it, you’ll hold changes for longer and test larger batches at once.\u003c/p\u003e\n\u003cp\u003eIn the software industry, there are several problems with large batch transferrals:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThey delay feedback because features take longer to get to customers\u003c/li\u003e\n\u003cli\u003eThey make it more difficult to trace bugs because the delta between each version is larger\u003c/li\u003e\n\u003cli\u003eThey increase the overhead of change management because they make versioning and automatic rollbacks more difficult to do\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThese problems exponentially increase the costs of holding software tasks as opposed to pushing them forward.\u003c/p\u003e\n\u003cp\u003eThe reason many people fail to acknowledge and act upon transaction costs in the software industry is that they compare software — a design process — to manufacturing processes.\u003c/p\u003e\n\u003cp\u003eIn manufacturing, the cost of holding pieces in a factory is linear. The holding cost for a piece is just the cost of keeping it in storage multiplied by the number of days it will be there. On the other hand, in software development, when holding a particular piece of work, you’ll experience a negative compounding effect due to the lack of feeback, the larger deltas between versions, and the overall harm to the overall system reliability.\u003c/p\u003e\n\u003cp\u003eNow that we understand the burger and the software variations of the problem, we can make a recommendation to both cooks and software engineers alike:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReducing transaction costs enables small batches. Small batches, in turn, reduce average cycle times, diminish risk, and enhance reliability\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eYou should only start without having finished when transaction costs are high, and it wouldn’t make economic sense to spend time decreasing them, either because you have agreed to a particular delivery date or because you don’t have the capital to invest.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThat said, I’d be careful to avoid falling into a situation where “you’re too busy draining the flood to be able to fix the leak”. The earlier you decrease transaction costs, the earlier you’ll be reaping the benefits from having done it.\u003c/p\u003e\n\u003ch2 id=\"how-finishing-what-you-start-makes-teams-more-predictable\"\u003eHow finishing what you start makes teams more predictable\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#how-finishing-what-you-start-makes-teams-more-predictable\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eDespite coming into the kitchen to offer unsolicited advice, you and I have become good friends with the cook. Now, it’s time for them to teach us a thing or two about how we can deliver software more predictably.\u003c/p\u003e\n\u003cp\u003eIn the burger shop’s kitchen, there’s a limit to how many patties you can put on the grill. Furthermore, zero burgers are in progress at the end of the day. “These constraints allow me to provide burger-eaters with predictable delivery times”, — says the cook.\u003c/p\u003e\n\u003cp\u003eTo understand why those constraints help the cook, let’s plot the burger shop’s arrivals and departures using \u003ca href=\"https://en.wikipedia.org/wiki/Cumulative_flow_diagram\"\u003ea cumulative flow diagram\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, let’s plot a cumulative flow diagram illustrating what happens when the cook prepares many burgers at once — a large batch.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/cfd-large-batches.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/cfd-large-batches.png\" alt=\"With large batches, there\u0026#x27;s more variability in cycle times.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eWith large batches, there's more variability in cycle times.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAs the diagram shows, a customer who arrives early waits for a long time for their burger, while a customer who comes later waits much less. In other words, there’s a significant amount of variability in the time customers have to wait until they get their burger — shown by the area in blue.\u003c/p\u003e\n\u003cp\u003eNow, let’s see what happens when the cook prepares fewer burgers at a time.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/cfd-small-batches.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/cfd-small-batches.png\" alt=\"Smaller batches decrease cycle time variability.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eSmaller batches decrease cycle time variability.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis time, a customer who arrived early doesn’t have to wait much longer than the customer who came later. As shown by the area in blue, there’s less variability in the time it takes for customers to get burgers.\u003c/p\u003e\n\u003cp\u003eAfter looking at these two diagrams, we can conclude that the larger the batch size, the more variability there is in waiting times.\u003c/p\u003e\n\u003cp\u003eAdditionally, if batch sizes vary, not only will the waiting time within a particular batch of customers be more variable, but also distinct batches of customers will see different waiting times. Customers who arrive earlier may see cycle times from 1 to 10 minutes, while customers who come later might see their burgers taking anywhere from 1 to 30 minutes, for example.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/cfd-different-batch-sizes.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/cfd-different-batch-sizes.png\" alt=\"If batch sizes also vary over time, distinct batches of customers see different variations of cycle time.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eIf batch sizes also vary over time, distinct batches of customers see different variations of cycle time.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThat’s why the cook mentioned it’s helpful to limit how many burgers they can fit on a grill: it makes batch sizes uniform.\u003c/p\u003e\n\u003cp\u003eThe same principle is valid for software development. The larger your batch sizes — the more tasks you work on in parallel — the more variability in cycle times you will see.\u003c/p\u003e\n\u003cp\u003eIn the software industry, however, we don’t have a “finite grill”. In other words, there’s no physical upper cap on how many tasks can be in progress at a time. Therefore, you must be adamant about creating work in progress limits yourself.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe lower you make WIP limits and stick to them, the less variability you’ll see in cycle times\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eBesides making your cycle-times unpredictable, the lack of WIP limits will also impact your ability to do forecasts.\u003c/p\u003e\n\u003cp\u003eImagine, for example, that your team tends to work on many tasks concurrently. In that case, most days they’ll split their attention between tasks. Then, there will be a day in which they’ll complete all those tasks, doing a large batch transferral.\u003c/p\u003e\n\u003cp\u003eLet’s simulate such a team assuming that their throughput over ten days looks like the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Each item represents the number of tasks delivered that day\nconst TEN_DAY_THROUGHPUT = [ 0, 0, 0, 0, 5, 0, 0, 0, 5, 0 ];\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf we go ahead and \u003ca href=\"https://lucasfcosta.com/2021/09/20/monte-carlo-forecasts.html\"\u003euse a Monte Carlo algorithm to simulate how many tasks this team can deliver\u003c/a\u003e in 30 days, we’ll obtain the following histogram.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/histogram-concurrent-team.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/histogram-concurrent-team.png\" alt=\"Teams that deliver many tasks at once are less predictable because there\u0026#x27;s a wider range of possible outcomes when simulating their performance.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eTeams that deliver many tasks at once are less predictable because there's a wider range of possible outcomes when simulating their performance.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this histogram, you can see a significant number of possible outcomes for this team: they may deliver anywhere from 0 to 90 tasks. Furthermore, there are plenty of likely scenarios in this distribution.\u003c/p\u003e\n\u003cp\u003eNow, let’s change the throughput samples we used in our simulation. \u003cstrong\u003eThis time, we’ll consider the team working on one task at a time, delivering in more regular intervals\u003c/strong\u003e, instead of working on plenty of tasks in parallel and delivering them all on the same day.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Each item represents the number of tasks delivered that day\nconst TEN_DAY_THROUGHPUT = [1, 1, 1, 1, 1, 2, 0, 1, 1, 1];\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlease notice that the team still delivered the same amount of tasks in those ten days. The only difference between these teams is that the second delivered tasks more uniformly.\u003c/p\u003e\n\u003cp\u003eSimulating such a team’s performance yields the histogram below.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/histogram-serial-team.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/histogram-serial-team.png\" alt=\"Teams which consistently deliver a small number of tasks are more preditable because there\u0026#x27;s a smaller range of possible outcomes when simulating their performance.\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eTeams that deliver many tasks at once are less predictable because there's a wider range of possible outcomes when simulating their performance.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIf you compare these two histograms, you’ll see that the second histogram’s distribution has fewer possible outcomes — 20 to 41 tasks instead of 0 to 90 —and results are more clustered towards the centre. In other words, its standard deviation is smaller.\u003c/p\u003e\n\u003cp\u003eTo make my point even more obvious, let’s see what happens if we assume the team always delivers one task each day.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Each item represents the number of tasks delivered that day\nconst TEN_DAY_THROUGHPUT = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1];\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAssuming our team will remain hyper-consistent, there’s only one possible outcome in the next 30 days: they’ll deliver 30 tasks.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lucasfcosta.com/assets/finish-what-you-start/histogram-uniform-team.png\"\u003e\u003cimg src=\"/assets/finish-what-you-start/histogram-uniform-team.png\" alt=\"A team which always delivers the same number of tasks each day will yield a \u0026#x22;deterministic\u0026#x22; forecast (days times throughput).\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eA team which always delivers the same number of tasks each day will yield a \"deterministic\" forecast (days * throughput).\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThe comparison between those three histograms leads to the conclusion that teams which deliver tasks more uniformly are more predictable, even if they deliver the same number of tasks within the period we’re using as the sample for our simulations.\u003c/p\u003e\n\u003ch2 id=\"putting-it-all-together\"\u003ePutting it all together\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#putting-it-all-together\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWhen you start a new task before finishing the previous, average cycle times will increase. That happens because you’ll increase the number of items in progress but maintain the same throughput.\u003c/p\u003e\n\u003cp\u003eLittle Law illustrates this behaviour by establishing a clear relationship between cycle time, work in progress, and throughput.\u003c/p\u003e\n\u003cp\u003eAvg. Cycle Time\\=Avg. Work In ProgressAvg. Throughput {Avg.\\ Cycle\\ Time} = \\cfrac{Avg.\\ Work\\ In\\ Progress}{Avg.\\ Throughput} Avg. Cycle Time\\=Avg. ThroughputAvg. Work In Progress​\u003c/p\u003e\n\u003cp\u003eAdditionally, there’s a cost to context-switching when it comes to software development tasks.\u003c/p\u003e\n\u003cp\u003eTeams which start tasks earlier than they should must also write specifications earlier. Therefore, they’ll waste an opportunity to gather feedback, digest it, and incorporate it into a feature’s specification, diminishing its chance of success.\u003c/p\u003e\n\u003cp\u003eMany times, teams will have multiple tasks in progress because moving a task from one stage to the next is costly. Consequently, these teams will attempt to transfer tasks from one stage to another in large batches to pay this high transaction cost only once.\u003c/p\u003e\n\u003cp\u003eThe problem with large batch transferrals in the software industry is that the cost of holding these tasks increases exponentially because their specifications perish, and change deltas increase, making it more difficult to find bugs. This increase in deltas also complicates change management, harming the system’s reliability.\u003c/p\u003e\n\u003cp\u003eOne last benefit of working on smaller batches of tasks at a time is that it makes teams more predictable. Delivering the same number of tasks uniformly is better than delivering multiple tasks at once because it makes cycle times uniform too. In turn, those uniform cycle times help you make better forecasts, as there will be fewer possible outcomes when simulating (or estimating) the team’s performance.\u003c/p\u003e\n\u003ch2 id=\"further-reading\"\u003eFurther reading\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#further-reading\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.co.uk/dp/B00K7OWG7O\"\u003eThe Principles of Product Development Flow: Second Generation Lean Product Development\u003c/a\u003e — \u003ca href=\"http://reinertsenassociates.com/about/\"\u003eDonald G. Reinertsen\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/dp/B013ZQ5TUQ\"\u003eActionable Agile Metrics for Predictability\u003c/a\u003e — \u003ca href=\"https://twitter.com/danvacanti\"\u003eDaniel Vacanti\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.co.uk/dp/B084WVMKLC\"\u003eWhen Will It Be Done?: Lean-Agile Forecasting to Answer Your Customers’ Most Important Question\u003c/a\u003e — \u003ca href=\"https://twitter.com/danvacanti\"\u003eDaniel Vacanti\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://lucasfcosta.com/2022/06/12/measure-queues-not-cycle-time.html\"\u003eHow high capacity utilisation hurts a team’s performance\u003c/a\u003e — \u003ca href=\"https://twitter.com/thewizardlucas\"\u003eLucas da Costa\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://lucasfcosta.com/2022/07/15/long-term-plans-dont-work.html\"\u003eWhy long-term plans don’t work and how to fix them\u003c/a\u003e — \u003ca href=\"https://twitter.com/thewizardlucas\"\u003eLucas da Costa\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"Iy0MoL0KnL55Br3AfTS2C","title":"Luke","desc":"","updated":1766965759366,"created":1644449449778,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"a724de3efd251cf89fe82a5860d9008b","links":[{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"life-tips","position":{"start":{"line":43,"column":5,"offset":2710},"end":{"line":43,"column":29,"offset":2734},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"life-tips","anchorHeader":"wodenokoto"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2026.articles","alias":"What I read in 2026","position":{"start":{"line":72,"column":3,"offset":4440},"end":{"line":72,"column":45,"offset":4482},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2026.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2025.articles","alias":"2025","position":{"start":{"line":73,"column":5,"offset":4487},"end":{"line":73,"column":32,"offset":4514},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2025.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2024.articles","alias":"2024","position":{"start":{"line":74,"column":5,"offset":4519},"end":{"line":74,"column":32,"offset":4546},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2024.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2023.articles","alias":"2023","position":{"start":{"line":75,"column":5,"offset":4551},"end":{"line":75,"column":32,"offset":4578},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2023.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2022.articles","alias":"2022","position":{"start":{"line":76,"column":5,"offset":4583},"end":{"line":76,"column":32,"offset":4610},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2022.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-struggled-brag-in","position":{"start":{"line":82,"column":3,"offset":4746},"end":{"line":82,"column":39,"offset":4782},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-struggled-brag-in"}}],"anchors":{"what-i-read-in-past":{"type":"header","text":"What I read in past","value":"what-i-read-in-past","line":76,"column":0,"depth":2}},"children":["zd4mq442jike0pr0wba1u3m","6hzeqsofq67gdk88flxlkhp","778ijii93yu5uwnrwmn5zi4","g1fngdjl25nes6fs3lip602","ZbdkdApFqLdks4Moq92R9","uoc5hhki3o4py15cesddu8q","9qf7j06jtdkm6rnx9ymvwb0","5zn10cvj7ajy2gh2is5nqmg","4qo9ma0z0yu1czns6pxl7y5","ok0e729ho7o09xetujkxc0m","GR5x8HnNFEN6fU2UBSEIK","yirtnlj8q24yutcf3ss1xqy","eq0wc6t7wl2wv221yb68ro4","7x2fnv4j6gxts08qk0jguny","ettkt3iClONnxpbGwBVLl","7l4knev6v613tbuoskvmbdg","hvh5bud6yp7dc89tuh95tr9","4fvoqrplw0cweo554usbjos","f8qsfql0a9v8thpeo82udfa","1swsbrhqi9jk41v9eodyi5q","SQqYupi6EFddTerBA8RRD","hjNeNc1F2JUh0lTWanH4h","qf0l4wbrc9jgooyzexmbq5v","o7xruzrah5wzqetottecss7","z1zo2mp6ddji5p317i4x9xw","v06c2tjelh341x4resa50fh","0yqesk4rcffwgyuab5x8rfa","sy2vkbtyu671chkvgn1yt8j","ufixpmxoydiccoh59kphrib","alswadkx4wb05y1z9iwfzfv","1daut9dpw70xd0zh5a7j5p4"],"parent":null,"data":{},"body":"\nHi there 👋. I'm a Front-end developer.\n\n---\n\n- 현실은 인간의 연산으로 완전히 파악할 수 없는 복잡계. 주어진 상황과 능력으로 할 수 있는 최선의 적응은 단순함과 꾸준함.\n\n  - 파산을 면하는 선에서 여러가지를 해보고 자신에게 맞는 걸 위주로 꾸준히. 그를 위해 단순, 편안, 쾌적함이 필요.\n\n- 🥱 -\u003e 🤔💡🌱 - [On The Death of Daydreaming](https://www.afterbabel.com/p/on-the-death-of-daydreaming)\n  - boredom -\u003e easy fun -\u003e art -\u003e profit?\n\n\u003e I've often described my motivation for building software to others using imagery: I like to go find a secluded beach, build a large, magnificent sand castle, and then walk away. Will anyone notice? Probably not. Will the waves eventually destroy it? Yep. Did I still get immense satisfaction? Absolutely. - [aliasxneo](https://news.ycombinator.com/item?id=41497113)\n\n\u003e We love to see the process, not just the result. The imperfections in your work can be beautiful if they show your struggle for perfection, not a lack of care. - [ralphammer](https://ralphammer.com/is-perfection-boring/)\n\n\u003e Simplicity, even if it sacrifices some ideal functionality has better survival characteristics than the-right-thing. - [The Rise of Worse is Better](https://www.dreamsongs.com/RiseOfWorseIsBetter.html)\n\n\u003e [Roberto Blake was talking about making 100 crappy videos](https://www.youtube.com/watch?v=OnUBaQ1Sp_E) to get better over time. Putting in the reps and improving a little bit each time.\n\u003e\n\u003e Putting in the work without expecting any external reward at first (eg views, followers, likes, etc) will pay off in the long run. - [100 Scrappy Things](https://www.florin-pop.com/blog/100-scrappy-things/)\n\n\u003e Make the difficult habitual, the habitual easy, and the easy beautiful. - [Constantin S. Stanislavski](https://www.goodreads.com/quotes/7102271-make-the-difficult-habitual-the-habitual-easy-and-the-easy)\n\n\u003e A good match is a **structured** dance, where players aim to **score** while they are following well-defined **rules**. This **freedom within a structure** is what makes it fun. - [ralphammer](https://ralphammer.com/how-to-get-started/)\n\n- [Pivot Points](https://longform.asmartbear.com/pivot-points/)\n\n  - non-judgmental aspects of personality that can be strengths in some contexts and weaknesses in others\n  - Pivot Points are fixed in the short term\n\n- [Hedged Bets](https://longform.asmartbear.com/predict-the-future/#hedged-bets)\n  - trading slightly less maximum upside for predictable, net-positive outcomes.\n\n\u003e “Motivation often comes after starting, not before. Action produces momentum.”\n\u003e [When you start a new habit, it should take less than two minutes to do.](https://jamesclear.com/how-to-stop-procrastinating)\n\u003e\n\u003e - James Clear\n\n\u003e Focus is more about **not** keeping busy when you need to wait for something.  \n\u003e Eat the boredom for a minute.\n\u003e\n\u003e - [[life-tips#wodenokoto]]\n\n\u003e [4 minutes run hard enough to push heart rate to 90%, 3 minutes recover, repeat 4 times](https://news.ycombinator.com/item?id=34213181)\n\u003e\n\u003e - https://www.ntnu.edu/cerg/advice\n\u003e - [Get running with Couch to 5K](https://www.nhs.uk/live-well/exercise/running-and-aerobic-exercises/get-running-with-couch-to-5k/)\n\n\u003e [recommended routine - bodyweightfitness](https://www.reddit.com/r/bodyweightfitness/wiki/kb/recommended_routine/) - I Don't Have This Much Time!\n\u003e\n\u003e - Don't workout at all (saves anywhere from 20 to 60 minutes, but really, really, really, really, really, really, really, really, really not recommended)\n\n\u003e 도무지 읽히지 않는 책 앞에서 내가 택한 방법은 펼쳐진 페이지 앞에서 멍때리기이다. 다르게 표현하면 이렇다. 펼쳐진 두 페이지 앞에서 오래 머물기.\n\u003e\n\u003e 책을 펼쳐놓는 것으로 충분하다. 읽지 못해도 좋다. 매일 정해진 진도를 나가야 하는 학교 수업이 아니니까. 하지만 읽지 않아도 괜찮다고 해서 펼쳐두지조차 않으면 곤란하다. 가능한 한 자주 책을 펼쳐두도록 하자. 전혀 읽지 않고 멍하니 바라보고 있다가 다시 덮게 되더라도\n\u003e\n\u003e - 막막한 독서. 시로군. P.10~13\n\n\u003e I think it should be everyone's primary focus to sleep well, drink water, get outside, get active, and eat generally decently. I hate to say it, but if you're not eating a good amount of vegetables and fruit, decent protein, sleep, etc, no amount of XYZ will catch up to that detriment. - [CE02](https://news.ycombinator.com/item?id=35056071)\n\n\u003e My real battle is doing good versus doing nothing. - [Deirdre Sullivan](https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral)\n\n[Kind Engineering](https://kind.engineering/) - How To Engineer Kindness\n\n\u003e Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. - [Teller](https://www.goodreads.com/quotes/6641527-sometimes-magic-is-just-someone-spending-more-time-on-something)\n\n---\n\n## What I read in past\n\n- [[What I read in 2026|read.2026.articles]]\n  - [[2025|read.2025.articles]]\n  - [[2024|read.2024.articles]]\n  - [[2023|read.2023.articles]]\n  - [[2022|read.2022.articles]]\n- 📝 [Gists](https://gist.github.com/Luke-SNAW)\n- 📜 [Journals](https://luke-snaw.github.io/Luke-SNAW__netlify-CMS.github.io/)\n\n---\n\n- [[journal.what-i-struggled-brag-in]]\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":false,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.115.0","enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Luke SNAW","description":"Personal knowledge space"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","siteUrl":"https://luke-snaw.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"c71w2asq7qwr9vrs3khuu9i"},"buildId":"wirstT2ztC8OQsbzKjhvw","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
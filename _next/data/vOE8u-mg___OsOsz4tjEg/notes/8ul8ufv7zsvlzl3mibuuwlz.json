{"pageProps":{"note":{"id":"8ul8ufv7zsvlzl3mibuuwlz","title":"A Completely Non-Technical Explanation of AI and Deep Learning","desc":"","updated":1682466602751,"created":1682466544483,"custom":{},"fname":"dev.ai.a-completely-non-technical-explanation-of-ai","type":"note","vault":{"fsPath":"vault"},"contentHash":"7a3b49864e4613f09faac88de5670f0b","links":[],"anchors":{"overview":{"type":"header","text":"Overview","value":"overview","line":10,"column":0,"depth":2},"day-one":{"type":"header","text":"Day One","value":"day-one","line":14,"column":0,"depth":2},"day-two":{"type":"header","text":"Day Two","value":"day-two","line":58,"column":0,"depth":2},"day-ten":{"type":"header","text":"Day Ten","value":"day-ten","line":72,"column":0,"depth":2},"neural-networks":{"type":"header","text":"Neural Networks","value":"neural-networks","line":82,"column":0,"depth":2},"day-forty":{"type":"header","text":"Day Forty","value":"day-forty","line":90,"column":0,"depth":2},"deep-learning":{"type":"header","text":"Deep Learning","value":"deep-learning","line":102,"column":0,"depth":2}},"children":[],"parent":"0yknotw2i3rxs1hc9y7kn5n","data":{}},"body":"<h1 id=\"a-completely-non-technical-explanation-of-ai-and-deep-learning\">A Completely Non-Technical Explanation of AI and Deep Learning<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#a-completely-non-technical-explanation-of-ai-and-deep-learning\"></a></h1>\n<blockquote>\n<p><a href=\"https://www.parand.com/a-completely-non-technical-explanation-of-ai.html\">https://www.parand.com/a-completely-non-technical-explanation-of-ai.html</a></p>\n</blockquote>\n<h2 id=\"overview\">Overview<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#overview\"></a></h2>\n<p>This document will explain what neural networks are and how they work, which will help you understand how AI and machine learning work. In the scenario below you'll play the part of the neural network.</p>\n<h2 id=\"day-one\">Day One<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#day-one\"></a></h2>\n<p>First day of your new job as a \"classifier\" your boss walks in and drops a big spreadsheet of numbers on your desk.</p>\n<p>\"Is this a cat?\" she asks.</p>\n<p>Confused you ask \"What?\"</p>\n<p>\"Is this a cat?\"</p>\n<p>Even more confused, you respond \"I don't know\".</p>\n<p>\"Wrong!\" she says, and slaps you across the face.</p>\n<p>Before you've had a chance to be shocked she drops another large spreadsheet on your desk. \"Is this a cat?\"</p>\n<p>\"I don't understand\" you respond.</p>\n<p>\"Wrong!\" she says, and slaps you again.</p>\n<p>Another spreadsheet. \"Is this a cat?\"</p>\n<p>Not wanting another slap, you meekly respond \"Yes?\"</p>\n<p>\"Correct! Good job!\" she says, and gives you a wonderful reward. Almost makes up for the slaps.</p>\n<p>Another spreadsheet. Cat?</p>\n<p>Slightly more confident and wanting another reward you respond \"Yes\"</p>\n<p>\"Wrong!\". Another slap.</p>\n<p>You are very confused. \"I don't understand what's going on. You haven't told me the rules, you haven't told me how to figure out something is a cat, you haven't given me the logic to figure this out. You haven't trained me.\"</p>\n<p>\"Correct\" says the boss. \"This is training. Trust me, you're going to get very good at recognizing cats\"</p>\n<p>Another spreadsheet. This time you focus on the sheet. It's 256 columns and 256 rows, filled with numbers. Is it a cat? You don't know, so you guess.</p>\n<p>Another and another. Right, wrong, wrong, right again, it keeps going. Slaps and rewards.</p>\n<p>You're starting to notice some patterns - if the sheet is almost all zeros then it's not a cat. You look at the center of the sheet - that part should have larger numbers.</p>\n<p>It's getting slightly better - you're getting more rewards than slaps, guessing correctly more often than not. It's all about the patterns of the numbers.</p>\n<h2 id=\"day-two\">Day Two<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#day-two\"></a></h2>\n<p>This is the strangest job you've ever had. The slaps are terrible, but the rewards are so great you don't want to quit. How do you get better at this? It's not really possible for one person. If you had more people they could focus on different aspects of the sheet, look for different patterns, and you could use their findings to make better guesses.</p>\n<p>You hire 10 people and bring them to work the next day. When you get a spreadsheet you show it to those 10 people and ask them \"Is this a cat?\"</p>\n<p>They are as confused as you were. You force them to guess. The first guy looks like an idiot, so you decide to go with the opposite of what he says. The third lady looks really thoughtful so you put a lot of weight on what she says. In your mind you assign a weight to each of their guesses to come up with your final answer.</p>\n<p>Each time you get a reward or punishment you share it with the 10 people you've hired: you reward or slap them based on how much weight you put on their input and how much they contributed to you getting the answer right or wrong. You learn the patterns: if the first guy says a strong no and the third lady a strong yes then it's very likely a cat. You learn many more patterns like this.</p>\n<p>The 10 people are learning to hone their opinions based on the rewards and punishments they get. They can focus on different aspects of the sheet, and their opinions together can tell you a lot about the sheet.</p>\n<p>After what feels like an epoch and a lot of spreadsheets, eventually you get better. You're getting more rewards. This is working. Your boss says you're very perceptive, and starts calling you Perceptron.</p>\n<h2 id=\"day-ten\">Day Ten<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#day-ten\"></a></h2>\n<p>What if you get more people involved? You could make it 50 people reporting to you, but that'd be hard to manage. How about we add another layer of people before your 10?</p>\n<p>You hire 50 more people, have them give their guesses to the 10 people that report to you. You're now very removed from looking at the spreadsheets - instead you rely on the patterns found by the first layer of the people, who give their opinions to the second layer of the people, who then inform you. Everybody passes the slaps and rewards down the line based on how much each earlier person's guess contributed to their guess.</p>\n<p>It takes even longer, but eventually the system starts working. You're much more accurate in identifying when it's a cat.</p>\n<p>Interestingly you were never taught the rules or logic, and you didn't teach your people the logic or rules. You just propagated the rewards and punishments back through each layer: the more each person's opinion contributes to the answer, the more rewards or punishment you shared with them, and they in turn with the people in the layer behind them. Each person uses the same method to propogate their rewards and punishment back to the people in the layer below them.</p>\n<h2 id=\"neural-networks\">Neural Networks<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#neural-networks\"></a></h2>\n<p>This is how neural networks work: they see many examples and get rewarded or punished based on whether their guesses are correct. They use multiple layers of workers and eventually learn patterns. Importantly no one is teaching them what patterns they should be looking for or telling them the logic or the rules - the networks eventually figure out the patterns and logic based on very many rounds of example, reward, and punishment. This is called <strong>machine learning</strong>, because the machine is learning the rules by itself.</p>\n<p>Neural networks work well when you have many examples of something (eg. pictures of cats), but it's hard to write the logic and rules to describe how to recognize that thing. Try it - write down some rules for how to recognize a cat (eg. \"has 4 legs\"), then look at pictures of cats and see where the rules fail (eg. a picture of a cat's head). In these cases you use machine learning so the machine learns the rules by itself.</p>\n<p>Also note that computers see things as multi-dimensional tables of data. They don't look at a \"picture\" - they see 3 spreadsheets of numbers representing the RGB values of the picture.</p>\n<h2 id=\"day-forty\">Day Forty<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#day-forty\"></a></h2>\n<p>Identifying cats is a lucrative business and you're pretty good at it. But not good enough. How can we get even better? More people, more layers!</p>\n<p>Unfortunately it takes a long time for people to do their calculations, so you've been stuck with just a few layers of people for a while. Having a lot more people would make the process take too long.</p>\n<p>One day you run into a group of people who call themselves Gaming People United (GPU). These people play a game that has taught them to be very good at looking at spreadsheets and calculating numbers - in fact they can do a lot of calculations in parallel, very quickly.</p>\n<p>Excited, you hire a bunch of them and put them to work recognizing cats. Now instead of two layers of people you can have 10! Each layer can focus on higher and higher concepts - the first layer can look for small details (eg. do I see a pattern that looks like a small circle? Do I see a pattern that looks like a sharp edge?), the second layer can look for patterns from the results of the first layer (eg. are there two circles close to each other), the third layer can build on that (eg. are there two circle close to each other, and a triangle below them), and so forth. By the time the results of the layers get to you you have some fairly sophisticated concepts - we see a pattern that looks like a face, we also see patterns that could be legs, and a sharp thing that might be a beak. Now your guess is more informed than ever.</p>\n<p>You train the layers sending slaps and rewards down through each layer, and after many epochs you get really good at recognizing cats.</p>\n<h2 id=\"deep-learning\">Deep Learning<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#deep-learning\"></a></h2>\n<p>One of the major break-throughs in machine learning was the advent of <em>Deep Learning</em>, which is basically what we describe above - GPUs (Graphics Processing Units) got popular because they enable fast 3D graphics for games. They also happen to be very good at quickly doing the types of calculations neural networks need. Machine learning people started using GPUs for training neural networks, and with this extra speed they could have many more layers - from 3 or 4 layers to 10 or 11, and then hundreds.</p>\n<p>This addition of layers led to significant advances in neural network performance - very quickly neural networks became the best solution for voice recognition, for image recognition, image creation, and sophisticated language models. This is called <strong>Deep Learning</strong> because there are so many layers, not because it's profound.</p>","noteIndex":{"id":"Iy0MoL0KnL55Br3AfTS2C","title":"Luke","desc":"","updated":1761796791487,"created":1644449449778,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"4e745570ca97988a0362cb939b760952","links":[{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"life-tips","position":{"start":{"line":41,"column":5,"offset":2603},"end":{"line":41,"column":29,"offset":2627},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"life-tips","anchorHeader":"wodenokoto"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2025","alias":"What I read in 2025","position":{"start":{"line":70,"column":3,"offset":4333},"end":{"line":70,"column":54,"offset":4384},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2025"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2024","alias":"2024","position":{"start":{"line":71,"column":5,"offset":4389},"end":{"line":71,"column":41,"offset":4425},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2024"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2023","alias":"2023","position":{"start":{"line":72,"column":5,"offset":4430},"end":{"line":72,"column":41,"offset":4466},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2023"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-read-in.2022","alias":"2022","position":{"start":{"line":73,"column":5,"offset":4471},"end":{"line":73,"column":41,"offset":4507},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-read-in.2022"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-struggled-brag-in","position":{"start":{"line":79,"column":3,"offset":4643},"end":{"line":79,"column":39,"offset":4679},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-struggled-brag-in"}}],"anchors":{"what-i-read-in-past":{"type":"header","text":"What I read in past","value":"what-i-read-in-past","line":74,"column":0,"depth":2}},"children":["zd4mq442jike0pr0wba1u3m","6hzeqsofq67gdk88flxlkhp","778ijii93yu5uwnrwmn5zi4","g1fngdjl25nes6fs3lip602","ZbdkdApFqLdks4Moq92R9","uoc5hhki3o4py15cesddu8q","9qf7j06jtdkm6rnx9ymvwb0","5zn10cvj7ajy2gh2is5nqmg","4qo9ma0z0yu1czns6pxl7y5","ok0e729ho7o09xetujkxc0m","GR5x8HnNFEN6fU2UBSEIK","yirtnlj8q24yutcf3ss1xqy","eq0wc6t7wl2wv221yb68ro4","7x2fnv4j6gxts08qk0jguny","ettkt3iClONnxpbGwBVLl","7l4knev6v613tbuoskvmbdg","hvh5bud6yp7dc89tuh95tr9","4fvoqrplw0cweo554usbjos","f8qsfql0a9v8thpeo82udfa","1swsbrhqi9jk41v9eodyi5q","SQqYupi6EFddTerBA8RRD","hjNeNc1F2JUh0lTWanH4h","qf0l4wbrc9jgooyzexmbq5v","uur1lkol353z9vfeqb3n5bv","cd9n1czq3ursgkby985wkmm","k1sr43vwnfqztwc0s43pkcf","wfde75rhdvq2yfa2zy2q6rv","rjcmdv60jokmbw6zoq8u2ef","ujapvww8o6v3kpmlhtryq4k","pkwewou9d5e8ystswn1j2b4"],"parent":null,"data":{},"body":"\nHi there 👋. I'm a Front-end developer.\n\n---\n\n- 단순함과 꾸준함은 가장 쉬우면서도 지키기 어려운 원칙.\n\n- 🥱 -> 🤔💡🌱 - [On The Death of Daydreaming](https://www.afterbabel.com/p/on-the-death-of-daydreaming)\n  - boredom -> easy fun -> art -> profit?\n\n> I've often described my motivation for building software to others using imagery: I like to go find a secluded beach, build a large, magnificent sand castle, and then walk away. Will anyone notice? Probably not. Will the waves eventually destroy it? Yep. Did I still get immense satisfaction? Absolutely. - [aliasxneo](https://news.ycombinator.com/item?id=41497113)\n\n> We love to see the process, not just the result. The imperfections in your work can be beautiful if they show your struggle for perfection, not a lack of care. - [ralphammer](https://ralphammer.com/is-perfection-boring/)\n\n> Simplicity, even if it sacrifices some ideal functionality has better survival characteristics than the-right-thing. - [The Rise of Worse is Better](https://www.dreamsongs.com/RiseOfWorseIsBetter.html)\n\n> [Roberto Blake was talking about making 100 crappy videos](https://www.youtube.com/watch?v=OnUBaQ1Sp_E) to get better over time. Putting in the reps and improving a little bit each time.\n>\n> Putting in the work without expecting any external reward at first (eg views, followers, likes, etc) will pay off in the long run. - [100 Scrappy Things](https://www.florin-pop.com/blog/100-scrappy-things/)\n\n> Make the difficult habitual, the habitual easy, and the easy beautiful. - [Constantin S. Stanislavski](https://www.goodreads.com/quotes/7102271-make-the-difficult-habitual-the-habitual-easy-and-the-easy)\n\n> A good match is a **structured** dance, where players aim to **score** while they are following well-defined **rules**. This **freedom within a structure** is what makes it fun. - [ralphammer](https://ralphammer.com/how-to-get-started/)\n\n- [Pivot Points](https://longform.asmartbear.com/pivot-points/)\n\n  - non-judgmental aspects of personality that can be strengths in some contexts and weaknesses in others\n  - Pivot Points are fixed in the short term\n\n- [Hedged Bets](https://longform.asmartbear.com/predict-the-future/#hedged-bets)\n  - trading slightly less maximum upside for predictable, net-positive outcomes.\n\n> “Motivation often comes after starting, not before. Action produces momentum.”\n> [When you start a new habit, it should take less than two minutes to do.](https://jamesclear.com/how-to-stop-procrastinating)\n>\n> - James Clear\n\n> Focus is more about **not** keeping busy when you need to wait for something.  \n> Eat the boredom for a minute.\n>\n> - [[life-tips#wodenokoto]]\n\n> [4 minutes run hard enough to push heart rate to 90%, 3 minutes recover, repeat 4 times](https://news.ycombinator.com/item?id=34213181)\n>\n> - https://www.ntnu.edu/cerg/advice\n> - [Get running with Couch to 5K](https://www.nhs.uk/live-well/exercise/running-and-aerobic-exercises/get-running-with-couch-to-5k/)\n\n> [recommended routine - bodyweightfitness](https://www.reddit.com/r/bodyweightfitness/wiki/kb/recommended_routine/) - I Don't Have This Much Time!\n>\n> - Don't workout at all (saves anywhere from 20 to 60 minutes, but really, really, really, really, really, really, really, really, really not recommended)\n\n> 도무지 읽히지 않는 책 앞에서 내가 택한 방법은 펼쳐진 페이지 앞에서 멍때리기이다. 다르게 표현하면 이렇다. 펼쳐진 두 페이지 앞에서 오래 머물기.\n>\n> 책을 펼쳐놓는 것으로 충분하다. 읽지 못해도 좋다. 매일 정해진 진도를 나가야 하는 학교 수업이 아니니까. 하지만 읽지 않아도 괜찮다고 해서 펼쳐두지조차 않으면 곤란하다. 가능한 한 자주 책을 펼쳐두도록 하자. 전혀 읽지 않고 멍하니 바라보고 있다가 다시 덮게 되더라도\n>\n> - 막막한 독서. 시로군. P.10~13\n\n> I think it should be everyone's primary focus to sleep well, drink water, get outside, get active, and eat generally decently. I hate to say it, but if you're not eating a good amount of vegetables and fruit, decent protein, sleep, etc, no amount of XYZ will catch up to that detriment. - [CE02](https://news.ycombinator.com/item?id=35056071)\n\n> My real battle is doing good versus doing nothing. - [Deirdre Sullivan](https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral)\n\n[Kind Engineering](https://kind.engineering/) - How To Engineer Kindness\n\n> Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. - [Teller](https://www.goodreads.com/quotes/6641527-sometimes-magic-is-just-someone-spending-more-time-on-something)\n\n---\n\n## What I read in past\n\n- [[What I read in 2025|journal.what-i-read-in.2025]]\n  - [[2024|journal.what-i-read-in.2024]]\n  - [[2023|journal.what-i-read-in.2023]]\n  - [[2022|journal.what-i-read-in.2022]]\n- 📝 [Gists](https://gist.github.com/Luke-SNAW)\n- 📜 [Journals](https://luke-snaw.github.io/Luke-SNAW__netlify-CMS.github.io/)\n\n---\n\n- [[journal.what-i-struggled-brag-in]]\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":false,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.115.0","enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Luke SNAW","description":"Personal knowledge space"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","siteUrl":"https://luke-snaw.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}
{"pageProps":{"note":{"id":"iigqo2m0kkvm741rsklhgti","title":"Explaining The Postgres Meme","desc":"","updated":1693810102986,"created":1693809553384,"tags":"bookshelf","custom":{},"fname":"dev.DB.postgres.explaining-the-postgres-meme","type":"note","vault":{"fsPath":"vault"},"contentHash":"a94089363c86507ef713f58a9a4bb6a0","links":[{"type":"frontmatterTag","from":{"fname":"dev.DB.postgres.explaining-the-postgres-meme","id":"iigqo2m0kkvm741rsklhgti","vaultName":"vault"},"value":"tags.bookshelf","alias":"bookshelf","xvault":false,"to":{"fname":"tags.bookshelf"}}],"anchors":{"credits":{"type":"header","text":"CREDITS","value":"credits","line":22,"column":0,"depth":4},"attention":{"type":"header","text":"ATTENTION","value":"attention","line":26,"column":0,"depth":4},"levels":{"type":"header","text":"Levels","value":"levels","line":32,"column":0,"depth":2},"level-0-sky-zone":{"type":"header","text":"Level 0: Sky Zone","value":"level-0-sky-zone","line":45,"column":0,"depth":2},"data-types":{"type":"header","text":"Data Types","value":"data-types","line":53,"column":0,"depth":3},"create-table":{"type":"header","text":"CREATE TABLE","value":"create-table","line":71,"column":0,"depth":3},"select-insert-update-delete":{"type":"header","text":"SELECT, INSERT, UPDATE, DELETE","value":"select-insert-update-delete","line":92,"column":0,"depth":3},"order-by":{"type":"header","text":"ORDER BY","value":"order-by","line":127,"column":0,"depth":3},"limit-and-offset":{"type":"header","text":"LIMIT and OFFSET","value":"limit-and-offset","line":139,"column":0,"depth":3},"beware-this-method-for-pagination-might-be-slow":{"type":"header","text":"Beware: This method for pagination might be slow!","value":"beware-this-method-for-pagination-might-be-slow","line":150,"column":0,"depth":4},"group-by":{"type":"header","text":"GROUP BY","value":"group-by","line":154,"column":0,"depth":3},"null":{"type":"header","text":"NULL","value":"null","line":170,"column":0,"depth":3},"indexes":{"type":"header","text":"Indexes","value":"indexes","line":183,"column":0,"depth":3},"join":{"type":"header","text":"JOIN","value":"join","line":197,"column":0,"depth":3},"foreign-keys":{"type":"header","text":"Foreign Keys","value":"foreign-keys","line":221,"column":0,"depth":3},"orms":{"type":"header","text":"ORMs","value":"orms","line":246,"column":0,"depth":3},"level-1-surface-zone":{"type":"header","text":"Level 1: Surface Zone","value":"level-1-surface-zone","line":277,"column":0,"depth":2},"transactions":{"type":"header","text":"Transactions","value":"transactions","line":285,"column":0,"depth":3},"acid":{"type":"header","text":"ACID","value":"acid","line":300,"column":0,"depth":3},"query-plans-and-explain":{"type":"header","text":"Query plans and EXPLAIN","value":"query-plans-and-explain","line":311,"column":0,"depth":3},"inverted-indexes":{"type":"header","text":"Inverted Indexes","value":"inverted-indexes","line":428,"column":0,"depth":3},"keyset-pagination":{"type":"header","text":"Keyset Pagination","value":"keyset-pagination","line":438,"column":0,"depth":3},"computed-columns":{"type":"header","text":"Computed Columns","value":"computed-columns","line":453,"column":0,"depth":3},"stored-columns":{"type":"header","text":"Stored Columns","value":"stored-columns","line":465,"column":0,"depth":3},"order-by-aggregates":{"type":"header","text":"ORDER BY Aggregates","value":"order-by-aggregates","line":484,"column":0,"depth":3},"window-functions":{"type":"header","text":"Window Functions","value":"window-functions","line":511,"column":0,"depth":3},"outer-joins":{"type":"header","text":"Outer Joins","value":"outer-joins","line":564,"column":0,"depth":3},"ctes":{"type":"header","text":"CTEs","value":"ctes","line":584,"column":0,"depth":3},"normal-forms":{"type":"header","text":"Normal Forms","value":"normal-forms","line":606,"column":0,"depth":3},"level-2-sunlight-zone":{"type":"header","text":"Level 2: Sunlight Zone","value":"level-2-sunlight-zone","line":620,"column":0,"depth":2},"connection-pools":{"type":"header","text":"Connection Pools","value":"connection-pools","line":628,"column":0,"depth":3},"the-dual-table":{"type":"header","text":"The DUAL Table","value":"the-dual-table","line":636,"column":0,"depth":3},"lateral-joins":{"type":"header","text":"LATERAL Joins","value":"lateral-joins","line":654,"column":0,"depth":3},"recursive-ctes":{"type":"header","text":"Recursive CTEs","value":"recursive-ctes","line":674,"column":0,"depth":3},"orms-create-bad-queries":{"type":"header","text":"ORMs create bad queries","value":"orms-create-bad-queries","line":695,"column":0,"depth":3},"stored-procedures":{"type":"header","text":"Stored Procedures","value":"stored-procedures","line":712,"column":0,"depth":3},"cursors":{"type":"header","text":"Cursors","value":"cursors","line":763,"column":0,"depth":3},"there-are-no-non-nullable-types":{"type":"header","text":"There are no non-nullable types","value":"there-are-no-non-nullable-types","line":781,"column":0,"depth":3},"optimizers-dont-work-without-table-statistics":{"type":"header","text":"Optimizers don't work without table statistics","value":"optimizers-dont-work-without-table-statistics","line":789,"column":0,"depth":3},"plan-hints":{"type":"header","text":"Plan hints","value":"plan-hints","line":797,"column":0,"depth":3},"mvcc-garbage-collection":{"type":"header","text":"MVCC Garbage Collection","value":"mvcc-garbage-collection","line":813,"column":0,"depth":3},"level-3-twilight-zone":{"type":"header","text":"Level 3: Twilight Zone","value":"level-3-twilight-zone","line":823,"column":0,"depth":2},"count-vs-count1":{"type":"header","text":"COUNT(*) vs COUNT(1)","value":"count-vs-count1","line":831,"column":0,"depth":3},"isolation-levels-and-phantom-reads":{"type":"header","text":"Isolation Levels and Phantom Reads","value":"isolation-levels-and-phantom-reads","line":862,"column":0,"depth":3},"write-skew":{"type":"header","text":"Write skew","value":"write-skew","line":893,"column":0,"depth":3},"serializable-restarts-require-retry-loops-on-all-statements":{"type":"header","text":"Serializable restarts require retry loops on all statements","value":"serializable-restarts-require-retry-loops-on-all-statements","line":908,"column":0,"depth":3},"partial-indexes":{"type":"header","text":"Partial Indexes","value":"partial-indexes","line":950,"column":0,"depth":3},"generator-functions-zip-when-cross-joined":{"type":"header","text":"Generator functions zip when cross joined","value":"generator-functions-zip-when-cross-joined","line":961,"column":0,"depth":3},"sharding":{"type":"header","text":"Sharding","value":"sharding","line":1033,"column":0,"depth":3},"zigzag-join":{"type":"header","text":"ZigZag Join","value":"zigzag-join","line":1043,"column":0,"depth":3},"merge":{"type":"header","text":"MERGE","value":"merge","line":1079,"column":0,"depth":3},"triggers":{"type":"header","text":"Triggers","value":"triggers","line":1096,"column":0,"depth":3},"grouping-sets-cube-rollup":{"type":"header","text":"Grouping sets, Cube, Rollup","value":"grouping-sets-cube-rollup","line":1110,"column":0,"depth":3},"level-4-midnight-zone":{"type":"header","text":"Level 4: Midnight Zone","value":"level-4-midnight-zone","line":1196,"column":0,"depth":2},"denormalization":{"type":"header","text":"Denormalization","value":"denormalization","line":1204,"column":0,"depth":3},"nulls-in-check-constraints-are-truthy":{"type":"header","text":"NULLs in CHECK constraints are truthy","value":"nulls-in-check-constraints-are-truthy","line":1212,"column":0,"depth":3},"transaction-contention":{"type":"header","text":"Transaction Contention","value":"transaction-contention","line":1244,"column":0,"depth":3},"select-for-update":{"type":"header","text":"SELECT FOR UPDATE","value":"select-for-update","line":1250,"column":0,"depth":3},"timestamptz-doesnt-store-a-timezone":{"type":"header","text":"timestamptz doesn't store a timezone","value":"timestamptz-doesnt-store-a-timezone","line":1280,"column":0,"depth":3},"star-schemas":{"type":"header","text":"Star Schemas","value":"star-schemas","line":1312,"column":0,"depth":3},"sargability":{"type":"header","text":"Sargability","value":"sargability","line":1320,"column":0,"depth":3},"ascending-key-problem":{"type":"header","text":"Ascending Key Problem","value":"ascending-key-problem","line":1354,"column":0,"depth":3},"ambiguous-network-errors":{"type":"header","text":"Ambiguous Network Errors","value":"ambiguous-network-errors","line":1379,"column":0,"depth":3},"utf8mb4":{"type":"header","text":"utf8mb4","value":"utf8mb4","line":1385,"column":0,"depth":3},"level-5-abyssal-zone":{"type":"header","text":"Level 5: Abyssal Zone","value":"level-5-abyssal-zone","line":1395,"column":0,"depth":2},"cost-models-dont-reflect-reality":{"type":"header","text":"Cost models don't reflect reality","value":"cost-models-dont-reflect-reality","line":1403,"column":0,"depth":3},"nulljsonb-is-null--false":{"type":"header","text":"null::jsonb IS NULL = false","value":"nulljsonb-is-null--false","line":1409,"column":0,"depth":3},"tpcc-requires-wait-times":{"type":"header","text":"TPCC requires wait times","value":"tpcc-requires-wait-times","line":1424,"column":0,"depth":3},"deferrable-initially-immediate":{"type":"header","text":"DEFERRABLE INITIALLY IMMEDIATE","value":"deferrable-initially-immediate","line":1434,"column":0,"depth":3},"explain-approximates-select-count":{"type":"header","text":"EXPLAIN approximates SELECT COUNT(*)","value":"explain-approximates-select-count","line":1453,"column":0,"depth":3},"match-partial-foreign-keys":{"type":"header","text":"MATCH PARTIAL Foreign Keys","value":"match-partial-foreign-keys","line":1469,"column":0,"depth":3},"causal-reverse":{"type":"header","text":"Causal Reverse","value":"causal-reverse","line":1477,"column":0,"depth":3},"level-6-hadal-zone":{"type":"header","text":"Level 6: Hadal Zone","value":"level-6-hadal-zone","line":1492,"column":0,"depth":2},"vectorized-doesnt-mean-simd":{"type":"header","text":"Vectorized doesn't mean SIMD","value":"vectorized-doesnt-mean-simd","line":1500,"column":0,"depth":3},"nulls-are-equal-in-distinct-but-unequal-in-unique":{"type":"header","text":"NULLs are equal in DISTINCT but unequal in UNIQUE","value":"nulls-are-equal-in-distinct-but-unequal-in-unique","line":1510,"column":0,"depth":3},"volcano-model":{"type":"header","text":"Volcano Model","value":"volcano-model","line":1561,"column":0,"depth":3},"join-ordering-is-np-hard":{"type":"header","text":"Join ordering is NP Hard","value":"join-ordering-is-np-hard","line":1589,"column":0,"depth":3},"database-cracking":{"type":"header","text":"Database Cracking","value":"database-cracking","line":1609,"column":0,"depth":3},"wcoj":{"type":"header","text":"WCOJ","value":"wcoj","line":1621,"column":0,"depth":3},"learned-indexes":{"type":"header","text":"Learned Indexes","value":"learned-indexes","line":1629,"column":0,"depth":3},"txid-exhaustion":{"type":"header","text":"TXID Exhaustion","value":"txid-exhaustion","line":1635,"column":0,"depth":3},"level-7-pitch-black-zone":{"type":"header","text":"Level 7: Pitch Black Zone","value":"level-7-pitch-black-zone","line":1645,"column":0,"depth":2},"the-halloween-problem":{"type":"header","text":"The halloween problem","value":"the-halloween-problem","line":1653,"column":0,"depth":3},"attention-1":{"type":"header","text":"ATTENTION","value":"attention-1","line":1669,"column":0,"depth":4},"dee-and-dum":{"type":"header","text":"Dee and Dum","value":"dee-and-dum","line":1673,"column":0,"depth":3},"serial-is-non-transactional":{"type":"header","text":"SERIAL is non-transactional","value":"serial-is-non-transactional","line":1680,"column":0,"depth":3},"allballs":{"type":"header","text":"allballs","value":"allballs","line":1722,"column":0,"depth":3},"fsyncgate":{"type":"header","text":"fsyncgate","value":"fsyncgate","line":1736,"column":0,"depth":3},"every-sql-operator-is-actually-a-join":{"type":"header","text":"Every SQL operator is actually a join","value":"every-sql-operator-is-actually-a-join","line":1754,"column":0,"depth":3},"null-1":{"type":"header","text":"NULL","value":"null-1","line":1770,"column":0,"depth":3},"conclusion":{"type":"header","text":"Conclusion","value":"conclusion","line":1774,"column":0,"depth":2},"references":{"type":"header","text":"References","value":"references","line":1780,"column":0,"depth":2}},"children":[],"parent":"xyg5ao6vugkef44ahxssq60","data":{}},"body":"<h1 id=\"explaining-the-postgres-meme\">Explaining The Postgres Meme<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#explaining-the-postgres-meme\"></a></h1>\n<blockquote>\n<p><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme\">https://avestura.dev/blog/explaining-the-postgres-meme</a><br>\n<a href=\"https://www.youtube.com/watch?v=JZRWkfXNQOk\">SQL iceberg explained</a></p>\n</blockquote>\n<p>I spend a significant amount of my time online, and on a regular day, I am either learning about STEM topics, indulging in memes, or both. On one such day, I came across a meme that truly caught my attention. It sparked numerous questions above my head, leading to a moment of deafening silence within me:</p>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%271280%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Fpostgres-meme.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Fpostgres-meme.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>I already knew that data storage and retrieval ain't ever been one of my strong suits, but after seeing this meme it kind of made me unsecure as I had basically zero effing clue about a huge portion of it. I felt the urge that I have to know what this is all about, so I have decided to learn from multiple sources.</p>\n<p>One of the best ways to learn something is to explain it, and this blog post aims to do exactly that. Let's review and explain every part of this meme, while unraveling its meaning and secrets.</p>\n<h4 id=\"credits\">CREDITS<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#credits\"></a></h4>\n<p>Shout out to <a href=\"https://twitter.com/largedatabank\">Jordan Lewis</a> (and friends) for creating this meme. This was initially <a href=\"https://twitter.com/largedatabank/status/1559651463919452161\">published in a tweet on twitter</a> and then went viral on other social platforms. I've personally seen it on a Telegram group, and didn't know about the origin of it while I was writing this blog post until I've finished writing about the half of it.</p>\n<h4 id=\"attention\">ATTENTION<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#attention\"></a></h4>\n<p>The meme is called \"The SQL Iceberg\" and it is a general SQL meme, not a PostgreSQL one. However, as we want to analyze it while wearing our PostgreSQL hat, I think it is safe to title this post \"Explaining The Postgres Meme\", because it is hard to target all or even major database management systems in one blog post for such a highly detailed photo. The creators of this meme happen to be the developers of CockroachDB, which is a <a href=\"https://www.cockroachlabs.com/docs/stable/postgresql-compatibility\">highly compatible database with PostgreSQL</a>, so we are probably not much far from what they had in mind when creating this meme.</p>\n<p>EDIT: Midway through writing this blog post, I discovered the origin of this meme and watched the creator's explanations. It seems that the content of this post aligns closely with the creator's intentions.</p>\n<h2 id=\"levels\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#levels\"></a>Levels<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#levels\"></a></h2>\n<p>Let's name each level in the meme:</p>\n<ul>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-0-sky-zone\">Level 0: Sky Zone</a>: <code>CREATE TABLE</code>, <code>JOIN</code>, <code>NULL</code>, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-1-surface-zone\">Level 1: Surface Zone</a>: ACID, outer joins, normal forms, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-2-sunlight-zone\">Level 2: Sunlight Zone</a>: Connection pools, LATERAL Join, Stored Procedures, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-3-twilight-zone\">Level 3: Twilight Zone</a>: Isolation levels, ZigZag Join, Triggers, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-4-midnight-zone\">Level 4: Midnight Zone</a>: Denormalization, <code>SELECT FOR UPDATE</code>, star schemas, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-5-abyssal-zone\">Level 5: Abyssal Zone</a>: <code>MATCH PARTIAL</code> foreign keys, <code>null::jsonb IS NULL = false</code>, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-6-hadal-zone\">Level 6: Hadal Zone</a>: volcano model, join ordering is NP Hard, ...</li>\n<li><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-7-pitch-black-zone\">Level 7: Pitch Black Zone</a>: <code>NULL</code>, the halloween problem, fsyncgate, ...</li>\n</ul>\n<h2 id=\"level-0-sky-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-0-sky-zone\"></a>Level 0: Sky Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-0-sky-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27152%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsky.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsky.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Sky Zone! These are the very high level concepts which everyone seem to have encountered while working with Relational Database Management Systems like PostgreSQL. Without any further ado, let's get into the topics on the sky level.</p>\n<h3 id=\"data-types\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#data-types\"></a>Data Types<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#data-types\"></a></h3>\n<p>PostgreSQL supports a large number of different data types varying from numeric, monetary, arrays, json, and xml to things like geometric, network address, and composite types. Here is <a href=\"https://www.postgresql.org/docs/current/datatype.html\">a long list of supported data types is PostgreSQL</a>.</p>\n<p>This query shows the types that are interesting to an application developer. It results <strong>87</strong> different data types on PostgreSQL version 14.1:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> typname<span class=\"token punctuation\">,</span> typlen<span class=\"token punctuation\">,</span> nspname\n<span class=\"token keyword\">from</span> pg_type t\n<span class=\"token keyword\">join</span> pg_namespace n\n<span class=\"token keyword\">on</span> t<span class=\"token punctuation\">.</span>typnamespace <span class=\"token operator\">=</span> n<span class=\"token punctuation\">.</span>oid\n<span class=\"token keyword\">where</span> nspname <span class=\"token operator\">=</span> <span class=\"token string\">'pg_catalog'</span>\n<span class=\"token operator\">and</span> typname <span class=\"token operator\">!</span><span class=\"token operator\">~</span> <span class=\"token string\">'(^_|^pg_|^reg|_handlers$)'</span>\n<span class=\"token keyword\">order</span> <span class=\"token keyword\">by</span> nspname<span class=\"token punctuation\">,</span> typname<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>As an example, if you want to store the audit logs of the actions done by admin users and need to store their IPs, you can use the <code>inet</code> type in PostgreSQL instead of storing it as <code>text</code>. This will help you to store those data more efficiently, and validate them more easily, compared to a system that doesn't support such a type (e.g. Sqlite).</p>\n<h3 id=\"create-table\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#create-table\"></a><code>CREATE TABLE</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#create-table\"></a></h3>\n<p>SQL (Structured Query Language) is composed of several areas, and each of them has a specific sub-language.</p>\n<p>One of these sub-languages is called <strong>DDL</strong> which stands for <em>data definition language</em>. It consists of statements like <code>CREATE</code>, <code>ALTER</code>, and <code>DROP</code>, which are used to defined on-disk data structures.</p>\n<p>Here is an example of a create table query:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> <span class=\"token string\">\"audit_log\"</span> <span class=\"token punctuation\">(</span>\n\tid <span class=\"token keyword\">serial</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span>\n\tip inet<span class=\"token punctuation\">,</span>\n\t<span class=\"token keyword\">action</span> <span class=\"token keyword\">text</span><span class=\"token punctuation\">,</span>\n\tactor <span class=\"token keyword\">text</span><span class=\"token punctuation\">,</span>\n\tdescription <span class=\"token keyword\">text</span><span class=\"token punctuation\">,</span>\n\tcreated_at <span class=\"token keyword\">timestamp</span> <span class=\"token keyword\">default</span> <span class=\"token function\">NOW</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>This will create an <code>audit_log</code> table with columns such as <code>id</code>, <code>ip</code>, <code>action</code>, etc.</p>\n<h3 id=\"select-insert-update-delete\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#select-insert-update-delete\"></a><code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#select-insert-update-delete\"></a></h3>\n<p><strong>DML</strong> is another one of SQL sub-languages and stands for <em>data manipulation language</em>. It covers the <code>insert</code>, <code>update</code>, and <code>delete</code> statements which are used to feed data into the database system.</p>\n<p><code>select</code> also helps us to retrieve data from the database. This is probably one of the simplest select queries in SQL:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Here are some of the examples of such DML queries:</p>\n<p>insertupdatedeleteselect</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> <span class=\"token string\">\"audit_log\"</span> <span class=\"token punctuation\">(</span>ip<span class=\"token punctuation\">,</span> <span class=\"token keyword\">action</span><span class=\"token punctuation\">,</span> actor<span class=\"token punctuation\">,</span> description<span class=\"token punctuation\">)</span> <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span>\n\t<span class=\"token string\">'127.0.0.1'</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token string\">'delete user'</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token string\">'admin'</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token string\">'admin deleted the user x'</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>The <code>table table_name</code> command can also be used to select an entire table. This sql command:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">table</span> users<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>is equivalent to</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> users<span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"order-by\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#order-by\"></a><code>ORDER BY</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#order-by\"></a></h3>\n<p>SQL does not guarantee any kind of ordering of the result set of any query, unless you specify an <code>order by</code> clause.</p>\n<p>simple order byk-nearest-neighbor ordering</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> <span class=\"token string\">\"audit_log\"</span>\n<span class=\"token keyword\">order</span> <span class=\"token keyword\">by</span> created_at <span class=\"token keyword\">desc</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"limit-and-offset\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#limit-and-offset\"></a><code>LIMIT</code> and <code>OFFSET</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#limit-and-offset\"></a></h3>\n<p><code>LIMIT</code> and <code>OFFSET</code> allow you to retrieve just a portion of the rows that are generated by the rest of the query. The below query returns audit logs number 100 to 109:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> <span class=\"token string\">\"audit_log\"</span>\n<span class=\"token keyword\">offset</span> <span class=\"token number\">100</span>\n<span class=\"token keyword\">limit</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h4 id=\"beware-this-method-for-pagination-might-be-slow\">Beware: This method for pagination might be slow!<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#beware-this-method-for-pagination-might-be-slow\"></a></h4>\n<p>In many cases, using offset will slow down the performance of your query as the database must count all rows from the beginning until it reaches the requested page. For more information, read the <a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#keyset-pagination\">Keyset pagination</a> section.</p>\n<h3 id=\"group-by\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#group-by\"></a><code>GROUP BY</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#group-by\"></a></h3>\n<p>The <code>group by</code> clause introduces <em>Aggregates</em> (aka Map/Reduce) in PostgreSQL, which enables us to map our rows into different groups and then reduce the result set into a single value.</p>\n<p>Assuming we have a <code>Student</code> table definition with <code>id</code>, <code>class_no</code> and <code>grade</code> columns, we can find the average grade of each class using this query:</p>\n<p>aggregate using group by clausetable definition</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> class_no<span class=\"token punctuation\">,</span> <span class=\"token function\">avg</span><span class=\"token punctuation\">(</span>grade<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> class_avg\n<span class=\"token keyword\">from</span> student\n<span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> class_no<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Note that the <code>Student</code> table defined this way for demonstration purposes only.</p>\n<h3 id=\"null\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#null\"></a><code>NULL</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#null\"></a></h3>\n<p>In PostgreSQL, <code>NULL</code> means <em>undefined</em> value, or simply not knowing the value, rather than the absence of a value. That is why <code>true = NULL</code>, <code>false = NULL</code>, and <code>NULL = NULL</code> checks all result in a <code>NULL</code>.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span>\n\t<span class=\"token boolean\">true</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">NULL</span> <span class=\"token keyword\">as</span> a<span class=\"token punctuation\">,</span>\n\t<span class=\"token boolean\">false</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">NULL</span> <span class=\"token keyword\">as</span> b<span class=\"token punctuation\">,</span>\n\t<span class=\"token boolean\">NULL</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">NULL</span> <span class=\"token keyword\">as</span> c<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- result= a: NULL, b: NULL, c: NULL</span>\n</code></pre>\n<h3 id=\"indexes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#indexes\"></a>Indexes<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#indexes\"></a></h3>\n<p>When used correctly, Indexes in PostgreSQL allow you to access your data much faster because they prevent the need for a sequential scan when an index is present. Additionally, certain constraints like <code>PRIMARY KEY</code> and <code>UNIQUE</code> are only possible using a backing index.</p>\n<p>Here is a simple query to create an index on <code>last_name</code> column of <code>student</code> table using <code>GiST</code> method.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">index</span> <span class=\"token keyword\">on</span> student <span class=\"token keyword\">using</span> gist<span class=\"token punctuation\">(</span>last_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Click for more details: Why do Primary Key and UNIQUE constraint need backing indexes?</p>\n<p>Click for more details: What is GiST?</p>\n<h3 id=\"join\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#join\"></a><code>JOIN</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#join\"></a></h3>\n<p>Queries can access multiple tables at once, or access the same table in such a way that multiple rows of the table are being processed at the same time. Queries that access multiple tables (or multiple instances of the same table) at one time are called join queries.</p>\n<p>We can also see joins as a way to craft new <em>Relations</em> from a pair of existing ones. A <em>relation</em> in PostgreSQL is a set of data having a common set of properties.</p>\n<p>The simple query below retrieves the admin user with its role name:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> u<span class=\"token punctuation\">.</span>username<span class=\"token punctuation\">,</span> u<span class=\"token punctuation\">.</span>email<span class=\"token punctuation\">,</span> r<span class=\"token punctuation\">.</span>role_name\n<span class=\"token keyword\">from</span> <span class=\"token string\">\"user\"</span> <span class=\"token keyword\">as</span> u\n<span class=\"token keyword\">join</span> <span class=\"token string\">\"role\"</span> <span class=\"token keyword\">as</span> r\n<span class=\"token keyword\">on</span> u<span class=\"token punctuation\">.</span>role_id <span class=\"token operator\">=</span> r<span class=\"token punctuation\">.</span>role_id <span class=\"token comment\">-- equivalent: using(role_id)</span>\n<span class=\"token keyword\">where</span> u<span class=\"token punctuation\">.</span>username <span class=\"token operator\">=</span> <span class=\"token string\">'admin'</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>There are multiple kinds of joins, including but not limited to:</p>\n<ul>\n<li><strong>Inner Joins</strong>: Only keep the rows that satisfy the join condition for both side of involved relations (left and right).</li>\n<li><strong>Left/Right/Full Outer Joins</strong>: Retrieve all records from table even for those with no matching value in either left, right, or both side of the relations.</li>\n<li><strong>Cross Join</strong>: A cartesian product of left and right relations, giving all the possible combinations from the left table rows joined with the right table rows.</li>\n</ul>\n<p>There are also some other types of joins which we will discuss in deeper levels.</p>\n<h3 id=\"foreign-keys\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#foreign-keys\"></a>Foreign Keys<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#foreign-keys\"></a></h3>\n<p>Foreign key constraints help you to maintain the <em>referential integrity</em> of your data. Assuming you have <code>Author</code> and <code>Book</code> tables, you can reference Author from the Book table, and PostgreSQL will make sure that the referencing author exists in the Author table when inserting a row into the Book table:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> author <span class=\"token punctuation\">(</span>\n\tname <span class=\"token keyword\">text</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> book <span class=\"token punctuation\">(</span>\n\tname <span class=\"token keyword\">text</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span>\n\tauthor <span class=\"token keyword\">text</span> <span class=\"token keyword\">references</span> author<span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> author <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'George Orwell'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> book <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'Animal Farm'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'George Orwell'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- OK</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> book <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'Anna Karenina'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Leo Tolstoy'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- NOT OK</span>\n<span class=\"token comment\">-- ERROR:  insert or update on table \"book\" violates foreign key constraint \"book_author_fkey\"</span>\n<span class=\"token comment\">-- DETAIL:  Key (author)=(Leo Tolstoy) is not present in table \"author\".</span>\n</code></pre>\n<p>PostgreSQL enforces the presence of either a <code>unique</code> or <code>primary key</code> constraint on the target column of the target table.</p>\n<h3 id=\"orms\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#orms\"></a>ORMs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#orms\"></a></h3>\n<p>Object-relational Mapping (ORM, O/RM, and also known as O/R Mapping tool) is a technique for mapping data to and from relational databases and an object-oriented programming language. ORMs help programmer to interact and alter the data within the database using the language constructs defined in an object-oriented programming language. In other words, ORM acts as a bridge between the object-oriented world, and the mathematical relational world.</p>\n<p>JavaC#Python</p>\n<p>java</p>\n<pre class=\"language-java\"><code class=\"language-java\"><span class=\"token comment\">// Java, Hibernate ORM</span>\n<span class=\"token annotation punctuation\">@Entity</span>\n<span class=\"token annotation punctuation\">@Table</span><span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token string\">\"Person\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Person</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token annotation punctuation\">@Id</span>\n    <span class=\"token annotation punctuation\">@GeneratedValue</span><span class=\"token punctuation\">(</span>strategy <span class=\"token operator\">=</span> <span class=\"token class-name\">GenerationType</span><span class=\"token punctuation\">.</span>IDENTITY<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">Long</span> id<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">String</span> name<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">int</span> age<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token class-name\">Configuration</span> configuration <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Configuration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">configure</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"hibernate.cfg.xml\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token class-name\">SessionFactory</span> sessionFactory <span class=\"token operator\">=</span> configuration<span class=\"token punctuation\">.</span><span class=\"token function\">buildSessionFactory</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Session</span> session <span class=\"token operator\">=</span> sessionFactory<span class=\"token punctuation\">.</span><span class=\"token function\">openSession</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t<span class=\"token class-name\">List</span><span class=\"token generics\"><span class=\"token punctuation\">&#x3C;</span><span class=\"token class-name\">Person</span><span class=\"token punctuation\">></span></span> persons <span class=\"token operator\">=</span> session<span class=\"token punctuation\">.</span><span class=\"token function\">createQuery</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"FROM Person\"</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Person</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">list</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\te<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h2 id=\"level-1-surface-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-1-surface-zone\"></a>Level 1: Surface Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-1-surface-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27152%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsurface.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsurface.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Surface Zone! Now that we have got past the sky level, we can get familiar with some of the more advanced features and concepts and dive deeper into the fundamental components and functionalities of PostgreSQL . These topics will give you a solid grounding and understanding of the database system.</p>\n<h3 id=\"transactions\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#transactions\"></a>Transactions<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#transactions\"></a></h3>\n<p>A transaction turns a bundle of steps/actions into a single \"all or nothing\" operation. The intermediate steps are not visible to other concurrently running transactions. Generally speaking, a transaction represents any change in a database.</p>\n<p>In PostgreSQL, a transaction is surrounded by <code>BEGIN</code> and <code>COMMIT</code> commands. PostgreSQL treats every SQL statement as being executed within a transaction. If you do not issue a <code>BEGIN</code> command, then each individual statement has an implicit <code>BEGIN</code> and (if successful) <code>COMMIT</code> wrapped around it. The below example shows transferring of a coin from Player1 to Player2 in the database of a video game server (the example is oversimplified):</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">BEGIN</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">update</span> accounts <span class=\"token keyword\">set</span> coins <span class=\"token operator\">=</span> coins <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token keyword\">where</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"Player1\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">update</span> accounts <span class=\"token keyword\">set</span> coins <span class=\"token operator\">=</span> coins <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">where</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"Player2\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">COMMIT</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Here we want to make sure that either all the updates are applied to database, or none of them happen. We do not want a system failure decrease coins from Player1, but no coin is added to Player2's inventory. Grouping a set of operations into a transaction gives us such guarantee.</p>\n<h3 id=\"acid\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#acid\"></a>ACID<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#acid\"></a></h3>\n<p>ACID is an acronym for Atomicity, Consistency, Isolation, and Durability. These are a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps.</p>\n<p>A database transaction should be ACID by definition:</p>\n<ul>\n<li><strong>Atomicity:</strong> A transaction must either be complete in its entirety, or have no effect. Atomicity guarantees that each transaction is treated as a single \"unit\".</li>\n<li><strong>Consistency:</strong> Ensures that a transaction can only bring the database from one consistent state to another, and prevent database corruption by an illegal transaction. As an example, a transaction should not allow a <code>NOT NULL</code> column to have a <code>NULL</code> value after a <code>COMMIT</code>.</li>\n<li><strong>Isolation:</strong> Transactions are often executed concurrently (multiple reads and writes at a time). As we have stated in the previous section, the intermediate steps are not visible to other concurrently running transactions, which means a concurrently executed transaction shouldn't have a different result compared to when the transactions were executed sequentially.</li>\n<li><strong>Durability:</strong> The database management system is not allowed to miss any committed transaction after a restart or any kind of crash. All the committed transactions should be written on non-volatile memory.</li>\n</ul>\n<h3 id=\"query-plans-and-explain\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#query-plans-and-explain\"></a>Query plans and EXPLAIN<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#query-plans-and-explain\"></a></h3>\n<p>Every database system needs a <em>planner</em> to create a <em>query plan</em> out of your SQL queries. A good query planner is critical for good performance. In PostgreSQL, the <code>EXPLAIN</code> command is used to know what query plan is created for the input query.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">explain</span> <span class=\"token keyword\">select</span> <span class=\"token string\">\"name\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"author\"</span> <span class=\"token keyword\">from</span> <span class=\"token string\">\"book\"</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- output:</span>\n<span class=\"token comment\">-- Seq Scan on book  (cost=0.00..18.80 rows=880 width=64)</span>\n</code></pre>\n<p>For a more complex query like this:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span>\n\tw<span class=\"token punctuation\">.</span>temp_lo<span class=\"token punctuation\">,</span>\n\tw<span class=\"token punctuation\">.</span>temp_hi<span class=\"token punctuation\">,</span>\n\tw<span class=\"token punctuation\">.</span>city<span class=\"token punctuation\">,</span>\n\tc<span class=\"token punctuation\">.</span>location <span class=\"token keyword\">as</span> city_location\n<span class=\"token keyword\">from</span> weather <span class=\"token keyword\">as</span> w\n<span class=\"token keyword\">join</span> city <span class=\"token keyword\">as</span> c\n<span class=\"token keyword\">on</span> c<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> w<span class=\"token punctuation\">.</span>city<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>We get more information on things like how is PostgreSQL trying to find the record (using a sequential scan or hash, etc), costs, timing, and performance information. Below information is obtained using <code>EXPLAIN ANALYZE</code> command. Using <code>ANALYSE</code> option alongside <code>EXPLAIN</code> shows the exact row counts and true run time along with estimates provided by the <code>EXPLAIN</code>:</p>\n<pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">[</span>\n  <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"Plan\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"Node Type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Hash Join\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Parallel Aware\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Async Capable\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Join Type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Inner\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Startup Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">18.1</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Total Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">55.28</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Plan Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">648</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Plan Width\"</span><span class=\"token operator\">:</span> <span class=\"token number\">202</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Actual Startup Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.024</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Actual Total Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.027</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Actual Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Actual Loops\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Inner Unique\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Hash Cond\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"((w.city)::text = (c.name)::text)\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"Plans\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"Node Type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Seq Scan\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Parent Relationship\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Outer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Parallel Aware\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Async Capable\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Relation Name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"weather\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Alias\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"w\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Startup Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Total Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">13.6</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Plan Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">360</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Plan Width\"</span><span class=\"token operator\">:</span> <span class=\"token number\">186</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Startup Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Total Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Loops\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"Node Type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Hash\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Parent Relationship\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Inner\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Parallel Aware\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Async Capable\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Startup Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">13.6</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Total Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">13.6</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Plan Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">360</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Plan Width\"</span><span class=\"token operator\">:</span> <span class=\"token number\">194</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Startup Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.008</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Total Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.008</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Actual Loops\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Hash Buckets\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Original Hash Buckets\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Hash Batches\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Original Hash Batches\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Peak Memory Usage\"</span><span class=\"token operator\">:</span> <span class=\"token number\">9</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"Plans\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span>\n              <span class=\"token property\">\"Node Type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Seq Scan\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Parent Relationship\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Outer\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Parallel Aware\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Async Capable\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Relation Name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"city\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Alias\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"c\"</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Startup Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Total Cost\"</span><span class=\"token operator\">:</span> <span class=\"token number\">13.6</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Plan Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">360</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Plan Width\"</span><span class=\"token operator\">:</span> <span class=\"token number\">194</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Actual Startup Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.004</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Actual Total Time\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.005</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Actual Rows\"</span><span class=\"token operator\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n              <span class=\"token property\">\"Actual Loops\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span>\n            <span class=\"token punctuation\">}</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"Triggers\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">]</span>\n</code></pre>\n<div class=\"table-responsive\">\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th align=\"center\">#</th><th align=\"center\">Node</th><th align=\"center\">Timings</th><th align=\"center\"></th><th align=\"center\">Rows</th><th align=\"center\"></th><th align=\"center\"></th><th align=\"center\">Loops</th><th></th></tr></thead><tbody><tr><td align=\"center\"></td><td align=\"center\"></td><td align=\"center\">Exclusive</td><td align=\"center\">Inclusive</td><td align=\"center\">Rows X</td><td align=\"center\">Actual</td><td align=\"center\">Plan</td><td align=\"center\"></td><td></td></tr><tr><td align=\"center\"></td><td align=\"center\">1.</td><td align=\"center\">Hash Inner Join (cost=18.1..55.28 rows=648 width=202) (actual=0.019..0.022 rows=3 loops=1) Hash Cond: ((w.city)::text = (c.name)::text)</td><td align=\"center\">0.007 ms</td><td align=\"center\">0.022 ms</td><td align=\"center\"> 216</td><td align=\"center\">3</td><td align=\"center\">648</td><td>1</td></tr><tr><td align=\"center\"></td><td align=\"center\">2.</td><td align=\"center\">Seq Scan on weather as w (cost=0..13.6 rows=360 width=186) (actual=0.008..0.008 rows=3 loops=1)</td><td align=\"center\">0.008 ms</td><td align=\"center\">0.008 ms</td><td align=\"center\"> 120</td><td align=\"center\">3</td><td align=\"center\">360</td><td>1</td></tr><tr><td align=\"center\"></td><td align=\"center\">3.</td><td align=\"center\">Hash (cost=13.6..13.6 rows=360 width=194) (actual=0.007..0.007 rows=3 loops=1) Buckets: 1024 Batches: 1 Memory Usage: 9 kB</td><td align=\"center\">0.003 ms</td><td align=\"center\">0.007 ms</td><td align=\"center\"> 120</td><td align=\"center\">3</td><td align=\"center\">360</td><td>1</td></tr><tr><td align=\"center\"></td><td align=\"center\">4.</td><td align=\"center\">Seq Scan on city as c (cost=0..13.6 rows=360 width=194) (actual=0.003..0.004 rows=3 loops=1)</td><td align=\"center\">0.004 ms</td><td align=\"center\">0.004 ms</td><td align=\"center\"> 120</td><td align=\"center\">3</td><td align=\"center\">360</td><td>1</td></tr></tbody></table></div>\n<p>If you have pgAdmin installed, it can show you a graphical output as well:</p>\n<p><img src=\"/static/images/posts/postgres-meme/explain-plan.svg\" alt=\"Explain Plan from pgAdmin\"></p>\n<h3 id=\"inverted-indexes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#inverted-indexes\"></a>Inverted Indexes<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#inverted-indexes\"></a></h3>\n<p>An inverted index is an index structure storing a set of <code>(key, posting list)</code> pairs, where <em>posting list</em> is a set of row IDs in which the key occurs.</p>\n<p>Inverted indexes are used when we want to index composite values (called an <em>item</em>), where each element value in the item is a key. As an example, a document is an item, and the word we're searching for inside the document is the key.</p>\n<p><img src=\"/static/images/posts/postgres-meme/inverted-index.svg\" alt=\"Explain Plan from pgAdmin\"></p>\n<p>PostgreSQL supports GIN, which stands for Generalized Inverted Index. GIN is generalized in the sense that the GIN access method code does not need to know the specific operations that it accelerates.</p>\n<h3 id=\"keyset-pagination\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#keyset-pagination\"></a>Keyset Pagination<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#keyset-pagination\"></a></h3>\n<p>There are many ways in which one can implement pagination to read only a portion of the rows from the database. As we have suggested in the <code>OFFSET</code>/<code>LIMIT</code> section, in many cases using offset will slow down the performance of your query as the database must count all rows from the beginning until it reaches the requested page. One way to overcome this is to use the Keyset pagination:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> <span class=\"token string\">\"audit_log\"</span>\n<span class=\"token keyword\">where</span> created_at <span class=\"token operator\">&#x3C;</span> ?\n<span class=\"token keyword\">limit</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- equivalent standard SQL: fetch first 10 rows only</span>\n</code></pre>\n<p>Here instead of skipping records, we simply use <code>keyset_column > x</code> where <code>x</code> is the last record from the previous page we have fetched.</p>\n<ul>\n<li>Read more: <a href=\"https://use-the-index-luke.com/sql/partial-results/fetch-next-page\">Paging Through Results by Markus Winand</a></li>\n</ul>\n<h3 id=\"computed-columns\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#computed-columns\"></a>Computed Columns<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#computed-columns\"></a></h3>\n<p>A computed or a generated column in a table is a column which its value is a function of other column in the same row. In other words, a computed column for columns is what a view is for tables. The value of a computed column can be read, but it can not be directly written. A computed/generated column is defined using <code>GENERATED ALWAYS AS</code> in PostgreSQL:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> people <span class=\"token punctuation\">(</span>\n\t<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>\n    height_cm <span class=\"token keyword\">numeric</span><span class=\"token punctuation\">,</span>\n    height_in <span class=\"token keyword\">numeric</span> GENERATED ALWAYS <span class=\"token keyword\">AS</span> <span class=\"token punctuation\">(</span>height_cm <span class=\"token operator\">/</span> <span class=\"token number\">2.54</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">-- this won't work, will explain why in the next section</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<h3 id=\"stored-columns\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#stored-columns\"></a>Stored Columns<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#stored-columns\"></a></h3>\n<p>A generated column can either be <code>stored</code> or <code>virtual</code>:</p>\n<ul>\n<li>Stored: computed when it is written (inserted or updated) and occupies storage as if it were a normal column</li>\n<li>Virtual: occupies no storage and is computed when it is read</li>\n</ul>\n<p>Thus, a virtual generated column is similar to a view and a stored generated column is similar to a materialized view (except that it is always updated automatically).</p>\n<p>If you have tried the previous query you might have faced an error. This is because at the time of writing this post PostgreSQL only implements stored generated columns, therefore you need to mark the column using <code>STORED</code>:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> people <span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span>\n    height_cm <span class=\"token keyword\">numeric</span><span class=\"token punctuation\">,</span>\n    height_in <span class=\"token keyword\">numeric</span> GENERATED ALWAYS <span class=\"token keyword\">AS</span> <span class=\"token punctuation\">(</span>height_cm <span class=\"token operator\">/</span> <span class=\"token number\">2.54</span><span class=\"token punctuation\">)</span> STORED <span class=\"token comment\">-- works fine</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"order-by-aggregates\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#order-by-aggregates\"></a><code>ORDER BY</code> Aggregates<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#order-by-aggregates\"></a></h3>\n<p>An aggregate function computes a single result from a set of input values. Some of the most famous aggregate functions are <code>min</code>, <code>max</code>, <code>sum</code>, and <code>avg</code> which are used to calculate minimum, maximum, sum, and the average of a set of results. The query below calculates the average of high and low temperatures from the weather records in the weather table:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span>\n\t<span class=\"token function\">avg</span><span class=\"token punctuation\">(</span>temp_lo<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> temp_lo_average<span class=\"token punctuation\">,</span>\n\t<span class=\"token function\">avg</span><span class=\"token punctuation\">(</span>temp_hi<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> temp_hi_average\n<span class=\"token keyword\">from</span> weather<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>The input of some aggregate functions are introduced by <code>ORDER BY</code>. These functions are sometimes referred to as inverse distribution functions. As an example, the below query shows the median rank of all players for each game server:</p>\n<p>ORDER BY aggregatetable definitions</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span>\n    <span class=\"token string\">\"server\"</span><span class=\"token punctuation\">,</span>\n    percentile_cont<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">WITHIN</span> <span class=\"token keyword\">GROUP</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">ORDER</span> <span class=\"token keyword\">BY</span> rank <span class=\"token keyword\">DESC</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> median_rank\n<span class=\"token keyword\">FROM</span> <span class=\"token string\">\"player\"</span>\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> <span class=\"token string\">\"server\"</span>\n\n<span class=\"token comment\">-- server    median_rank</span>\n<span class=\"token comment\">-- asia      2.5</span>\n<span class=\"token comment\">-- europe    5</span>\n</code></pre>\n<h3 id=\"window-functions\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#window-functions\"></a>Window Functions<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#window-functions\"></a></h3>\n<p>Window Functions are very powerful tools that let you process several values of the result set at a time. This might be similar to what we can achieve with aggregate functions, however, window functions do not cause rows to become grouped into a single output row like non-window aggregate calls would.</p>\n<p>A window function call always contains an <code>OVER</code> clause directly following the window function's name and argument(s):</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span>\n\tcity<span class=\"token punctuation\">,</span>\n\ttemp_lo<span class=\"token punctuation\">,</span>\n\ttemp_hi<span class=\"token punctuation\">,</span>\n\t<span class=\"token function\">avg</span><span class=\"token punctuation\">(</span>temp_lo<span class=\"token punctuation\">)</span> <span class=\"token keyword\">over</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">partition</span> <span class=\"token keyword\">by</span> city<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> temp_lo_average<span class=\"token punctuation\">,</span>\n\trank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">over</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">partition</span> <span class=\"token keyword\">by</span> city <span class=\"token keyword\">order</span> <span class=\"token keyword\">by</span> temp_hi<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> temp_hi_rank\n<span class=\"token keyword\">from</span> weather\n\n<span class=\"token comment\">-- city     temp_lo  temp_hi  temp_lo_average  temp_hi_rank</span>\n<span class=\"token comment\">-- Lahijan  10       20       10.33333333      1</span>\n<span class=\"token comment\">-- Lahijan  11       25       10.33333333      1</span>\n<span class=\"token comment\">-- Lahijan  10       20       10.33333333      3</span>\n<span class=\"token comment\">-- Rasht    15       45       15               1</span>\n<span class=\"token comment\">-- Rasht    20       35       15               2</span>\n<span class=\"token comment\">-- Rasht    10       30       15               3</span>\n</code></pre>\n<p>When using Window Functions, understanding the concept of <strong>window frame</strong> is necessary. For each row, there is a set of rows within its partition called its window frame. Some window functions act only on the rows of the window frame, rather than of the whole partition.</p>\n<p>In general, these are the window frame rules of thumb:</p>\n<ul>\n<li>If <code>ORDER BY</code> is supplied then the frame consists of all rows from the start of the partition up through the current row (plus any following rows that are equal to the current row according to the <code>ORDER BY</code> clause)</li>\n<li>When <code>ORDER BY</code> is omitted the default frame consists of all rows in the partition</li>\n</ul>\n<p>OVEROVER (ORDER BY salary)</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> salary<span class=\"token punctuation\">,</span> <span class=\"token function\">sum</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span> <span class=\"token keyword\">over</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> empsalary<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">--  salary |  sum</span>\n<span class=\"token comment\">-- --------+-------</span>\n<span class=\"token comment\">--    5200 | 47100</span>\n<span class=\"token comment\">--    5000 | 47100</span>\n<span class=\"token comment\">--    3500 | 47100</span>\n<span class=\"token comment\">--    4800 | 47100</span>\n<span class=\"token comment\">--    3900 | 47100</span>\n<span class=\"token comment\">--    4200 | 47100</span>\n<span class=\"token comment\">--    4500 | 47100</span>\n<span class=\"token comment\">--    4800 | 47100</span>\n<span class=\"token comment\">--    6000 | 47100</span>\n<span class=\"token comment\">--    5200 | 47100</span>\n<span class=\"token comment\">-- (10 rows)</span>\n</code></pre>\n<p>Click for more details: More frame specifications!</p>\n<h3 id=\"outer-joins\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#outer-joins\"></a>Outer Joins<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#outer-joins\"></a></h3>\n<p>As we have mentioned earlier, an outer join retrieve all records from table even for those with no matching value in either left, right, or both side of the relations.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> weather <span class=\"token keyword\">left</span> <span class=\"token keyword\">outer</span> <span class=\"token keyword\">join</span> cities <span class=\"token keyword\">ON</span> weather<span class=\"token punctuation\">.</span>city <span class=\"token operator\">=</span> cities<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">--      city      | temp_lo | temp_hi | prcp |    date    |     name      | location</span>\n<span class=\"token comment\">-- ---------------+---------+---------+------+------------+---------------+-----------</span>\n<span class=\"token comment\">--  Hayward       |      37 |      54 |      | 1994-11-29 |               |</span>\n<span class=\"token comment\">--  San Francisco |      46 |      50 | 0.25 | 1994-11-27 | San Francisco | (-194,53)</span>\n<span class=\"token comment\">--  San Francisco |      43 |      57 |    0 | 1994-11-29 | San Francisco | (-194,53)</span>\n<span class=\"token comment\">-- (3 rows)</span>\n</code></pre>\n<p>Above query shows a left outer join because the table mentioned on the left of the join operator (weather) will have each of its rows at least once in the output, whereas the table on the right (cities) will only have those rows that match a row on the left table.</p>\n<p>In PostgreSQL, <code>left outer join</code>, <code>right outer join</code>, and <code>full outer join</code> are used to do outer joins.</p>\n<h3 id=\"ctes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#ctes\"></a>CTEs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ctes\"></a></h3>\n<p><code>WITH</code> queries, or Common Table Expressions (CTEs) can be thought of as defining temporary tables that exist just for one query. Using a <code>WITH</code> clause, we can define an auxiliary statement which can be attached to a primary statement.</p>\n<p>In the query below, we first define two auxiliary tables called <code>hottest_weather_of_city</code>, and <code>not_so_hot_cities</code>, and then we use them in the primary <code>select</code> query:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">with</span> hottest_weather_of_city <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n\t<span class=\"token keyword\">select</span> city<span class=\"token punctuation\">,</span> <span class=\"token function\">max</span><span class=\"token punctuation\">(</span>temp_hi<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> max_temp_hi\n\t<span class=\"token keyword\">from</span> weather\n\t<span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> city\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> not_so_hot_cities <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n\t<span class=\"token keyword\">select</span> city\n\t<span class=\"token keyword\">from</span> hottest_weather_of_city\n\t<span class=\"token keyword\">where</span> max_temp_hi <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">35</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> weather\n<span class=\"token keyword\">where</span> city <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">select</span> city <span class=\"token keyword\">from</span> not_so_hot_cities<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>In short, Common Table Expressions is just another name for <code>WITH</code> clauses.</p>\n<h3 id=\"normal-forms\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#normal-forms\"></a>Normal Forms<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#normal-forms\"></a></h3>\n<p>Database normalization is the process of structuring a relational database in accordance with a series of so-called normal forms to reduce data redundancy and improve data integrity.</p>\n<p>There are several levels of normalization, and a higher level of database normalization cannot be achieved unless the previous levels have been satisfied.</p>\n<p>Here are some of the normal forms:</p>\n<ul>\n<li><strong>1NF:</strong> Columns cannot contain relations or composite values (each cell is single-values), and there are no duplicated rows in the table</li>\n<li><strong>2NF:</strong> Non-key columns are dependent on all of the key (it should not be dependent on a part of the composite key). In other words, there are no partial dependencies.</li>\n<li><strong>3NF:</strong> Table has no transitive dependencies.</li>\n</ul>\n<p>Other normals forms like EKNF, BCNF, 4NF, 5NF, DKNF, and 6NF are not covered in this blog post. You can read more about them at <a href=\"https://en.wikipedia.org/wiki/Database_normalization#Normal_forms\">the Wikipedia page of normal forms</a>.</p>\n<h2 id=\"level-2-sunlight-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-2-sunlight-zone\"></a>Level 2: Sunlight Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-2-sunlight-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27177%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsunlight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fsunlight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Sunlight Zone! As we descend further, we'll explore more advanced features and techniques in PostgreSQL. Get ready to bask in the glow of knowledge and expand your database skills.</p>\n<h3 id=\"connection-pools\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#connection-pools\"></a>Connection Pools<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#connection-pools\"></a></h3>\n<p>Connecting to a database server consists of several time-consuming steps (create a socket, initial handshake, parse connection string, authentication, etc). Connection pools are a way to further improve performance by pooling users connections to a database. The idea is to decrease the total number of connections that must be opened. Whenever a client wants to connect to the database, an open connection from the pool is reused instead of creating a new one.</p>\n<p><img src=\"/static/images/posts/postgres-meme/connection-pool.svg\" alt=\"Explain Plan from pgAdmin\"></p>\n<p>There are many tools and libraries for different programming languages which can help you create connection pools, as well as server-side connection pooling software that works for all connection types, not just within a single software stack. You can create or debug connection pools with tools like Amazon RDS Proxy, <code>pgpool</code>, <code>pgbouncer</code>, <code>pg_crash</code>, etc.</p>\n<h3 id=\"the-dual-table\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#the-dual-table\"></a>The DUAL Table<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#the-dual-table\"></a></h3>\n<p>The DUAL table is a single-row single-column dummy table which was initially added as an underlying object in the Oracle database systems by Charles Weiss. This table is used for situations when you want to <code>select</code> something but no <code>from</code> clause is needed. In Oracle, <code>FROM</code> clause is mandatory, so you would need the <code>dual</code> table. However, in PostgreSQL, creating such table is not required as you can <code>select</code> without a <code>from</code> clause.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token comment\">--- postgresql</span>\n<span class=\"token keyword\">select</span> <span class=\"token number\">1</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- oracle</span>\n<span class=\"token keyword\">select</span> <span class=\"token number\">1</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">from</span> dual<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>That being said, this table can be created in postgres as a view to ease porting problems from Oracle to PostgreSQL. This allows code to remain somewhat compatible with Oracle SQL without annoying the Postgres parser:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> dual<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"lateral-joins\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#lateral-joins\"></a>LATERAL Joins<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lateral-joins\"></a></h3>\n<p>PostgreSQL added the LATERAL join technique since PostgreSQL 9.3. Using lateral joins, you can look at the left hand table:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> weather <span class=\"token keyword\">as</span> w\n<span class=\"token keyword\">join</span> lateral <span class=\"token punctuation\">(</span>\n\t<span class=\"token keyword\">select</span> city<span class=\"token punctuation\">.</span>location\n\t<span class=\"token keyword\">from</span> city\n\t<span class=\"token keyword\">where</span> city<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> w<span class=\"token punctuation\">.</span>city <span class=\"token comment\">-- only possible to reference \"w\" because of lateral</span>\n<span class=\"token punctuation\">)</span> c <span class=\"token keyword\">on</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>In the above query, the inner subquery became a <em>correlated subquery</em> to the outer <code>select</code> query. Without lateral, each subquery is evaluated independently and as a result, cannot cross-reference any other <code>FROM</code> item. You would get this error if you haven't used <code>LATERAL</code>:</p>\n<pre><code>ERROR: invalid reference to FROM-clause entry for table \"w\"\nHINT: There is an entry for table \"w\", but it cannot be referenced from this part of the query.\n</code></pre>\n<h3 id=\"recursive-ctes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#recursive-ctes\"></a>Recursive CTEs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#recursive-ctes\"></a></h3>\n<p><code>WITH</code> clauses can be used with the optional <code>RECURSIVE</code> option. This modifier changes <code>WITH</code> from a mere syntactic convenience into a feature that accomplishes things not otherwise possible in standard SQL. Using <code>RECURSIVE</code>, a <code>WITH</code> query can refer to its own output. The below query creates the fibonacci sequence:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">with</span> recursive fib<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token punctuation\">(</span>\n  <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">union</span> <span class=\"token keyword\">all</span>\n    <span class=\"token keyword\">select</span> b<span class=\"token punctuation\">,</span> a <span class=\"token operator\">+</span> b <span class=\"token keyword\">from</span> fib <span class=\"token keyword\">where</span> b <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">1000</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">select</span> a <span class=\"token keyword\">from</span> fib<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- 0</span>\n<span class=\"token comment\">-- 1</span>\n<span class=\"token comment\">-- 1</span>\n<span class=\"token comment\">-- 2</span>\n<span class=\"token comment\">-- 3</span>\n<span class=\"token comment\">-- 5</span>\n<span class=\"token comment\">-- ...</span>\n</code></pre>\n<h3 id=\"orms-create-bad-queries\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#orms-create-bad-queries\"></a>ORMs create bad queries<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#orms-create-bad-queries\"></a></h3>\n<p>As mentioned in previous sections, ORMs are essentially abstractions built on top of SQL to simplify interactions with your database. Some people use ORMs to write code using the language structures provided by their programming language, rather than crafting SQL queries themselves. The ORM serves as a layer between the relational database and the application, generating the necessary queries.</p>\n<p>On the downside, ORMs abstract away database features, can be more challenging to debug than raw queries, and occasionally generate suboptimal queries that are significantly slower than well-written SQL for the same task. One well-known issue is the N+1 query problem.</p>\n<p>Let's assume we want to retrieve a blog post along with its comments. A common mistake we often encounter is the N+1 query problem: One <code>select</code> query to fetch the post and n additional queries to select comments for each post (n + 1 queries in total). This is easy to fix in raw SQL with a simple join. However, when using an ORM, you have less control on the generated queries, and it can sometimes be challenging to determine whether you've encountered this problem or not without using a profiler:</p>\n<p>N+1 RoundtripFix with Join</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token comment\">-- one query to fetch the posts</span>\n<span class=\"token keyword\">select</span> id<span class=\"token punctuation\">,</span> title <span class=\"token keyword\">from</span> blog_post<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- N query in a loop to fetch the comments of each post:</span>\n<span class=\"token keyword\">select</span> body <span class=\"token keyword\">from</span> comments <span class=\"token keyword\">where</span> post_id <span class=\"token operator\">=</span> :post_id<span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"stored-procedures\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#stored-procedures\"></a>Stored Procedures<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#stored-procedures\"></a></h3>\n<p>Stored procedures are server-side procedures with names that are typically written in various languages, with SQL being the most common. The following displays the definition of a procedure in SQL:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">procedure</span> insert_person<span class=\"token punctuation\">(</span>id <span class=\"token keyword\">integer</span><span class=\"token punctuation\">,</span> first_name <span class=\"token keyword\">text</span><span class=\"token punctuation\">,</span> last_name <span class=\"token keyword\">text</span><span class=\"token punctuation\">,</span> cash <span class=\"token keyword\">integer</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">language</span> <span class=\"token keyword\">sql</span>\n<span class=\"token keyword\">as</span> $$\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> person <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">,</span> first_name<span class=\"token punctuation\">,</span> last_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> cash <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">,</span> cash<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n$$<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Stored procedures are invoked using the <code>CALL</code> statement:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">call</span> insert_person<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Maryam'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Mirzakhani'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>One distinguishing feature of PostgreSQL compared to other database systems is that it allows you to write your procedures in any programming language you prefer. This is in contrast to most database engines that restrict you to using only a predefined set of languages.</p>\n<p>Additional languages can be easily integrated into the PostgreSQL server using the <code>CREATE LANGUAGE</code> command:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">language</span> myLovelyLanguage\n  <span class=\"token keyword\">handler</span> my_language_handler <span class=\"token comment\">-- the function that glue postgresql with any external language</span>\n  validator my_language_validator <span class=\"token comment\">-- check syntax errors before executing function</span>\n</code></pre>\n<p>Functions are a concept similar to stored procedures, but they are distinct entities. Traditionally, people used the term \"Stored Procedure\" to refer to both, but there are differences between them. One key distinction is that functions can return values, whereas stored procedures do not. However, this is not the only difference.</p>\n<p>One of the most significant differences between stored procedures and functions is that functions can be used within a <code>SELECT</code> statement, but they cannot start or commit transactions:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> my_func<span class=\"token punctuation\">(</span>last_name<span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>On the other hand, stored procedures can start and commit transactions, but they can not be used inside select statements.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">call</span> sp_can_commit_a_transaction<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>In short:</p>\n<ul>\n<li>Functions have return values, but stored procedures do not.</li>\n<li>Functions can be used in <code>select</code> statements, but stored procedures do not.</li>\n<li>Functions can not start or commit transactions, but stored procedures can.</li>\n</ul>\n<p>There's also a concept called <code>Trigger Functions</code>, but we will talk about them when we're deeper in the ocean!</p>\n<h3 id=\"cursors\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#cursors\"></a>Cursors<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cursors\"></a></h3>\n<p>The idea behind <code>CURSOR</code> is that the data is generated only when needed (via a <code>FETCH</code>). This mechanism allows us to consume the result set while the database is generating the results. In contrast, it avoids waiting for the database engine to complete its work and send all the results at once:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">declare</span> my_cursor scroll <span class=\"token keyword\">cursor</span> <span class=\"token keyword\">for</span> <span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> films<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- you can read more about SCROLL in the collapsible box</span>\n\n<span class=\"token keyword\">fetch</span> forward <span class=\"token number\">5</span> <span class=\"token keyword\">from</span> my_cursor<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- FORWARD is the direction, PostgreSQL supports many directions.</span>\n<span class=\"token comment\">-- Outputs five rows 1, 2, 3, 4, and 5</span>\n<span class=\"token comment\">-- Cursor is now at position 5</span>\n\n<span class=\"token keyword\">fetch</span> prior <span class=\"token keyword\">from</span> my_cursor<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- outputs row number 4, PRIOR is also a direction.</span>\n\n<span class=\"token keyword\">close</span> my_cursor<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Click for more details: What is an scroll cursor?</p>\n<h3 id=\"there-are-no-non-nullable-types\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#there-are-no-non-nullable-types\"></a>There are no non-nullable types<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#there-are-no-non-nullable-types\"></a></h3>\n<p>As mentioned previously, SQL's <code>null</code> is a marker, not a value. SQL <code>null</code> means unknown, and not having nullable types means we can control the nullability of columns solely through the use of <code>not null</code> check constraints.</p>\n<p>This approach results in flexible data types where any user of the database can input data into the system, even if the data for a column with such a data type is missing or unknown.</p>\n<p>PostgreSQL permits the creation of user-defined types using <code>CREATE TYPE</code>, and it's possible to specify a default for the data type in case a user desires columns of that data type to default to something other than a <code>null</code> value. However, it remains valid to set the column value to <code>null</code> if there are no <code>not null</code> check constraints defined.</p>\n<h3 id=\"optimizers-dont-work-without-table-statistics\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#optimizers-dont-work-without-table-statistics\"></a>Optimizers don't work without table statistics<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#optimizers-dont-work-without-table-statistics\"></a></h3>\n<p>As previously mentioned, PostgreSQL strives to generate an optimal execution plan for your SQL queries. Various plans can produce the same result set, but a well-designed planner/optimizer can produce a faster and more efficient execution plan.</p>\n<p>Query optimization is an art of science, and in order to come up with a good plan, PostgreSQL needs data. PostgreSQL uses a <em>cost-based optimizer</em> which utilizes data statistics, not static rules. The planner/optimizer <em>estimates</em> the cost of each step in the plan, and picks a plan that has the least cost for the system. Additionally, PostgreSQL switches to a <em>Genetic Query Optimizer</em> when the number of joins exceeds a defined threshold (set by the <code>geqo_threshold</code> variable). This is because among all relational operators, joins are often the most complex and challenging to process and optimize.</p>\n<p>As a result, PostgreSQL is equipped with a <em>cumulative statistics system</em> which collects and reports information related to the database server activities. These statistics can come in handy for the optimizer. You can read more about the statistics that PostgreSQL collect at <a href=\"https://www.postgresql.org/docs/current/monitoring-stats.html\">The Cumulative Statistics System</a>.</p>\n<h3 id=\"plan-hints\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#plan-hints\"></a>Plan hints<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#plan-hints\"></a></h3>\n<p>As we already know, PostgreSQL does its best to come up with a good plan execution using statistics, estimates, and guessing. While this approach is generally effective for optimizing user queries, there are situations where users may want to provide hints to the database engine to manually influence certain decisions in execution plans.</p>\n<p>These hints can make their way to the planner/optimizer using approaches like the <code>pg_hint_plan</code> project and adding SQL Comments before the queries:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token comment\">/*+ SeqScan(users) */</span> <span class=\"token keyword\">explain</span> <span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> users <span class=\"token keyword\">where</span> id <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">--                      QUERY PLAN</span>\n<span class=\"token comment\">-- ------------------------------------------------------</span>\n<span class=\"token comment\">-- Seq Scan on a  (cost=0.00..1483.00 rows=10 width=47)</span>\n</code></pre>\n<p>The comment <code>/*+ SeqScan(users) */</code> instructs the planner to utilize a sequential scan when searching for items in the \"users\" table. Similarly, hints for joins can be provided using <code>HashJoin(weather city)</code> syntax within the comment.</p>\n<h3 id=\"mvcc-garbage-collection\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#mvcc-garbage-collection\"></a>MVCC Garbage Collection<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#mvcc-garbage-collection\"></a></h3>\n<p>MVCC stands for Multiversion Concurrency Control. Every database engine needs to somehow manage concurrent access to data, and PostgreSQL as an advanced database engine is no exception. As the name suggests, MVCC is the concurrency control mechanism inside Postgres. Multiversion means that each statement sees it's own version of the database (aka snapshot) as it was sometimes ago. This prevents statements from viewing inconsistent data.</p>\n<p>MVCC enables the read and write locks not to conflict with each other, so reading never blocks writing and writing never blocks reading (and PostgreSQL was the first database to be designed with this feature).</p>\n<p>Keeping multiple copies/versions of data produces garbage data that takes a lot of space on the disk which degrades the performance of the database in the long run. Postgres uses <code>VACUUM</code> to garbage-collect data. <code>VACUUM</code> reclaims storage occupied by dead tuples, which are tuples that are deleted or obsoleted by an update are not physically removed from their table. It is necessary to do <code>VACUUM</code> periodically, especially on frequently-updated tables, hence why PostgreSQL includes an autovacuum facility which can automate routine vacuum maintenance.</p>\n<ul>\n<li>Read more: <a href=\"https://cloud.google.com/blog/products/databases/deep-dive-into-postgresql-vacuum-garbage-collector\">Google Cloud Blogs: A deep dive into VACUUM FAQs</a></li>\n</ul>\n<h2 id=\"level-3-twilight-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-3-twilight-zone\"></a>Level 3: Twilight Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-3-twilight-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27156%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Ftwilight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Ftwilight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Twilight Zone! Things are starting to get intriguing as we venture into more complex database concepts. Brace yourself for a deeper understanding of PostgreSQL's inner workings.</p>\n<h3 id=\"count-vs-count1\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#count-vs-count1\"></a><code>COUNT(*)</code> vs <code>COUNT(1)</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#count-vs-count1\"></a></h3>\n<p>The <code>COUNT</code> function is an aggregate function that can take the form of either <code>count(*)</code>  which counts the total number of input rows  or <code>count(expression)</code>  which counts the number of input rows where the value of the expression is not <code>null</code>.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token comment\">-- Number of all rows, including nulls and duplicates.</span>\n<span class=\"token comment\">-- Performance Warning: PostgreSQL uses a sequential scan of the entire table,</span>\n<span class=\"token comment\">-- or the entirety of an index that includes all rows.</span>\n<span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Number of all rows where `middle_name` is not null</span>\n<span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span>middle_name<span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Number of all unique and not-null `middle_name`s</span>\n<span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">distinct</span> middle_name<span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n</code></pre>\n<p><code>count(1)</code> has no <em>functional</em> difference with <code>count(*)</code> as every row is being counted as constant 1:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- equivalent result:</span>\n<span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>However, an ongoing myth claims that:</p>\n<blockquote>\n<p>using <code>count(1)</code> is better than <code>count(*)</code> because <code>count(*)</code> unnecessarily selects all the columns.</p>\n</blockquote>\n<p>The above statement  is wrong. In PostgreSQL, <code>count(*)</code> is faster as it is an special hard-coded syntax with no arguments for <code>count</code> aggregate function. <code>count(1)</code> is specifically slower as it follows the <code>count(expression)</code> syntax and it needs to check if constant 1 is not equal to <code>null</code> for each row.</p>\n<h3 id=\"isolation-levels-and-phantom-reads\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#isolation-levels-and-phantom-reads\"></a>Isolation Levels and Phantom Reads<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#isolation-levels-and-phantom-reads\"></a></h3>\n<p>As we have mentioned earlier, the I in ACID stands for Isolation. A transaction must be isolated from other concurrent transactions running in the database. As an example, when you want to backup your database using tools like <code>pg_dump</code>, you don't want your backup to be affected by other write operations in the system.</p>\n<p>The SQL standard defines 4 levels of transaction isolation. These isolation level are defined in terms of <em>phenomena</em>, and each of these levels either prohibits these <em>phenomena</em>, or does not guarantee of them not happening. The phenomena are listed below:</p>\n<ul>\n<li><strong>dirty read:</strong> A transaction reads data written by a concurrent uncommitted transaction.</li>\n<li><strong>nonrepeatable read</strong>: A transaction re-reads data it has previously read and finds that data has been modified by another transaction (that committed since the initial read).</li>\n<li><strong>phantom read</strong>: A transaction re-executes a query returning a set of rows that satisfy a search condition and finds that the set of rows satisfying the condition has changed due to another recently-committed transaction.</li>\n<li><strong>serialization anomaly</strong>: The result of successfully committing a group of transactions is inconsistent with all possible orderings of running those transactions one at a time. Write skew is the simplest form of serialization anomaly.</li>\n</ul>\n<p>The four isolation levels in databases are:</p>\n<ul>\n<li><code>Read uncommitted</code></li>\n<li><code>Read committed</code></li>\n<li><code>Repeatable read (aka Snapshot Isolation, or Anomaly Serializable)</code></li>\n<li><code>Serializable (aka Serializable Snapshot Isolation)</code></li>\n</ul>\n<p>It's important to note that PostgreSQL does not implement the <code>read uncommitted</code> isolation level. Instead, PostgreSQL's <em>Read Uncommitted</em> mode behaves like <em>Read Committed</em>. This is because it is the only sensible way to map the standard isolation levels to PostgreSQL's multiversion concurrency control architecture. This approach aligns with the SQL Standard because the standard defines the minimum guarantees, not the maximum ones. Therefore, PostgreSQL can and does disallow <em>phantom reads</em> even in the <em>repeatable read</em> isolation level:</p>\n<div class=\"table-responsive\">\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th>Isolation Level</th><th>Dirty Read</th><th>Nonrepeatable Read</th><th>Phantom Read</th><th>Serialization Anomaly</th></tr></thead><tbody><tr><td>Read uncommitted</td><td> Possible ( not in PG)</td><td> Possible</td><td> Possible</td><td> Possible</td></tr><tr><td>Read committed</td><td> Not possible</td><td> Possible</td><td> Possible</td><td> Possible</td></tr><tr><td>Repeatable read</td><td> Not possible</td><td> Not possible</td><td> Possible ( not in PG)</td><td> Possible</td></tr><tr><td>Serializable</td><td> Not possible</td><td> Not possible</td><td> Not possible</td><td> Not possible</td></tr></tbody></table></div>\n<p>The term \"Serializable\" execution means that a transaction can run as if it has a \"serial execution,\" where no concurrent operation is affecting it.</p>\n<p>Click for more details: PostgreSQL Serializable Isolation is an art of science!</p>\n<h3 id=\"write-skew\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#write-skew\"></a>Write skew<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#write-skew\"></a></h3>\n<p>Write skew is the simplest form of serialization anomaly, and the Serializable isolation level protects you from it. However, the Repeatable Read isolation level does not provide the same protection against write skew.</p>\n<p>Assume a table with a column which has either <code>Black</code> or <code>White</code> as the value. Two users concurrently try to make all rows contain matching color values, but their attempts go in opposite directions. One is trying to update all white rows to black and the other is trying to update all black rows to white.</p>\n<p>In such a case, two concurrent transactions each determine what they are writing based on reading a data set (rows with black/white column), and that dataset overlaps what the other is writing. In this case we can get a state which could not occur if either had run before the other</p>\n<p>If these updates are run serially, all colors will match: one of the transactions turn all rows to white, and the other turns all rows to black. If they are run concurrently in <code>REPEATABLE READ</code> mode, the values will be switched, which is not consistent with any serial order of runs. If they are run concurrently in <code>SERIALIZABLE</code> mode, PostgreSQL's Serializable Snapshot Isolation (SSI) will notice the write skew and roll back one of the transactions.</p>\n<p>Read more:</p>\n<ul>\n<li><a href=\"https://wiki.postgresql.org/wiki/SSI\">PostgreSQL's Serializable Snapshot Isolation (SSI) vs plain Snapshot Isolation (SI)</a></li>\n<li><a href=\"https://wiki.postgresql.org/wiki/Serializable\">PostgreSQL's Serializable Wiki</a></li>\n</ul>\n<h3 id=\"serializable-restarts-require-retry-loops-on-all-statements\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#serializable-restarts-require-retry-loops-on-all-statements\"></a>Serializable restarts require retry loops on all statements<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#serializable-restarts-require-retry-loops-on-all-statements\"></a></h3>\n<p>Restarting a serializable transaction requires retry on all the statements of the transaction, not just the failed one. And if the generated transaction on the backend relies on computed values outside of the sql code, those codes needs to be re-executed as well:</p>\n<p>ts</p>\n<pre class=\"language-ts\"><code class=\"language-ts\"><span class=\"token comment\">// This code snippet is for demonstration-purposes only</span>\n<span class=\"token keyword\">let</span> retryCount <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n<span class=\"token keyword control-flow\">while</span> <span class=\"token punctuation\">(</span>retryCount <span class=\"token operator\">&#x3C;=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword control-flow\">try</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">const</span> computedSpecies <span class=\"token operator\">=</span> <span class=\"token function\">computeSpecies</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">const</span> catto <span class=\"token operator\">=</span> <span class=\"token keyword control-flow\">await</span> db<span class=\"token punctuation\">.</span><span class=\"token method function property-access\">transaction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token method function property-access\">execute</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">async</span> <span class=\"token punctuation\">(</span>trx<span class=\"token punctuation\">)</span> <span class=\"token arrow operator\">=></span> <span class=\"token punctuation\">{</span>\n      <span class=\"token keyword\">const</span> armin <span class=\"token operator\">=</span> <span class=\"token keyword control-flow\">await</span> trx\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">insertInto</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"person\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n          first_name<span class=\"token operator\">:</span> <span class=\"token string\">\"Armin\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">returning</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">executeTakeFirstOrThrow</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n      <span class=\"token keyword control-flow\">return</span> <span class=\"token keyword control-flow\">await</span> trx\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">insertInto</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pet\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n          owner_id<span class=\"token operator\">:</span> armin<span class=\"token punctuation\">.</span><span class=\"token property-access\">id</span><span class=\"token punctuation\">,</span>\n          name<span class=\"token operator\">:</span> <span class=\"token string\">\"Catto\"</span><span class=\"token punctuation\">,</span>\n          species<span class=\"token operator\">:</span> computedSpecies<span class=\"token punctuation\">,</span>\n          is_favorite<span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">returningAll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span><span class=\"token method function property-access\">executeTakeFirstOrThrow</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword control-flow\">continue</span>\n  <span class=\"token punctuation\">}</span> <span class=\"token keyword control-flow\">catch</span> <span class=\"token punctuation\">{</span>\n    retryCount<span class=\"token operator\">++</span>\n    <span class=\"token keyword control-flow\">await</span> <span class=\"token function\">delay</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h3 id=\"partial-indexes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#partial-indexes\"></a>Partial Indexes<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#partial-indexes\"></a></h3>\n<p>A <em>partial index</em> is an index built over a subset of a table specified using a <code>where</code> clause, and is useful when you know that the column values are unique only in certain circumstances. One major use-case for partial indexes is for the times that you don't want to put common items in the index, as their frequent changes can increase the size of index and slow the index down because of the recurring updates.</p>\n<p>As an example, let's assume that most of your customers have the same nationality (at least 25% or so), and there are just a handful of different values in the table, it could be a good idea to create a partial index on the column:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">index</span> nationality_idx <span class=\"token keyword\">on</span> person<span class=\"token punctuation\">(</span>nationality<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">where</span> nationality <span class=\"token operator\">not</span> <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'american'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'iranian'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'indian'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"generator-functions-zip-when-cross-joined\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#generator-functions-zip-when-cross-joined\"></a>Generator functions zip when cross joined<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#generator-functions-zip-when-cross-joined\"></a></h3>\n<p>Generator functions, also known as <em>Set Returning Functions (SRF)</em>, are functions that can return more than one row. Unlike many other databases in which only scalar values can appear in <code>select</code> clauses, PostgreSQL allows set-returning functions to appear in <code>select</code>. One of the most famous generator functions is the <code>generate_series</code> functions which accepts <code>start</code>, <code>stop</code>, and <code>step (optional)</code> parameters, and generates a series of values from start to stop with a step size. This function can generate different types of series including <code>integer</code>, <code>bigint</code>, <code>numeric</code>, and even <code>timestamp</code>:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- or `select generate_series(2,4);`</span>\n\n<span class=\"token comment\">--  generate_series</span>\n<span class=\"token comment\">-- -----------------</span>\n<span class=\"token comment\">--                2</span>\n<span class=\"token comment\">--                3</span>\n<span class=\"token comment\">--                4</span>\n<span class=\"token comment\">-- (3 rows)</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token string\">'2008-03-01 00:00'</span>::<span class=\"token keyword\">timestamp</span><span class=\"token punctuation\">,</span>\n                              <span class=\"token string\">'2008-03-04 12:00'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'10 hours'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">--    generate_series</span>\n<span class=\"token comment\">-- ---------------------</span>\n<span class=\"token comment\">--  2008-03-01 00:00:00</span>\n<span class=\"token comment\">--  2008-03-01 10:00:00</span>\n<span class=\"token comment\">--  2008-03-01 20:00:00</span>\n<span class=\"token comment\">--  2008-03-02 06:00:00</span>\n<span class=\"token comment\">--  2008-03-02 16:00:00</span>\n<span class=\"token comment\">--  2008-03-03 02:00:00</span>\n<span class=\"token comment\">--  2008-03-03 12:00:00</span>\n<span class=\"token comment\">--  2008-03-03 22:00:00</span>\n<span class=\"token comment\">--  2008-03-04 08:00:00</span>\n<span class=\"token comment\">-- (9 rows)</span>\n</code></pre>\n<p>In SQL, you can cross join two table using either of these two syntaxes:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> table_a <span class=\"token keyword\">cross</span> <span class=\"token keyword\">join</span> table_b<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- with `cross join`</span>\n<span class=\"token comment\">-- or --</span>\n<span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> table_a<span class=\"token punctuation\">,</span> table_b<span class=\"token punctuation\">;</span>           <span class=\"token comment\">-- with comma</span>\n</code></pre>\n<p>And for functions, you can call them using either of these two syntaxes:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- with `select * from`</span>\n<span class=\"token comment\">-- or --</span>\n<span class=\"token keyword\">select</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>        <span class=\"token comment\">-- with `select` only</span>\n</code></pre>\n<p>Combining these two syntaxes, when we execute the same cross join syntax for generator functions using <code>select * from f()</code> and <code>select f()</code> syntaxes, one of them turns into a zip operation instead of a cross join:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> a<span class=\"token punctuation\">,</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> b<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- cross joins</span>\n\n<span class=\"token comment\">-- a\tb</span>\n<span class=\"token comment\">-- 1\t5</span>\n<span class=\"token comment\">-- 1\t6</span>\n<span class=\"token comment\">-- 1\t7</span>\n<span class=\"token comment\">-- 2\t5</span>\n<span class=\"token comment\">-- 2\t6</span>\n<span class=\"token comment\">-- 2\t7</span>\n<span class=\"token comment\">-- 3\t5</span>\n<span class=\"token comment\">-- 3\t6</span>\n<span class=\"token comment\">-- 3\t7</span>\n\n<span class=\"token keyword\">select</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> a<span class=\"token punctuation\">,</span> generate_series<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> b<span class=\"token punctuation\">;</span> <span class=\"token comment\">-- zips</span>\n\n<span class=\"token comment\">-- a\tb</span>\n<span class=\"token comment\">-- 1\t5</span>\n<span class=\"token comment\">-- 2\t6</span>\n<span class=\"token comment\">-- 3\t7</span>\n</code></pre>\n<p>In the second case we get the result from two generator functions side by side (this is called the <code>zip</code> of two results), instead of a cartesian product. This is because a <code>join</code> plan can not be created without a <code>from</code>/<code>merge</code> clause (omitted <code>from</code> clause is intended for computing the results of simple expressions), and PostgreSQL creates a so called <code>ProjectSet</code> node in the plan to project(display) the items coming from the generator functions.</p>\n<h3 id=\"sharding\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#sharding\"></a>Sharding<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sharding\"></a></h3>\n<p>Sharding in database is the ability to horizontally partition data across one more database shards. While partitioning feature allows a table to be partitioned into multiple tables, sharding allows a table to be partitioned in a way so parts of it live on external foreign servers.</p>\n<p>PostgreSQL uses the Foreign Data Wrappers (FDW) approach to implement sharding, but it is still in progress.</p>\n<p><img src=\"/static/images/posts/postgres-meme/sharding-fdw.svg\" alt=\"FDW Sharding\"></p>\n<p><a href=\"https://github.com/citusdata/citus\">Citus</a> is an open-source extension for PostgreSQL which enables it to achieve horizontal scalability through sharding and replication. One key advantage of Citus is that it is not a fork of PostgreSQL but an extension, which allows it to stay in sync with the community release. In contrast, many other forks of PostgreSQL often lag behind the community release in terms of updates and features.</p>\n<h3 id=\"zigzag-join\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#zigzag-join\"></a>ZigZag Join<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#zigzag-join\"></a></h3>\n<p>We've previously discussed <em>logical</em> joins, including left join, right join, inner join, cross join, and full joins. These joins are <em>logical</em> in a sense that they are simple joins that we write in our SQL codes. There is another category of joins called <em>physical</em> joins. Physical joins represent the actual join operations that the database performs to join your data. These include Nested Loop Join, Hash Join, and Merge Join. You can use <code>explain</code> functionality to see which kind of physical join your database is using in the plan to execute the logical join you have defined in your SQL.</p>\n<p>ZigZag join is a physical join strategy, and can be thought of as a more performant nested loop join. Assume we have a table like this:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> vehicle<span class=\"token punctuation\">(</span>id <span class=\"token keyword\">integer</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span> tires <span class=\"token keyword\">integer</span><span class=\"token punctuation\">,</span> wings <span class=\"token keyword\">integer</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">create</span> <span class=\"token keyword\">index</span> <span class=\"token keyword\">on</span> vehicle<span class=\"token punctuation\">(</span>tires<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">create</span> <span class=\"token keyword\">index</span> <span class=\"token keyword\">on</span> vehicle<span class=\"token punctuation\">(</span>wings<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>And we have a <code>select</code> query like this:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> vehicle <span class=\"token keyword\">where</span> tires <span class=\"token operator\">=</span> <span class=\"token number\">0</span> <span class=\"token operator\">and</span> wings <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Normally this would be a tough task for a database without a Zig-Zag join, because using one of the secondary indexes and the primary index in our join plan, we still need to fetch many records if we're having such a situation:</p>\n<ul>\n<li>there are many vehicles with tires = 0, or wings = 1</li>\n<li>but not many vehicles with both tires = 0 and wings = 1.</li>\n</ul>\n<p>ZigZag join can make use of both indexes to reduce the number of fetched records:</p>\n<p><img src=\"/static/images/posts/postgres-meme/zigzag.svg\" alt=\"Zig Zag Join\"></p>\n<p>In the zig-zag join shown in the image above, we continually switch between the secondary indexes while comparing with the primary index:</p>\n<ol>\n<li>We first look at the tires index for values of <code>tires = 0</code>. The first <code>id</code> is equal to <code>1</code>. Therefore, we need to jump (zig) to the other index and look for rows where <code>id = 1 (match)</code> or <code>id > 1 (skip)</code>. So in general, we jump to the row where <code>id >= 1</code>.</li>\n<li>Zig to the wings index, and as <code>id = 1</code>, we have found a match. We can safely lookup the next record of the same index.</li>\n<li>The next record has the <code>id = 2</code>. We zag to the tires index where <code>id >= 2</code>.</li>\n<li>The current record has <code>id = 10</code>. It's not a match, but we've already skipped a lot of records.</li>\n<li>We zig to the wings index again, looking for records where <code>id >= 10</code></li>\n<li>And so on...</li>\n</ol>\n<h3 id=\"merge\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#merge\"></a>MERGE<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#merge\"></a></h3>\n<p>Merge conditionally inserts, updates, or delete rows of a table using a <em>data source</em>:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">merge</span> <span class=\"token keyword\">into</span> customer_account  <span class=\"token keyword\">as</span> ca\n<span class=\"token keyword\">using</span> recent_transactions <span class=\"token keyword\">as</span> tx\n<span class=\"token keyword\">on</span> tx<span class=\"token punctuation\">.</span>customer_id <span class=\"token operator\">=</span> ca<span class=\"token punctuation\">.</span>customer_id\n<span class=\"token keyword\">when</span> <span class=\"token keyword\">matched</span> <span class=\"token keyword\">then</span>\n  <span class=\"token keyword\">update</span> <span class=\"token keyword\">set</span> balance <span class=\"token operator\">=</span> balance <span class=\"token operator\">+</span> transaction_value\n<span class=\"token keyword\">when</span> <span class=\"token operator\">not</span> <span class=\"token keyword\">matched</span> <span class=\"token keyword\">then</span>\n  <span class=\"token keyword\">insert</span> <span class=\"token punctuation\">(</span>customer_id<span class=\"token punctuation\">,</span> balance<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">.</span>customer_id<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">.</span>transaction_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Using <code>merge</code> we simplify multiple procedural language statements into a single merge statement.</p>\n<h3 id=\"triggers\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#triggers\"></a>Triggers<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#triggers\"></a></h3>\n<p>Triggers are a mechanism in PostgreSQL that can execute a function before, after, or instead of the operation when a certain event is occurred on a table. These events can be either of <code>insert</code>, <code>update</code>, <code>delete</code>, or <code>truncate</code>. Trigger functions have access to special variables that store data both before and after an edit, hence why they are more powerful than <code>check</code> constraints:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">trigger</span> log_update\n    <span class=\"token keyword\">after</span> <span class=\"token keyword\">update</span> <span class=\"token keyword\">on</span> system_actions\n    <span class=\"token keyword\">for each row</span>\n    <span class=\"token keyword\">when</span> <span class=\"token punctuation\">(</span>NEW<span class=\"token punctuation\">.</span>action_type <span class=\"token operator\">=</span> <span class=\"token string\">'sensitive'</span> <span class=\"token operator\">or</span> OLD<span class=\"token punctuation\">.</span>action_type <span class=\"token operator\">=</span> <span class=\"token string\">'sensitive'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">execute</span> <span class=\"token keyword\">function</span> log_sensitive_system_action_change<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>As you can see, the <code>when</code> clause can refer to columns of the old and/or new row values by writing <code>OLD.column_name</code> or <code>NEW.column_name</code> respectively.</p>\n<h3 id=\"grouping-sets-cube-rollup\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#grouping-sets-cube-rollup\"></a>Grouping sets, Cube, Rollup<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#grouping-sets-cube-rollup\"></a></h3>\n<p>Imagine you want to see the sum of the salaries of a different departments based on the gender of the employees. One way to do this is to have multiple <code>group by</code> clauses and then <code>union</code> the result rows together:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">  <span class=\"token keyword\">select</span> dept_id<span class=\"token punctuation\">,</span> gender<span class=\"token punctuation\">,</span> <span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> employee <span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> dept_id<span class=\"token punctuation\">,</span> gender\n<span class=\"token keyword\">union</span> <span class=\"token keyword\">all</span>\n  <span class=\"token keyword\">select</span> dept_id<span class=\"token punctuation\">,</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span>   <span class=\"token keyword\">from</span> employee <span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> dept_id\n<span class=\"token keyword\">union</span> <span class=\"token keyword\">all</span>\n  <span class=\"token keyword\">select</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> gender<span class=\"token punctuation\">,</span> <span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span>    <span class=\"token keyword\">from</span> employee <span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> gender\n<span class=\"token keyword\">union</span> <span class=\"token keyword\">all</span>\n  <span class=\"token keyword\">select</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span>      <span class=\"token keyword\">from</span> employee<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- dept_id  gender  sum</span>\n<span class=\"token comment\">--</span>\n<span class=\"token comment\">-- 1        M       1000</span>\n<span class=\"token comment\">-- 1        F       1500</span>\n<span class=\"token comment\">-- 2        M       1700</span>\n<span class=\"token comment\">-- 2        F       1650</span>\n<span class=\"token comment\">-- 2        NULL    3350</span>\n<span class=\"token comment\">-- 1        NULL    2500</span>\n<span class=\"token comment\">-- NULL     M       2700</span>\n<span class=\"token comment\">-- NULL     F       3150</span>\n<span class=\"token comment\">-- NULL     NULL    5850</span>\n</code></pre>\n<p>However, this would be a pain if we want to report the sum of salaries for different groups of data. Grouping sets allow us to define a set of groupings and write a simpler query. The equivalent of the above query using grouping sets would be:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> dept_id<span class=\"token punctuation\">,</span> gender<span class=\"token punctuation\">,</span> <span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>salary<span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> employee\n<span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span>\n\tgrouping sets <span class=\"token punctuation\">(</span>\n\t\t<span class=\"token punctuation\">(</span>dept_id<span class=\"token punctuation\">,</span> gender<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t<span class=\"token punctuation\">(</span>dept_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t<span class=\"token punctuation\">(</span>gender<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>There are two types of grouping sets, each with its own syntax sugar due to their common usages: <code>rollup</code> and <code>cube</code>.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">rollup <span class=\"token punctuation\">(</span>e1<span class=\"token punctuation\">,</span> e2<span class=\"token punctuation\">,</span> e3<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>is equivalent of:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">grouping sets <span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">(</span> e1<span class=\"token punctuation\">,</span> e2<span class=\"token punctuation\">,</span> e3<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n    <span class=\"token punctuation\">(</span> e1<span class=\"token punctuation\">,</span> e2 <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span> e1 <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span> <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>and</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">cube <span class=\"token punctuation\">(</span> e1<span class=\"token punctuation\">,</span> e2<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span> <span class=\"token punctuation\">)</span>\n</code></pre>\n<p>is equivalent of:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">GROUPING SETS <span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> c <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">,</span> b    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">,</span>    c <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span> a       <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>    b<span class=\"token punctuation\">,</span> c <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>    b    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>       c <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span>         <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>Grouping sets can also be combined together:</p>\n<p>combined-gs.sqlequivalent.sql</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">group</span> <span class=\"token keyword\">by</span> a<span class=\"token punctuation\">,</span> cube <span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> grouping sets <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<h2 id=\"level-4-midnight-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-4-midnight-zone\"></a>Level 4: Midnight Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-4-midnight-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27161%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fmidnight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fmidnight.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Midnight Zone! In this level, we'll delve into the depths of PostgreSQL. Prepare to navigate the challenges and professional topics of a modern database system.</p>\n<h3 id=\"denormalization\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#denormalization\"></a>Denormalization<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#denormalization\"></a></h3>\n<p>One of the first steps of designing a database application is going thorough the normalization process (1NF, 2NF, ...) in order to reduce data redundancy and improve data integrity. Even though relational database, specially Postgres, are well optimized for having many primary keys and foreign keys in tables, and are capable of joining between many tables and handling many constraints, a heavily normalized schema might still be challenging to deal with because of performance penalties.</p>\n<p>In such a scenario, if maintaining a fully normalized table becomes challenging, the database designer can go thorough a process known as <em>denormalization</em>. In other words, it improves the read performance of your data, with the cost of reducing the write performance, as you may need to write multiple copies of your data.</p>\n<p>PostgreSQL natively supports many denormalized data types including <code>array</code>, composite types created via <code>create type</code>, <code>enum</code>, <code>xml</code>, and <code>json</code> types. Materialized views are also used to implement faster reads with slower writes trade-off. A materialized view is a view that is stored on disk. You can create a denormalized and materialized view of your data for fast reads, and then use <code>refresh materialized view my_view</code> to refresh this cache.</p>\n<h3 id=\"nulls-in-check-constraints-are-truthy\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#nulls-in-check-constraints-are-truthy\"></a><code>NULL</code>s in <code>CHECK</code> constraints are truthy<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nulls-in-check-constraints-are-truthy\"></a></h3>\n<p>As we have mentioned earlier, <code>null</code> in SQL means not knowing the value, rather than the absence of a value, and such a select will return <code>null</code>:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token boolean\">null</span> <span class=\"token operator\">></span> <span class=\"token number\">7</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- null</span>\n</code></pre>\n<p>If we create a column with a check constraint on it like this:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> mature_person<span class=\"token punctuation\">(</span>id <span class=\"token keyword\">integer</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span> age <span class=\"token keyword\">integer</span> <span class=\"token keyword\">check</span><span class=\"token punctuation\">(</span>age <span class=\"token operator\">>=</span> <span class=\"token number\">18</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>and then we try to insert a row where the <code>age</code> equals 15, we will get this error:</p>\n<pre><code>ERROR:  new row for relation \"mature_person\" violates check constraint \"mature_person_age_check\"\nDETAIL:  Failing row contains (1, 15).\n</code></pre>\n<p>However, this <code>insert</code> will succeed:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> mature_person<span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">,</span> age<span class=\"token punctuation\">)</span> <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">null</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">-- INSERT 0 1</span>\n<span class=\"token comment\">-- Query returned successfully in 80 msec.</span>\n</code></pre>\n<p>It's might not make sense to assume something satisfies a check constraint when you don't know the value of it (<code>null</code>), but in SQL we have to let the row thorough because <code>null</code>s in <code>check</code> constraints are truthy.</p>\n<h3 id=\"transaction-contention\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#transaction-contention\"></a>Transaction Contention<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#transaction-contention\"></a></h3>\n<p>Resource contention is a conflict over access to a shared resource like RAM, network interface, storage, etc. In case of SQL databases, a resource contention can appear in form of transaction contentions, and that is when multiple transactions want to write to a row at the same time. A transaction contention might require delays, retries, or halts to fix as they might cause deadlocks/livelocks. This is actually configurable using the <code>deadlock_timeout</code> config.</p>\n<p>A contention usually slows down your database without leaving many clues for you to debug them, and the negative effect gets worse when you have multiple nodes or clusters. That being said, tools like Postgres-BDR might provides tools to diagnose and correct contention problems.</p>\n<h3 id=\"select-for-update\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#select-for-update\"></a><code>SELECT FOR UPDATE</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#select-for-update\"></a></h3>\n<p><code>select</code> clause is used to read data from database, but sometimes you want to select rows in order to write them. If any of the below <em>lock strengths</em> are specified:</p>\n<ul>\n<li><code>select ... for update</code></li>\n<li><code>select ... for no key update</code></li>\n<li><code>select ... for share</code></li>\n<li><code>select ... for key share</code></li>\n</ul>\n<p>the <code>select</code> statement locks the entire selected rows (not just the columns) against concurrent updates:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">begin</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> users <span class=\"token keyword\">WHERE</span> group_id <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token keyword\">FOR</span> <span class=\"token keyword\">UPDATE</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">update</span> users <span class=\"token keyword\">set</span> balance <span class=\"token operator\">=</span> <span class=\"token number\">0.00</span> <span class=\"token keyword\">WHERE</span> group_id <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">commit</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>This is sometimes known as <em>pessimistic locking</em>. You should be careful when using explicit locking, because if you perform long-running works in a transaction, the database will lock the rows for the entirety of time:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">begin</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> users <span class=\"token keyword\">WHERE</span> group_id <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token keyword\">FOR</span> <span class=\"token keyword\">UPDATE</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- rows will remain locked and cause performance degradation</span>\n<span class=\"token comment\">-- doing a lot of time consuming calculations</span>\n<span class=\"token keyword\">update</span> users <span class=\"token keyword\">set</span> balance <span class=\"token operator\">=</span> <span class=\"token number\">0.00</span> <span class=\"token keyword\">WHERE</span> group_id <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">commit</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>You can switch to <em>optimistic locking</em> in such cases. Optimistic locking assumes that others won't update the same record and verifies this during update time, rather than locking the record throughout the entire processing duration on the client side.</p>\n<h3 id=\"timestamptz-doesnt-store-a-timezone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#timestamptz-doesnt-store-a-timezone\"></a><code>timestamptz</code> doesn't store a timezone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#timestamptz-doesnt-store-a-timezone\"></a></h3>\n<p>If we run this query:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> typname<span class=\"token punctuation\">,</span> typlen\n<span class=\"token keyword\">from</span> pg_type\n<span class=\"token keyword\">where</span> typname <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'timestamptz'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- typname      typlen</span>\n<span class=\"token comment\">-- timestamp    8</span>\n<span class=\"token comment\">-- timestamptz  8</span>\n</code></pre>\n<p>we will realize that <code>timestamp</code> and <code>timestamp with time zone</code> types have the same size, which means PostgreSQL doesn't actually store the timezone for <code>timestamptz</code>. All it does is that it formats the same value using a different timezone:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">timestamp</span>\n<span class=\"token comment\">-- \"2023-08-31 16:56:54.541131\"</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">timestamp</span> <span class=\"token keyword\">with</span> <span class=\"token keyword\">time</span> zone\n<span class=\"token comment\">-- \"2023-08-31 16:56:58.541131\"</span>\n\n<span class=\"token keyword\">set</span> timezone <span class=\"token operator\">=</span> <span class=\"token string\">'asia/tehran'</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">timestamp</span>\n<span class=\"token comment\">-- \"2023-08-31 16:56:54.541131\"</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">timestamp</span> <span class=\"token keyword\">with</span> <span class=\"token keyword\">time</span> zone\n<span class=\"token comment\">-- \"2023-08-31 16:56:23.73028+04:30\"</span>\n</code></pre>\n<h3 id=\"star-schemas\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#star-schemas\"></a>Star Schemas<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#star-schemas\"></a></h3>\n<p>Star schema is a database modeling approach adopted by relational data warehouses. It requires modelers to classify their model tables as either <em>dimension</em> or <em>fact</em>. The star schema consists of one or more fact tables referencing to any number of dimension tables.</p>\n<p>In data warehousing, a <em>fact</em> table consists of measurements, metrics or facts of a business process, while a dimension table is a structure that categorizes facts and measures in order to enable users to answer business questions. Commonly used dimensions are people, products, place and time.</p>\n<p><img src=\"/static/images/posts/postgres-meme/star-schemas.svg\" alt=\"Zig Zag Join\"></p>\n<h3 id=\"sargability\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#sargability\"></a>Sargability<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sargability\"></a></h3>\n<p>In relational databases, a condition (or predicate) in a query is said to be <em>sargable</em> if the DBMS engine can take advantage of an index to speed up the execution of the query. The ideal SQL search condition has the general form:</p>\n<pre><code>&#x3C;column> &#x3C;comparison operator> &#x3C;literal>\n</code></pre>\n<p>A common thing that can make a query non-sargible is using an indexed column inside a function, for example using this query:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> birthday <span class=\"token keyword\">from</span> users\n<span class=\"token keyword\">where</span> get_year<span class=\"token punctuation\">(</span>birthday<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token number\">2008</span>\n</code></pre>\n<p>instead of the equivalent sargible one:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> birthday <span class=\"token keyword\">from</span> users\n<span class=\"token keyword\">where</span> birthday <span class=\"token operator\">>=</span> <span class=\"token string\">'01-01-2008'</span> <span class=\"token operator\">AND</span> birthday <span class=\"token operator\">&#x3C;</span> <span class=\"token string\">'01-01-2009'</span>\n</code></pre>\n<p>Or as another example:</p>\n<p>non-sargiblesargible</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span>   players\n<span class=\"token keyword\">where</span>  SQRT<span class=\"token punctuation\">(</span>score<span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">7.5</span>\n</code></pre>\n<p>SARG is a contraction for Search ARGument. In the early days, IBM researchers named these kinds of search conditions \"sargable predicates\". In later days, Microsoft and Sybase redefined \"sargable\" to mean \"can be looked up via the index.\"</p>\n<h3 id=\"ascending-key-problem\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#ascending-key-problem\"></a>Ascending Key Problem<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ascending-key-problem\"></a></h3>\n<p>Assume that we have such a time-series event table:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> event<span class=\"token punctuation\">(</span>t <span class=\"token keyword\">timestamp</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span> content <span class=\"token keyword\">text</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>In this situation, the primary key or index of such tables are continuously increasing over time and the rows are always being added to the end of table. This can result in data fragmentation as the end of the table is the only spot being written, and the inserting point is not evenly distributed among the rows.</p>\n<p>This can lead to various issues, such as contention at the end of the table, making it challenging to distribute and shard the table, and slower data retrievals due to the lack of table statistics at the end.</p>\n<p>As mentioned earlier, a database system relies on statistics to generate more optimal execution plans. It's important to note that statistics for the most recently inserted rows are not included in the database statistics, e.g. <code>pg_stat_database</code>.</p>\n<p>One way to fix the ascending key problem in PostgreSQL is to use the block range index (BRIN index). These indexes give performance improvements when the data is naturally ordered as it is added to the table, such as <code>t timestamp</code> columns or a naturally auto incremented columns.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> event <span class=\"token punctuation\">(</span>\n  event_time <span class=\"token keyword\">timestamp</span> <span class=\"token keyword\">with</span> <span class=\"token keyword\">time</span> zone <span class=\"token operator\">not</span> <span class=\"token boolean\">null</span><span class=\"token punctuation\">,</span>\n  event_data jsonb <span class=\"token operator\">not</span> <span class=\"token boolean\">null</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">create</span> <span class=\"token keyword\">index</span> <span class=\"token keyword\">on</span> event <span class=\"token keyword\">using</span> BRIN <span class=\"token punctuation\">(</span>event_time<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"ambiguous-network-errors\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#ambiguous-network-errors\"></a>Ambiguous Network Errors<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ambiguous-network-errors\"></a></h3>\n<p>Various types of network errors can occur when working with databases, such as disconnecting from the database during a transaction. In such cases, it's your responsibility to verify whether your interaction with the database was successful or not.</p>\n<p>Ambiguous network errors may not provide clear indications of where the process was interrupted, or even if a network problem exists. If you are running a streaming replication, a young connection in the <code>pg_stat_replication</code> table might be a sign of a network problem or other kind of reliability issues.</p>\n<h3 id=\"utf8mb4\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#utf8mb4\"></a><code>utf8mb4</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#utf8mb4\"></a></h3>\n<p><code>utf8mb4</code> stands for \"UTF-8 Multibyte 4\" and is a MySQL type. It has nothing to do with PostgreSQL or the SQL standard.</p>\n<p>Historically, MySQL has used <code>utf8</code> as an alias for <code>utf8mb3</code>. That means that it can only store <em>Basic Multilingual Plane</em> unicode characters (3 byte unicode characters). If you want to be able to store all unicode characters, you need to explicitly use <code>utf8mb4</code> type.</p>\n<p>Beginning with MySQL 8.0.28, <code>utf8mb3</code> is used exclusively in the output of <code>show</code> statements and in Information Schema tables when this character set is meant.</p>\n<p>At some point in the MySQL history <code>utf8</code> is expected to become a reference to <code>utf8mb4</code>. To avoid ambiguity about the meaning of <code>utf8</code>, MySQL users (and MariaDB users, because MariaDB is a fork of MySQL) should consider specifying <code>utf8mb4</code> explicitly for character set references instead of <code>utf8</code>.</p>\n<h2 id=\"level-5-abyssal-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-5-abyssal-zone\"></a>Level 5: Abyssal Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-5-abyssal-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27141%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fabyssal.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fabyssal.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Abyssal Zone! Here, we'll explore the abyss of PostgreSQL's concepts. Things that you might haven't heard before!</p>\n<h3 id=\"cost-models-dont-reflect-reality\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#cost-models-dont-reflect-reality\"></a>Cost models don't reflect reality<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cost-models-dont-reflect-reality\"></a></h3>\n<p>When explaining a query, you can enable the \"cost\" option, which provides you with the estimated statement execution cost. This cost represents the planner's estimate of how long it will take to execute the statement, typically measured in cost units, conventionally indicating disk page fetches.</p>\n<p>The planner uses the table statistics to come up with the best plan it can with the lowest cost. However, that computed cost can be utterly wrong as it's just an estimated value, or could be based on the wrong statistics (as we've seen in the ascending key problem).</p>\n<h3 id=\"nulljsonb-is-null--false\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#nulljsonb-is-null--false\"></a><code>null::jsonb IS NULL</code> = <code>false</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nulljsonb-is-null--false\"></a></h3>\n<p><code>NULL</code> in SQL means not knowing the value, while JSON's <code>null</code> is JavaScript's <code>null</code> and represents the intentional absence of any value. This is why JSON's <code>null</code> in PostgreSQL's <code>jsonb</code> data-type is not equivalent to SQL's <code>null</code>:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token string\">'null'</span>::jsonb <span class=\"token operator\">is</span> <span class=\"token boolean\">null</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- false</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token string\">'{\"name\": null}'</span>::jsonb<span class=\"token operator\">-</span><span class=\"token operator\">></span><span class=\"token string\">'name'</span> <span class=\"token operator\">is</span> <span class=\"token boolean\">null</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- false, because JSON's null != SQL's null</span>\n\n<span class=\"token keyword\">select</span> <span class=\"token string\">'{\"name\": null}'</span>::jsonb<span class=\"token operator\">-</span><span class=\"token operator\">></span><span class=\"token string\">'last_name'</span> <span class=\"token operator\">is</span> <span class=\"token boolean\">null</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- true, because 'last_name' key doesn't exists in JSON, and the result is an SQL null</span>\n</code></pre>\n<h3 id=\"tpcc-requires-wait-times\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#tpcc-requires-wait-times\"></a>TPCC requires wait times<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#tpcc-requires-wait-times\"></a></h3>\n<p>TPC-C stands for \"Transaction Processing Performance Council - Benchmark C\" and is an online transaction processing benchmark hosted at <a href=\"https://www.tpc.org/tpcc/\">tpc.org</a>. TPC-C involves a mix of five concurrent transactions of different types and complexity either executed on-line or queued for deferred execution. The database is comprised of nine types of tables with a wide range of record and population sizes. TPC-C is measured in transactions per minute (tpmC).</p>\n<p>TPC-C benchmarks includes two type of wait times: The keying time represents the time spent entering data at the terminal (pressing keys on the keyboard) and the think time represents the time spent, by the operator, to read the result of the transaction at the terminal before requesting another transaction. Each transaction has a minimum keying time and a minimum think time.</p>\n<p>These times will help the benchmark to be closer to real-world scenarios. Benchmarking transactions without wait-time will make the system under test slower and slower overtime as the system internals will have no free resources to operate.</p>\n<p><code>pgbench</code> is the command-line tool used to benchmark PostgreSQL databases, and it supports TPC and many different command-line arguments including wait-time/schedule-lag-time.</p>\n<h3 id=\"deferrable-initially-immediate\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#deferrable-initially-immediate\"></a>DEFERRABLE INITIALLY IMMEDIATE<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#deferrable-initially-immediate\"></a></h3>\n<p>Constraints on columns can be either <code>deferred</code> or <code>immediate</code>. Immediate constraints are checked at the end of each statement, while deferred constraints are not checked until transaction commit. Each constraint has its own <code>IMMEDIATE</code> or <code>DEFERRED</code> mode.</p>\n<p>Upon creation, a constraint is given one of three characteristics:</p>\n<ul>\n<li><code>not deferrable</code> (default, equivalent to <code>immediate</code>): the constraint is checked immediately after each statement. This behavior can NOT be changed using the <code>set constraint</code> command. e.g. <code>set constraint pk_name deferred;</code></li>\n<li><code>deferrable initially immediate</code>: the constraint is checked immediately after each statement, however, this behavior can later be altered using the <code>set constraint</code> command.</li>\n<li><code>deferrable initially deferred</code>: the constraints are not checked until transaction commit. This behavior can later be altered using the <code>set constraint</code> command.</li>\n</ul>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> book <span class=\"token punctuation\">(</span>\n\tname <span class=\"token keyword\">text</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">,</span>\n\tauthor <span class=\"token keyword\">text</span> <span class=\"token keyword\">references</span> author<span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">)</span> <span class=\"token keyword\">on</span> <span class=\"token keyword\">delete</span> <span class=\"token keyword\">cascade</span> deferrable initially immediate<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>As you see in the SQL code above, <code>deferrable initially immediate</code> is specified while defining the schema of the table, not on runtime.</p>\n<h3 id=\"explain-approximates-select-count\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#explain-approximates-select-count\"></a>EXPLAIN approximates <code>SELECT COUNT(*)</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#explain-approximates-select-count\"></a></h3>\n<p>Using <code>explain</code> with <code>select count(*)</code> can give you an estimate of how many rows PostgreSQL think are in your table using table statistics.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">explain</span> <span class=\"token keyword\">select</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">from</span> users<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>If you don't need an exact count, the current statistic from the catalog table <code>pg_class</code> might be good enough and is much faster to retrieve for big tables:</p>\n<p>pg_class estimatepg_class estimate with exact schema</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> reltuples <span class=\"token keyword\">as</span> estimate_count <span class=\"token keyword\">from</span> pg_class <span class=\"token keyword\">where</span> relname <span class=\"token operator\">=</span> <span class=\"token string\">'table_name'</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"match-partial-foreign-keys\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#match-partial-foreign-keys\"></a>MATCH PARTIAL Foreign Keys<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#match-partial-foreign-keys\"></a></h3>\n<p><code>match full</code>, <code>match partial</code>, and <code>match simple</code>(default) are three table column constraints for the foreign keys. Foreign keys are supposed to guarantee the <em>referential integrity</em> of our database, and in order to do so, database needs to know how to match the referencing column value with the referenced column value in case of <code>null</code>s.</p>\n<ul>\n<li><code>match full</code>: will not allow one column of a multi-column foreign key to be <code>null</code> unless all foreign key columns are <code>null</code>; if they are all <code>null</code>, the row is not required to have a match in the referenced table.</li>\n<li><code>match simple</code>(default): allows any of the foreign key columns to be <code>null</code>; if any of them are <code>null</code>, the row is not required to have a match in the referenced table.</li>\n<li><code>match partial</code>: if all referencing columns are <code>null</code>, then the row of the referencing table passes the constraint check. If at least one referencing columns is not null, then the row passes the constraint check if and only if there is a row of the referenced table that matches all the non-null referencing columns. This is not yet implemented in PostgreSQL, but a workaround is to use <code>not null</code> constraints on the referencing column(s) to prevent these cases from arising.</li>\n</ul>\n<h3 id=\"causal-reverse\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#causal-reverse\"></a>Causal Reverse<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#causal-reverse\"></a></h3>\n<p>Causal reverse is a transaction anomaly that can be encountered even with Serializable isolation levels. To address this anomaly, a higher level of serializability known as <em>Strict Serializability</em> is required.</p>\n<p>Here is a simple example for the causal reverse anomaly:</p>\n<ol>\n<li>Thomas executes <code>select * from events</code>, doesn't get a respond yet.</li>\n<li>Ava executes <code>insert into events (id, time, content) values (1, '2023-09-01 02:01:16.679037', 'hello')</code> and commit.</li>\n<li>Emma executes <code>insert into events (id, time, content) values (2, '2023-09-01 02:02:56.819018', 'hi')</code> and commit.</li>\n<li>Thomas gets the respond of the <code>select</code> query from step 1. He gets the Emma's row, but not Ava's.</li>\n</ol>\n<p>In the causal reverse anomaly, a later write which was caused by an earlier write, time-travels to a point in the serial order prior to the earlier write.</p>\n<ul>\n<li>Read more: <a href=\"http://dbmsmusings.blogspot.com/2019/06/correctness-anomalies-under.html\">Correctness Anomalies Under Serializable Isolation</a></li>\n</ul>\n<h2 id=\"level-6-hadal-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-6-hadal-zone\"></a>Level 6: Hadal Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-6-hadal-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27153%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fhadal.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fhadal.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Hadal Zone! As we reach extreme depths, we'll discuss specialized PostgreSQL topics like learned indexes, TXID Exhaustion, and more!</p>\n<h3 id=\"vectorized-doesnt-mean-simd\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#vectorized-doesnt-mean-simd\"></a>Vectorized doesn't mean SIMD<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vectorized-doesnt-mean-simd\"></a></h3>\n<p>SIMD stands for \"Single instruction, multiple data\", and is a type of parallel processing when a single CPU instruction is simultaneously applied to multiple different data streams.</p>\n<p><img src=\"/static/images/posts/postgres-meme/simd.svg\" alt=\"SIMD\"></p>\n<p>The term \"Vector\" and \"Vectorized\" usually come with the term \"SIMD\" in computer literature. Vector programming (aka Array programming) refers to solutions that allow us to apply operations to an entire set of values at once. As a matter of fact, the extension instruction set which was added to the x86 instruction set architecture to perofrm SIMD is called <em>Advanced Vector Extensions (AVX)</em>.</p>\n<p>SIMD is one approach to leverage vector computations and not the only way. That being said, <a href=\"https://doxygen.postgresql.org/simd_8h_source.html\">PostgreSQL vectors are backed by SIMD cpu instructions</a>.</p>\n<h3 id=\"nulls-are-equal-in-distinct-but-unequal-in-unique\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#nulls-are-equal-in-distinct-but-unequal-in-unique\"></a><code>NULL</code>s are equal in <code>DISTINCT</code> but unequal in <code>UNIQUE</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nulls-are-equal-in-distinct-but-unequal-in-unique\"></a></h3>\n<p>Assume you have a table called <code>unique_items</code> with such a definition:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> unique_items<span class=\"token punctuation\">(</span>item <span class=\"token keyword\">text</span> <span class=\"token keyword\">unique</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>PostgreSQL will prevent you to insert duplicate <code>'hi'</code> values, as the second one would violate the unique constraint:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> unique_items <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'hi'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- INSERT 0 1</span>\n<span class=\"token comment\">-- Query returned successfully in 89 msec.</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> unique_items <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'hi'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- ERROR:   duplicate key value violates unique constraint \"unique_items_item_key\"</span>\n<span class=\"token comment\">-- DETAIL:  Key (item)=(hi) already exists.</span>\n</code></pre>\n<p>However, we can insert as many <code>null</code>s as we want:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> unique_items <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">null</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- INSERT 0 1; Query returned successfully</span>\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> unique_items <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">null</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- INSERT 0 1; Query returned successfully</span>\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> unique_items <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">null</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">-- INSERT 0 1; Query returned successfully</span>\n\n<span class=\"token keyword\">table</span> unique_items<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- item</span>\n<span class=\"token comment\">--</span>\n<span class=\"token comment\">-- \"hi\"</span>\n<span class=\"token comment\">-- `null`</span>\n<span class=\"token comment\">-- `null`</span>\n<span class=\"token comment\">-- `null`</span>\n</code></pre>\n<p>This means that to SQL, <code>null</code> values are not the same, as they are unknown values.</p>\n<p>But now if we <code>select distinct</code> items of the <code>unique_items</code> table, we will get this result:</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token keyword\">distinct</span> item <span class=\"token keyword\">from</span> unique_items<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- item</span>\n<span class=\"token comment\">--</span>\n<span class=\"token comment\">-- `null`</span>\n<span class=\"token comment\">-- \"hi\"</span>\n</code></pre>\n<p>All of the <code>null</code> values are shown as a single item, as if PostgreSQL grouped all the unknown values in one value.</p>\n<h3 id=\"volcano-model\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#volcano-model\"></a>Volcano Model<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#volcano-model\"></a></h3>\n<p>\"Volcano - An Extensible and Parallel Query Evaluation System\" is a research paper by Goetz Graefe that was published in the IEEE Transactions on Knowledge and Data Engineering (Volume: 6, Issue: 1) on February 1994. This evaluation system is called Volcano Model, Volcano iterator model, or sometimes simply referred to as the Iterator model.</p>\n<p>Each relational-algebraic operator produces a tuple stream, and a consumer can iterate over its input streams. The tuple stream interface is essentially: <code>open</code>, <code>next</code>, and <code>close</code>; all operators offer the same interface, and the implementation is opaque.</p>\n<p>Each <code>next</code> call produces a new tuple from the stream, if one is available. To obtain the query output, one \"next-next-next\"s on the final RA operator; that one will in turn use \"next\"s on its inputs to pull tuples allowing it to produce output tuples, etc. Some \"next\"s will take an extremely long time, since many \"next\"s on previous operators will be required before they emit any output.</p>\n<p>Example: <code>select max(v) from t</code> may need to go trough all of <code>t</code> in order to find that maximum.</p>\n<p>A highly simplified pseudocode of the volcano iteration model:</p>\n<pre><code>define volcano_iterator_evaluate(root):\n  q = root // operator `q` is the root of the query plan\n  open(q)\n  t = next(q)\n  while t != null:\n    emit(t) // ship current row to application\n    t = next(q)\n\n  close(q)\n</code></pre>\n<p>Click for more details: Abstract of the Paper</p>\n<ul>\n<li>Read more: <a href=\"https://cs-people.bu.edu/mathan/reading-groups/papers-classics/volcano.pdf\">Volcano-An Extensible and Parallel Query Evaluation System</a></li>\n</ul>\n<h3 id=\"join-ordering-is-np-hard\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#join-ordering-is-np-hard\"></a>Join ordering is NP Hard<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#join-ordering-is-np-hard\"></a></h3>\n<p>When you have multiple joins in your SQL query, the database engine needs to find an order to perform the joins. Finding the best join order is an NP-hard problem. This is why database engines use estimates, statistics, and soft computing approaches to find an order since finding the optimal solution would take forever.</p>\n<p>This is a simplified table of problem classes:</p>\n<div class=\"table-responsive\">\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th>Problem Class</th><th>Verify Solution</th><th>Find Solution</th><th>Example</th></tr></thead><tbody><tr><td>P</td><td> Easy</td><td> Easy</td><td>Multiply numbers</td></tr><tr><td>NP</td><td> Easy</td><td> Hard</td><td>8 Queens</td></tr><tr><td>NP-hard</td><td> Hard</td><td> Hard</td><td>Best next move in Chess</td></tr></tbody></table></div>\n<p>NP-hard problems are at least as hard as the hardest problems in NP. That means if P  NP (which is probabely the case, at least for now), NP-hard problems could not be solved in polynomial time.</p>\n<p><img src=\"/static/images/posts/postgres-meme/np-hard-complete.svg\" alt=\"SIMD\"></p>\n<blockquote>\n<p>If P=NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in creative leaps, no fundamental gap between solving a problem and recognizing the solution once it's found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss; everyone who could recognize a good investment strategy would be Warren Buffett.</p>\n<ul>\n<li>Scott Aaronson</li>\n</ul>\n</blockquote>\n<h3 id=\"database-cracking\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#database-cracking\"></a>Database Cracking<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#database-cracking\"></a></h3>\n<p>Cracking is a technique that shifts the cost of index maintenance from updates to query processing. The query pipeline optimizers are used to massage the query plans to crack and to propagate this information. The technique allows for improved access times and self-organized behavior.</p>\n<p>In other words, Database cracking is an approach for data indexing and index maintainance in a self-organized way. In a database system where database cracking is used, an incoming query requesting all elements which satisfy a certain condition <code>c</code> does not only return a result but it also causes a reodering of the physical database so that all elements satisfying <code>c</code> are stored in a contiguous memery space. Therefore the physical database is devided into multiple parts (cracked).</p>\n<p>By using this mechanism the database reorganizes itself in the most favourable way according to the workload which is put on it.</p>\n<p><img src=\"/static/images/posts/postgres-meme/database-cracking.svg\" alt=\"SIMD\"></p>\n<ul>\n<li>Read more: <a href=\"https://db.in.tum.de/teaching/ws1718/seminarHauptspeicherdbs/paper/werner.pdf\">Database Cracking by David Werner</a></li>\n</ul>\n<h3 id=\"wcoj\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#wcoj\"></a>WCOJ<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#wcoj\"></a></h3>\n<p>Traditional <em>binary join</em> algorithms such as hash join operate over two relations at a time (<code>r1 join r2</code>); joins between more than two relations are implemented by repeatedly applying binary joins (<code>r1 join (r2 join r3)</code>).</p>\n<p>WCOJ (Worst-Case Optimal Join) is a kind of join algorithm whose running time is worst-case optimal for all natural join queries, and is asymptotically faster in worst case than any join algorithm based on such iterated binary joins.</p>\n<ul>\n<li>Read more: <a href=\"https://arxiv.org/pdf/1203.1952.pdf\">Worst-case Optimal Join Algorithms</a></li>\n</ul>\n<h3 id=\"learned-indexes\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#learned-indexes\"></a>Learned Indexes<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#learned-indexes\"></a></h3>\n<p>Learned Indexes are indexing strategies that utilize artificial intelligence approaches and deep-learning models to outperform cache-optimized B-Trees and reduce memory usage. Google and MIT engineers developed such a model and published their work as a pioneer paper with the title \"The Case for Learned Index Structures\". The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records.</p>\n<ul>\n<li>Read more: <a href=\"https://arxiv.org/pdf/1712.01208.pdf\">The Case for Learned Index Structures</a></li>\n</ul>\n<h3 id=\"txid-exhaustion\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#txid-exhaustion\"></a>TXID Exhaustion<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#txid-exhaustion\"></a></h3>\n<p>Transaction ID Exhaustion, often referred to as the \"Wraparound Problem,\" arises due to the limited number of transaction IDs available and the absence of regular database maintenance, known as vacuuming.</p>\n<p>PostgreSQL's MVCC transaction semantics depend on being able to compare transaction ID (XID) numbers: a row version with an insertion XID greater than the current transaction's XID is in the future and should not be visible to the current transaction. But since transaction IDs have limited size (32 bits) a cluster that runs for a long time (more than 4 billion transactions) would suffer transaction ID wraparound: the XID counter wraps around to zero, and all of a sudden transactions that were in the past appear to be in the future  which means their output become invisible. In short, catastrophic data loss. (Actually the data is still there, but that's cold comfort if you cannot get at it.)</p>\n<p>To avoid this, it is necessary to vacuum every table in every database at least once every two billion transactions.</p>\n<ul>\n<li>Read more: <a href=\"https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-WRAPAROUND\">Routine Vacuuming: Preventing Transaction ID Wraparound Failures</a></li>\n</ul>\n<h2 id=\"level-7-pitch-black-zone\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#level-7-pitch-black-zone\"></a>Level 7: Pitch Black Zone<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#level-7-pitch-black-zone\"></a></h2>\n<p><img src=\"/data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27904%27%20height=%27153%27/%3e\"><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fpitch-black.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p><img src=\"/_next/image?url=%2Fstatic%2Fimages%2Fposts%2Fpostgres-meme%2Flevels%2Fpitch-black.jpg&#x26;w=1920&#x26;q=75\" alt=\"The Legendary Postgres meme\"></p>\n<p>Welcome to Pitch Black Zone! Congratulations on your journey to the deepest reaches of PostgreSQL knowledge. Brace yourself for esoteric and cutting-edge topics, where only the boldest dare to venture!</p>\n<h3 id=\"the-halloween-problem\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#the-halloween-problem\"></a>The halloween problem<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#the-halloween-problem\"></a></h3>\n<p>Halloween Problem is a database error that a database system developer needs to be aware of.</p>\n<p>On the Halloween day of 1976, a couple of computer engineers were working on a query that was supposed to give a 10% raise to every employee who earned less than $25,000:</p>\n<p>raise by 10% for salary &#x3C; 25000table definition</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">update</span> employee <span class=\"token keyword\">set</span> salary <span class=\"token operator\">=</span> salary <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>salary <span class=\"token operator\">/</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">where</span> salary <span class=\"token operator\">&#x3C;</span> <span class=\"token number\">25000</span>\n</code></pre>\n<p>This query would run successfully in their database, but when finished all the employees in the database earned at least $25,000. This is because the updated rows were also visible to the query execution engine, and as the match criteria in the <code>where</code> clause was still true, the database continued to increase their salaries until they are over $25,000.</p>\n<p>This could even cause an infinite loop in some cases where updates continually place the updated record ahead of the scan performing the update operation.</p>\n<h4 id=\"attention-1\">ATTENTION<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#attention-1\"></a></h4>\n<p>PostgreSQL does <strong>NOT</strong> have this problem. Halloween Problem is an error in database design, and any database with such a problem is not reliable.</p>\n<h3 id=\"dee-and-dum\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#dee-and-dum\"></a>Dee and Dum<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#dee-and-dum\"></a></h3>\n<ul>\n<li>Table <code>dee</code> is the table that has no columns but a single row. It plays the role of <code>True</code>.</li>\n<li>Table <code>dum</code> is the table that has no columns and no rows. It plays the role of <code>False</code>.</li>\n</ul>\n<p>These theoretical tables and terminology was created by Hugh Darwen. You can read more about the implmentation of these tables in PostgreSQL at <a href=\"https://blog.jooq.org/creating-tables-dum-and-dee-in-postgresql/\">Creating Tables Dum and Dee in PostgreSQL by Lukas Eder</a>. PostgreSQL trigger functions are used to enforce these rules.</p>\n<h3 id=\"serial-is-non-transactional\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#serial-is-non-transactional\"></a><code>SERIAL</code> is non-transactional<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#serial-is-non-transactional\"></a></h3>\n<p>Serial types in PostgreSQL are used to create autoincrementing columns. These data types (<code>smallserial</code>, <code>serial</code>, and <code>bigserial</code>) are not true types, but merely a syntactic sugar for creating unique identifier columns:</p>\n<p>serialequivalent query with sequence</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> tablename <span class=\"token punctuation\">(</span>\n    colname <span class=\"token keyword\">serial</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>Because <code>serial</code> types are implemented using sequences, there may be \"holes\" or gaps in the sequence of values which appears in the column, even if no rows are ever deleted.</p>\n<p>A value allocated from the sequence is still \"used up\" even if a row containing that value is never successfully inserted into the table column. This may happen, for example, if the inserting transaction rolls back. This is why <code>serial</code> types are considered non-transactional as they won't rollback their value in case of a transaction rollback.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> counter<span class=\"token punctuation\">(</span>c <span class=\"token keyword\">serial</span> <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- CREATE TABLE; Query returned successfully.</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> counter <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">default</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- INSERT 0 1; Query returned successfully. &#x3C;- uses id 1</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> counter <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">default</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- INSERT 0 1; Query returned successfully. &#x3C;- uses id 2</span>\n\n<span class=\"token keyword\">begin</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> counter <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">default</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nabort<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- ROLLBACK; Query returned successfully. &#x3C;- uses id 3, rollback doesn't give it back</span>\n\n<span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> counter <span class=\"token keyword\">values</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">default</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- INSERT 0 1; Query returned successfully. &#x3C;- uses id 4</span>\n\n<span class=\"token keyword\">table</span> counter<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- c</span>\n<span class=\"token comment\">--</span>\n<span class=\"token comment\">-- 1</span>\n<span class=\"token comment\">-- 2</span>\n<span class=\"token comment\">-- 4 &#x3C;- the number 3 is missing</span>\n</code></pre>\n<h3 id=\"allballs\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#allballs\"></a>allballs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#allballs\"></a></h3>\n<p>The <code>'allballs'</code> string will turn into the midnight time (<code>00:00:00</code>) when converted to <code>time</code>. This is because \"allballs\" is an slang for \"all zeros\". This slang was historically used in military communications.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> <span class=\"token string\">'allballs'</span>::<span class=\"token keyword\">time</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- time</span>\n<span class=\"token comment\">--</span>\n<span class=\"token comment\">-- 00:00:00</span>\n</code></pre>\n<ul>\n<li>Read more: <a href=\"https://www.postgresql.org/message-id/6EE64EF3AB31D5448D0007DD34EEB3412A75D9%40Herge.rcsinc.local\">PostgreSQL mailing list: Why is 'allballs' accepted as a literal for time?</a></li>\n</ul>\n<h3 id=\"fsyncgate\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#fsyncgate\"></a>fsyncgate<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fsyncgate\"></a></h3>\n<p><code>fsync</code> is an OS system call, and in Linux it is used to synchronize a file's in-core state with storage device. In other words, this system call ensures that the data written to a file is indeed written on the storage device and persisted by transfering/flushing all modified in-core data of the file to the disk or other permanent storage device.</p>\n<p>The term \"fsyncgate 2018\" is referred to the scandals and controversies around the reliability issues of the <code>fsync</code> system call on the PostgreSQL mailing list and elsewhere ( or as some people say, how \"PostgreSQL used fsync incorrectly for 20 years\").</p>\n<p>The issue was raised by Craig Ringer. Quoted from the mailing list:</p>\n<blockquote>\n<p>Hi all</p>\n<p>Some time ago I ran into an issue where a user encountered data corruption after a storage error. PostgreSQL played a part in that corruption by allowing checkpoint what should've been a fatal error.</p>\n<p>TL;DR: Pg should PANIC on fsync() EIO return. Retrying fsync() is not OK at least on Linux. When fsync() returns success it means \"all writes since the last fsync have hit disk\" but we assume it means \"all writes since the last SUCCESSFUL fsync have hit disk\".</p>\n<p>...</p>\n</blockquote>\n<ul>\n<li>Read more: <a href=\"https://www.postgresql.org/message-id/flat/CAMsr%2BYHh%2B5Oq4xziwwoEfhoTZgr07vdGG%2Bhu%3D1adXx59aTeaoQ%40mail.gmail.com\">PostgreSQL mailing list: PostgreSQL's handling of fsync() errors is unsafe and risks data loss at least on XFS</a></li>\n</ul>\n<h3 id=\"every-sql-operator-is-actually-a-join\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#every-sql-operator-is-actually-a-join\"></a>Every SQL operator is actually a join<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#every-sql-operator-is-actually-a-join\"></a></h3>\n<p>Every SQL operator can be represented using a join. One way to think about joins is that they \"look stuff up\" in a relation.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> age<span class=\"token punctuation\">,</span> age <span class=\"token operator\">*</span> age <span class=\"token keyword\">as</span> age_squared <span class=\"token keyword\">from</span> person<span class=\"token punctuation\">;</span>\n</code></pre>\n<p>For example in the above query, rather than computing <code>age * age</code> explicitly, we could also just look it up in the <code>squares</code> function table (with columns <code>x</code> and <code>xx</code>):</p>\n<pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">select</span> age<span class=\"token punctuation\">,</span> xx <span class=\"token keyword\">as</span> age_squared <span class=\"token keyword\">from</span> person <span class=\"token keyword\">join</span> squares <span class=\"token keyword\">on</span> age <span class=\"token operator\">=</span> x<span class=\"token punctuation\">;</span>\n</code></pre>\n<ul>\n<li>Read more: <a href=\"https://justinjaffray.com/join-the-ultimate-projection\">JOIN: The Ultimate Projection</a></li>\n</ul>\n<h3 id=\"null-1\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#null-1\"></a><code>NULL</code><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#null-1\"></a></h3>\n<p><code>NULL</code> can be tricky sometimes. Don't you think?</p>\n<h2 id=\"conclusion\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#conclusion\"></a>Conclusion<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#conclusion\"></a></h2>\n<p>We've seen a cool meme on the internet and we've tried to understand it. This was a journey from the skies on top of the SQL iceberg, to the deepest parts of the ocean where everything was pitch-black. We've looked at each part of this meme while wearing our PostgreSQL hat to see how these topics are related to the PostgreSQL implementation of SQL and relational databases.</p>\n<p>Yet again, shout out to Jordan Lewis and his friends for creating this cool and informative meme.</p>\n<h2 id=\"references\"><a href=\"https://avestura.dev/blog/explaining-the-postgres-meme#references\"></a>References<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#references\"></a></h2>\n<p>Resources I've used to write this blog post:</p>\n<ul>\n<li>PostgreSQL Documentations. [Online]. <a href=\"https://www.postgresql.org/docs/\">postgresql.org/docs</a></li>\n<li>Fontaine, D. (2019b). The Art of PostgreSQL: Turn Thousands of Lines of Code Into Simple Queries.</li>\n<li>Schnig, H. (2023). Mastering PostgreSQL 15: Advanced techniques to build and manage scalable, reliable, and fault-tolerant database applications. Packt Publishing Ltd.</li>\n<li>Dombrovskaya, H., Novikov, B., &#x26; Bailliekova, A. (2021). PostgreSQL query Optimization: The Ultimate Guide to Building Efficient Queries. Apress.</li>\n<li>Riggs, S., &#x26; Ciolli, G. (2022). PostgreSQL 14 Administration Cookbook: Over 175 Proven Recipes for Database Administrators to Manage Enterprise Databases Effectively.</li>\n<li>Use the Index, Luke! A Guide to Database Performance for Developers. [Online]. <a href=\"https://use-the-index-luke.com/\">use-the-index-luke.com</a></li>\n<li>Gulutzan, P., &#x26; Pelzer, T. (2003). SQL Performance Tuning. Addison-Wesley Professional.</li>\n<li>Cockroach Labs Blog. [Online]. <a href=\"https://www.cockroachlabs.com/blog/\">Cockroach Labs Blog</a></li>\n<li>Justin Jaffray's Blog. [Online]. <a href=\"https://justinjaffray.com/posts\">Justin Jaffray's Blog</a></li>\n</ul>\n<hr>\n<h2 id=\"tags\">Tags<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#tags\"></a></h2>\n<ol>\n<li><a class=\"color-tag\" style=\"--tag-color: #c77986;\" href=\"/notes/0ce4gh9w22elz738jbxchfo\">bookshelf</a></li>\n</ol>","noteIndex":{"id":"Iy0MoL0KnL55Br3AfTS2C","title":"Luke","desc":"","updated":1766965759366,"created":1644449449778,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"a724de3efd251cf89fe82a5860d9008b","links":[{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"life-tips","position":{"start":{"line":43,"column":5,"offset":2710},"end":{"line":43,"column":29,"offset":2734},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"life-tips","anchorHeader":"wodenokoto"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2026.articles","alias":"What I read in 2026","position":{"start":{"line":72,"column":3,"offset":4440},"end":{"line":72,"column":45,"offset":4482},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2026.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2025.articles","alias":"2025","position":{"start":{"line":73,"column":5,"offset":4487},"end":{"line":73,"column":32,"offset":4514},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2025.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2024.articles","alias":"2024","position":{"start":{"line":74,"column":5,"offset":4519},"end":{"line":74,"column":32,"offset":4546},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2024.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2023.articles","alias":"2023","position":{"start":{"line":75,"column":5,"offset":4551},"end":{"line":75,"column":32,"offset":4578},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2023.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"read.2022.articles","alias":"2022","position":{"start":{"line":76,"column":5,"offset":4583},"end":{"line":76,"column":32,"offset":4610},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"read.2022.articles"}},{"type":"wiki","from":{"fname":"root","id":"Iy0MoL0KnL55Br3AfTS2C","vaultName":"vault"},"value":"journal.what-i-struggled-brag-in","position":{"start":{"line":82,"column":3,"offset":4746},"end":{"line":82,"column":39,"offset":4782},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"journal.what-i-struggled-brag-in"}}],"anchors":{"what-i-read-in-past":{"type":"header","text":"What I read in past","value":"what-i-read-in-past","line":76,"column":0,"depth":2}},"children":["zd4mq442jike0pr0wba1u3m","6hzeqsofq67gdk88flxlkhp","778ijii93yu5uwnrwmn5zi4","g1fngdjl25nes6fs3lip602","ZbdkdApFqLdks4Moq92R9","uoc5hhki3o4py15cesddu8q","9qf7j06jtdkm6rnx9ymvwb0","5zn10cvj7ajy2gh2is5nqmg","4qo9ma0z0yu1czns6pxl7y5","ok0e729ho7o09xetujkxc0m","GR5x8HnNFEN6fU2UBSEIK","yirtnlj8q24yutcf3ss1xqy","eq0wc6t7wl2wv221yb68ro4","7x2fnv4j6gxts08qk0jguny","ettkt3iClONnxpbGwBVLl","7l4knev6v613tbuoskvmbdg","hvh5bud6yp7dc89tuh95tr9","4fvoqrplw0cweo554usbjos","f8qsfql0a9v8thpeo82udfa","1swsbrhqi9jk41v9eodyi5q","SQqYupi6EFddTerBA8RRD","hjNeNc1F2JUh0lTWanH4h","qf0l4wbrc9jgooyzexmbq5v","o7xruzrah5wzqetottecss7","z1zo2mp6ddji5p317i4x9xw","v06c2tjelh341x4resa50fh","0yqesk4rcffwgyuab5x8rfa","sy2vkbtyu671chkvgn1yt8j","ufixpmxoydiccoh59kphrib","alswadkx4wb05y1z9iwfzfv","1daut9dpw70xd0zh5a7j5p4"],"parent":null,"data":{},"body":"\nHi there . I'm a Front-end developer.\n\n---\n\n-        .          .\n\n  -          .   , ,  .\n\n-  ->  - [On The Death of Daydreaming](https://www.afterbabel.com/p/on-the-death-of-daydreaming)\n  - boredom -> easy fun -> art -> profit?\n\n> I've often described my motivation for building software to others using imagery: I like to go find a secluded beach, build a large, magnificent sand castle, and then walk away. Will anyone notice? Probably not. Will the waves eventually destroy it? Yep. Did I still get immense satisfaction? Absolutely. - [aliasxneo](https://news.ycombinator.com/item?id=41497113)\n\n> We love to see the process, not just the result. The imperfections in your work can be beautiful if they show your struggle for perfection, not a lack of care. - [ralphammer](https://ralphammer.com/is-perfection-boring/)\n\n> Simplicity, even if it sacrifices some ideal functionality has better survival characteristics than the-right-thing. - [The Rise of Worse is Better](https://www.dreamsongs.com/RiseOfWorseIsBetter.html)\n\n> [Roberto Blake was talking about making 100 crappy videos](https://www.youtube.com/watch?v=OnUBaQ1Sp_E) to get better over time. Putting in the reps and improving a little bit each time.\n>\n> Putting in the work without expecting any external reward at first (eg views, followers, likes, etc) will pay off in the long run. - [100 Scrappy Things](https://www.florin-pop.com/blog/100-scrappy-things/)\n\n> Make the difficult habitual, the habitual easy, and the easy beautiful. - [Constantin S. Stanislavski](https://www.goodreads.com/quotes/7102271-make-the-difficult-habitual-the-habitual-easy-and-the-easy)\n\n> A good match is a **structured** dance, where players aim to **score** while they are following well-defined **rules**. This **freedom within a structure** is what makes it fun. - [ralphammer](https://ralphammer.com/how-to-get-started/)\n\n- [Pivot Points](https://longform.asmartbear.com/pivot-points/)\n\n  - non-judgmental aspects of personality that can be strengths in some contexts and weaknesses in others\n  - Pivot Points are fixed in the short term\n\n- [Hedged Bets](https://longform.asmartbear.com/predict-the-future/#hedged-bets)\n  - trading slightly less maximum upside for predictable, net-positive outcomes.\n\n> Motivation often comes after starting, not before. Action produces momentum.\n> [When you start a new habit, it should take less than two minutes to do.](https://jamesclear.com/how-to-stop-procrastinating)\n>\n> - James Clear\n\n> Focus is more about **not** keeping busy when you need to wait for something.  \n> Eat the boredom for a minute.\n>\n> - [[life-tips#wodenokoto]]\n\n> [4 minutes run hard enough to push heart rate to 90%, 3 minutes recover, repeat 4 times](https://news.ycombinator.com/item?id=34213181)\n>\n> - https://www.ntnu.edu/cerg/advice\n> - [Get running with Couch to 5K](https://www.nhs.uk/live-well/exercise/running-and-aerobic-exercises/get-running-with-couch-to-5k/)\n\n> [recommended routine - bodyweightfitness](https://www.reddit.com/r/bodyweightfitness/wiki/kb/recommended_routine/) - I Don't Have This Much Time!\n>\n> - Don't workout at all (saves anywhere from 20 to 60 minutes, but really, really, really, really, really, really, really, really, really not recommended)\n\n>            .   .      .\n>\n>    .   .        .        .      .         \n>\n> -  . . P.10~13\n\n> I think it should be everyone's primary focus to sleep well, drink water, get outside, get active, and eat generally decently. I hate to say it, but if you're not eating a good amount of vegetables and fruit, decent protein, sleep, etc, no amount of XYZ will catch up to that detriment. - [CE02](https://news.ycombinator.com/item?id=35056071)\n\n> My real battle is doing good versus doing nothing. - [Deirdre Sullivan](https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral)\n\n[Kind Engineering](https://kind.engineering/) - How To Engineer Kindness\n\n> Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. - [Teller](https://www.goodreads.com/quotes/6641527-sometimes-magic-is-just-someone-spending-more-time-on-something)\n\n---\n\n## What I read in past\n\n- [[What I read in 2026|read.2026.articles]]\n  - [[2025|read.2025.articles]]\n  - [[2024|read.2024.articles]]\n  - [[2023|read.2023.articles]]\n  - [[2022|read.2022.articles]]\n-  [Gists](https://gist.github.com/Luke-SNAW)\n-  [Journals](https://luke-snaw.github.io/Luke-SNAW__netlify-CMS.github.io/)\n\n---\n\n- [[journal.what-i-struggled-brag-in]]\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":false,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.115.0","enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Luke SNAW","description":"Personal knowledge space"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","siteUrl":"https://luke-snaw.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}
---
id: 7lj5gliqgn1gf7upu0nmv2c
title: AI Founder's Bitter Lesson.
desc: ""
updated: 1739433078343
created: 1739433033847
---

> https://lukaspetersson.com/blog/2025/bitter-vertical/
>
> https://news.hada.io/topic?id=19154

- AI Safety 스타트업 Andon Labs (YC w24) 창업자 Lukas Petersson 의 4부작 글을 하나로 정리
  - 역사적으로 AI 분야에서는 일반적인 접근 방식이 항상 승리했음
  - 현재 AI 애플리케이션 분야의 창업자들은 과거 AI 연구자들이 저지른 실수를 반복하고 있음
  - 더 나은 AI 모델은 범용 AI 애플리케이션을 가능하게 할 것이며, 동시에 AI 모델과 관련된 소프트웨어의 부가가치는 감소할 것
- 챕터 1: 역사는 반복된다
- 챕터 2: 경쟁 우위가 없음
- 챕터 3: 역사의 발자취
- 챕터 4: 당신은 마법사입니다

---

## 챕터 1: 역사는 반복된다(History Repeats Itself)

### tl;dr:

- 최근 AI 발전은 다양한 문제를 해결하는 새로운 제품을 가능하게 만듦
- 그러나 대부분의 제품은 현재 모델의 제한된 능력 내에서 작동, 진정한 AI의 힘인 유연성을 활용하지 못함
- AI 역사는 일반적인 접근 방식이 항상 승리한다는 것을 반복적으로 보여줌. Richard Sutton은 "The Bitter Lesson"에서 이를 강조
- 오늘날 AI 창업자들은 과거 AI 연구자들이 겪었던 실수를 반복하는 경향이 있음

### Richard Sutton의 에세이 : [The Bitter Lesson](http://incompleteideas.net/IncIdeas/BitterLesson.html) 요약. ([한글 번역](https://newsight.tistory.com/302))

- 다음과 같은 교훈을 제시함:
  - AI 연구자들은 지식을 에이전트에 통합하려 시도함
  - 이는 단기적으로 효과적이고 만족감을 줌
  - 장기적으로는 발전이 정체되고 더 나아가 진전에 방해가 됨
  - 결국 정반대의 접근법에서 기초한 계산량의 확장을 통해 돌파구를 마련함
- AI 연구에서도 이러한 패턴이 반복적으로 관찰되며, 현재도 끝나지 않았다고 경고

### AI 제품과 The Bitter Lesson

- AI 제품은 일반적으로 AI 모델과 이를 둘러싼 소프트웨어로 구성
- 성능을 향상시키는 두 가지 방법:
  1. 소프트웨어를 제약해 오류를 줄이는 엔지니어링 작업
  2. 더 나은 모델이 출시될 때까지 기다리는 것
- 모델이 발전할수록 엔지니어링 작업의 가치는 줄어듦
- OpenAI의 새로운 모델 출시로 프롬프트 엔지니어링의 가치가 감소한 사례는 이를 보여줌

### 제약 유형과 AI 제품

- AI 제품의 제약 요소는 두 가지로 분류 가능:
  - **특정성**: 특정 문제에 초점을 맞춘 소프트웨어 (수직적 솔루션)
  - **자율성**: AI가 스스로 작업을 수행할 수 있는 능력
- 이를 바탕으로 AI 제품 분류 가능: 특정성(Vertical vs. Horizontal)과 자율성(Workflow vs. Agent)
  - Vertical Workflow
    - 특정 문제를 해결하기 위해 고정된 순서로 동작하는 시스템
    - Harvey가 대표적인 사례로, 특정 법률 작업과 같은 좁은 영역의 문제를 처리하도록 설계된 워크플로 시스템
  - Vertical Agent
    - 특정 작업 영역에서 자율적으로 동작하며, 작업 과정에서 자체적으로 결정을 내리는 시스템
    - Devin이 대표적인 사례로, 제한된 도구와 데이터를 사용하여 반복적인 작업을 수행하며 필요에 따라 작업 단계를 조정
  - Horizontal Workflow
    - 다양한 문제를 해결할 수 있는 일반적인 워크플로 시스템
    - ChatGPT가 대표적인 사례로, 여러 종류의 입력에 대해 사전 정의된 절차에 따라 응답하지만 완전한 자율성을 가지지 않음
  - Horizontal Agent
    - 다양한 문제를 다룰 수 있는 완전히 자율적인 시스템
    - Claude computer-use가 대표적인 사례로, 회사의 표준 소프트웨어를 사용하여 사용자의 지시에 따라 작업하며 인간과 유사한 방식으로 문제를 해결

### Vertical Workflow와 The Bitter Lesson의 연결

- Demo Day에서 발표된 대부분의 제품이 Vertical Workflow 형태에 해당
  - 현재 모델의 신뢰도가 충분하지 않아 다른 접근 방식이 어려운 상황
  - 복잡한 문제도 Vertical Workflow로 제한하여 수용 가능한 성능을 구현하려는 경향
- 엔지니어링 작업으로 이러한 솔루션을 개선할 수 있으나, 한계가 존재
  - 현재 모델로 해결할 수 없는 문제는 더 발전된 모델을 기다리는 것이 더 나은 전략
  - Leopold Aschenbrenner의 관찰: 더 나은 모델을 기다리는 시간이 엔지니어링 작업보다 짧을 가능성

### The Bitter Lesson과 현재 AI 제품의 관계

- AI 연구자들은 “허용 가능한 성능”을 위해 지식 기반 솔루션을 엔지니어링하였으나, 결국 더 많은 계산 자원을 활용한 일반 솔루션이 이를 능가
- 현재의 AI 제품 개발 방식은 이러한 패턴과 유사

### Bitter Lesson의 네 가지 관찰과 제약 유형의 적용

Bitter Lesson에서 언급된 네 가지 주요 관찰은 AI 제품의 자율성과 특정성 제약에도 뚜렷하게 반영됨.  
이를 각각의 제약에 따라 설명하면 다음과 같음:

1. **첫 번째 관찰: AI 연구자들은 지식을 에이전트에 통합하려 함**

- 자율성 제약:
  - 개발자는 자율적 에이전트를 실험하지만 신뢰성이 떨어짐
  - 대신 작업 단계를 워크플로 형태로 하드코딩하여 자신이 문제를 해결하는 방식과 동일한 절차를 따르도록 만듦
- 특정성 제약:
  - 개발자는 일반적인 문서 분석 시스템을 만들려 하지만 신뢰성 문제로 어려움을 겪음
  - 대신 재무제표와 같은 특정 유형의 문서에 초점을 맞추고, 구체적인 메트릭과 검증 규칙을 하드코딩

2. **두 번째 관찰: 단기적으로는 효과적이며 연구자에게 만족감을 줌**

- 자율성 제약:
  - 워크플로를 하드코딩하면 안정성이 증가함
- 특정성 제약:
  - 좁은 범위의 문서와 메트릭만 처리하도록 전문화하면 정확도가 향상됨

3. **세 번째 관찰: 장기적으로는 발전이 정체되며 더 나아가 방해가 됨**

- 자율성 제약:
  - 하드코딩된 워크플로는 새로운 상황을 다룰 수 없어서 부정확한 결과를 초래
- 특정성 제약:
  - 특정 문제만 다룰 수 있는 시스템은 병합 문서나 실적 발표 분석과 같은 관련 작업을 처리하지 못함
  - 각각의 작업마다 별도의 특화 시스템이 필요

4. **네 번째 관찰: 계산 자원의 확장을 기반으로 돌파구가 마련됨**

- 자율성 제약:
  - 새로운 모델은 동적으로 적합한 접근 방식을 찾아내고, 필요 시 오류를 수정하며 신뢰할 수 있는 자율적 에이전트를 가능하게 만듦
- 특정성 제약:
  - 새로운 모델은 모든 비즈니스 문서를 포괄적으로 이해하며 관련 정보를 추출할 수 있어, 특화된 시스템이 더 이상 필요하지 않게 됨
- 자율성이 필요한 문제에서는 더 자율적인 제품이 더 나은 성능을 발휘
- 복잡하고 넓은 입력 공간을 다룰 때는 덜 특화된 제품이 더 나은 결과를 제공

### 마무리: AI 스타트업과 The Bitter Lesson

- 이 글은 AI에서 스타트업의 역할을 탐구하는 4부작 시리즈 중 첫 번째로, 도메인 지식을 활용한 AI 모델이 계산 자원을 활용한 모델에 의해 꾸준히 대체되는 역사적 패턴을 강조
- 오늘날의 AI 제품은 이 패턴과 놀랍도록 유사한 모습을 보임
- 현재 모델의 한계를 보완하기 위해 소프트웨어를 개발하는 것은, 특히 모델이 빠르게 발전하는 상황에서는 실패 가능성이 높은 전략
- YC 파트너 Jarred의 지적: 초기 세대의 수직적 워크플로 LLM 앱들은 차세대 GPT 모델에 의해 대체됨
- Sam Altman의 조언: 더 나은 모델 출시를 두려워하지 않고, 이를 기대할 수 있는 스타트업을 구축하는 것이 중요
- 많은 AI 애플리케이션 레이어의 창업자들이 새로운 모델 출시를 기대하며 들떠 있으나, 이는 위험한 신호일 수 있음
  - 더 나은 모델이 출시될 경우, 현재의 경쟁 우위를 줄일 가능성이 큼
  - 특히, 더 어려운 문제를 더 효과적으로 해결할 수 있는 제품 성능 관점에서는 이러한 위험이 더욱 뚜렷
- 다음 글에서는 시장 채택이라는 또 다른 차원을 탐구하고, 더 나은 성능이 반드시 시장에서의 성공을 보장하지 않음을 논의할 예정

---

## [챕터 2: 경쟁 우위가 없음(No Powers)](https://lukaspetersson.com/blog/2025/power-vertical/)

### tl;dr:

- AI 역사에서 모델 한계를 도메인 지식으로 보완하려는 접근은 결국 계산 자원을 활용해 일반화된 접근을 택하는 방식에 밀린 사례가 많음
- 수직적 AI(vertical AI)는 현재 모델의 한계를 보완하기 위해 특정 작업 흐름(워크플로)을 사전 정의해 정확도를 높이는 방식으로 시장에 먼저 진입함
- 수평적 AI(horizontal AI)는 ChatGPT처럼 범용 모델을 활용하고 계속 발전하는 형태로, 모델이 개선될 때마다 여러 분야에서 더 뛰어난 성능을 보일 가능성임
- 장기적으로 수평적 AI는 여러 제약을 두는 수직적 AI보다 높은 성능과 유연성을 보유해 우위를 점할 가능성임

### 문제 난이도와 성능 곡선

- Figure 1은 수직적 AI가 먼저 시장에 진입하지만, 모델이 개선된 수평적 AI가 결국 성능을 추월하는 단순 예시임
- 문제 난이도가 높은 경우(Figure 2) 수직적 AI는 아예 충분한 성능에 도달하지 못하고, 수평적 AI가 개선되어서야 비로소 해결이 가능해짐
- 현 시점에 수직적 AI가 적용 가능한 문제들은 상대적으로 ‘난이도가 낮은 문제’로, 이 범주에서는 수직적 AI가 선점 효과를 누릴 수 있지만 장기 경쟁력은 불확실함

### 수평적 AI가 제공하는 ‘원격 협업자’ 개념

- 향후 수평적 AI는 원격 근무자처럼 컴퓨터와 계정을 부여받고 필요한 데이터를 스스로 찾아 사용할 수 있는 형태로 발전할 가능성이 있음
- ChatGPT 등 이미 많은 사용자가 익숙해진 UI가 점차적으로 강화되어 기업에서 빠르게 도입할 수 있는 여건이 갖춰질 수 있음
- 수평적 AI는 모델이 개선될 때마다 다양한 기능을 즉시 흡수하기 때문에, 수직적 AI보다 경쟁 우위를 유지하기가 쉬움

### 선행 사례: AcademicGPT와의 경험

- GPT-3.5 시점에 긴 입력 한계를 극복하기 위해 AcademicGPT를 출시했지만, GPT-4가 긴 입력을 기본 제공하자 기존 솔루션은 빠르게 도태되었음
- YC 파트너 Jared의 말처럼 ‘첫 번째 세대 LLM 앱은 다음 세대 모델에 대부분 밀렸음’
- 여러 기능을 동시에 제공하는 수직적 AI도 결국 모델 성능이 발전하면 동일한 과정을 겪을 위험이 있음

### Helmer의 7 Powers 분석

- 이 장에서는 Hamilton Helmer의 7가지 경쟁 우위(Switching Costs, Counter-Positioning, Scale Economies, Network Economies, Brand Power, Process Power, Cornered Resource)를 통해 수직적 AI가 수평적 AI와 경쟁할 수 있는가를 살펴봄
- ## Switching Cost (전환 비용)
  - 사용자들이 특정 수직적 AI 솔루션의 UI나 워크플로에 익숙해졌어도, 수평적 AI는 ‘신규 직원을 채용하듯’ 간단히 온보딩하는 방식으로 적용 가능함
  - 이미 ChatGPT 등 수평적 AI 솔루션을 도입한 기업이 늘고 있어, 전환 과정이 어렵지 않을 가능성임
  - 가격 측면에서도 수평적 AI는 여러 수직적 솔루션을 통합할 수 있어 비용 절감 효과가 예상됨
- ## Counter Positioning (역포지셔닝)
  - 수직적 AI는 특정 시장에 특화된 솔루션으로 맞춤형 가치를 제공할 수 있지만, 모델이 점차 개선되면 수평적 AI가 전반적으로 더 나은 성능을 보일 가능성임
  - 수직적 AI는 새로운 모델을 도입할 때마다 기존의 ‘제약’으로 인해 차별성을 잃거나, 제약을 해제하면 결국 수평적 모델과 유사해지는 딜레마를 겪음
- ## Scale Economy (규모 경제)
  - 수직적 AI도 SaaS와 마찬가지로 규모에 따라 비용을 낮출 수 있지만, 수평적 AI 역시 다수 분야를 통합해 비용을 분산시킬 수 있는 장점이 있음
  - 대규모 R&D 투자를 통해 개발된 수평적 모델을 다양한 용도에 적용함으로써 비용 절감을 가속화할 수 있음
- ## Network Economy (네트워크 효과)
  - 수직적 AI와 수평적 AI 모두 사용자 데이터를 바탕으로 개선 가능성은 있지만, 수평적 AI는 더 폭넓은 사용자 집단에서 피드백을 얻어 모델의 전반적 성능을 향상할 수 있는 장점이 큼
  - 다양한 분야에서 축적된 데이터를 활용해 모델 전반이 개선되므로, 수직적 AI가 감당하기 어려운 속도로 발전할 수 있음
- ## Brand Power (브랜드 파워)
  - 브랜드 파워는 작은 스타트업 단계에서 얻기 어려운 우위임
  - OpenAI나 Google처럼 이미 브랜드 영향력이 큰 기업들은 예외지만, 대부분 수직적 AI 스타트업은 브랜드 파워를 무기로 삼기 어렵음
- ## Process Power (프로세스 파워)
  - 프로세스 파워 역시 대규모 기업이 많은 시간에 걸쳐 다듬은 운영 체계를 통해 얻게 되는 우위임
  - 초기 스타트업 단계에서 이는 거의 해당되지 않는 범주임
- ## Cornered Resource (독점적 자원)
  - 독점적 자원은 특정 데이터나 자원을 오직 한 회사가 보유하고, 해당 자원이 그 분야에서 반드시 필요한 경우에만 큰 경쟁 우위가 됨
  - 많은 AI 스타트업이 ‘독점 데이터’가 있다고 주장하지만, 실제로는 그 데이터가 완전히 독점적이지 않거나 그 데이터가 없어도 모델이 충분히 학습 가능한 경우가 많음
  - 예외적으로 진정한 독점 자원을 확보한 기업은 수평적 AI의 발전에도 불구하고 경쟁력을 유지할 가능성임

## 마무리

- 결국, 수직적 AI가 선점 효과를 누리는 시나리오에서도 수평적 AI가 더 높은 성능을 갖추면 대부분의 수직적 AI는 유지하기 어려운 상황임
- Helmer의 7 Powers 중 진정한 ‘Cornered Resource’를 확보한 경우에만 수직적 AI가 장기적인 모멘텀을 확보할 가능성임
- AcademicGPT가 GPT-4 출시 후 빠르게 몰락한 사례처럼, 여러 기능을 보강한 수직적 AI도 모델이 개선되면 결국 비슷한 흐름을 맞이할 수 있음
- 다음 장(3장)에서는 ‘원격 협업자’ 형태의 수평적 AI가 언제, 어떻게 현실화될지 예측하고, 이를 가로막는 기술, 규제, 신뢰, 경제적 장벽 등에 대해 구체적으로 살펴볼 예정임

---

## [챕터 3: 역사의 발자취(A Footnote in History)](https://lukaspetersson.com/blog/2025/power-vertical/)

- Anthropic의 CEO가 "가상 협업자(virtual collaborator)" 개념을 설명한 인터뷰를 공개함
- 이는 필자가 이 시리즈에서 "수평적 AI 제품(horizontal AI product)"이라 부른 개념과 유사함
- OpenAI는 곧 "Operator"를 발표할 것으로 예상되며, 유출된 벤치마크에 따르면 Claude보다 성능이 크게 앞섬 (OSWorld 벤치마크에서 Claude는 22%, Operator는 38%)
- 이러한 성능 향상은 예상된 범위 내이며, 필자는 3개월 전의 예측을 그대로 유지함
- 이전 챕터에서 수직적 AI 애플리케이션이 경쟁력을 유지하기 어려운 이유를 설명함
  - 일반적 AI 솔루션과 성능 차이가 줄어듦
  - 수평적 AI 제품이 경쟁력을 갖추면, 수직적 AI 제품이 방어할 방법이 거의 없음
- 중요한 질문: "수직적 AI에서 수평적 AI로의 전환이 언제 발생할 것인가?"
  - 10년 후라면 지금 수직적 AI를 개발하는 것이 의미 있을 수도 있음
  - 하지만 1~2년 내에 변화가 온다면, 완전히 다른 전략이 필요함
- 모든 산업에서 동시에 수직적 AI에서 수평적 AI로 전환이 일어나지는 않음
- 그러나 현재 대부분의 AI 스타트업이 집중하는 시장은 상대적으로 단순한 분야이므로, 주요 산업에서는 유사한 시기에 변화가 발생할 것으로 예상됨
- 2027년까지는 대부분의 산업에서 수직적 AI 제품이 살아남기 어려울 것으로 전망됨
- "채택(adoption)"이란 사용자가 새로운 문제를 해결하거나 기존 문제의 해결 방법을 변경할 때 어떤 제품을 선택하는지를 의미함
- 다음 요소는 고려되지 않음
  - **시장 점유율**: 기존 계약 등이 영향을 미칠 수 있음
  - **절대적 크기**: AI가 새로운 활용 사례를 열면서 시장이 확장될 것이지만, 본 분석에서는 상대적 변화만을 고려함
  - **잠재적 가치**: 현재 시점에서 사람들이 어떤 솔루션을 선택하는지를 평가하며, 미래의 개선 가능성은 포함되지 않음
- 예를 들어, A에서 B로 흐름이 이동한다면, 과거에는 A가 선호되었지만 이제는 B가 더 나은 선택지로 여겨짐

### 수직적/수평적 AI 및 워크플로우/에이전트 개념

- "수직적(vertical) AI"와 "수평적(horizontal) AI"는 서로 다른 AI 제품 유형을 의미함
- "워크플로우(workflow)"와 "에이전트(agent)"도 AI 제품을 분류하는 개념임
- 본 문서에서는 수평적 AI 제품 내에서 워크플로우와 에이전트 개념을 하나로 묶어 설명
  - 같은 회사가 두 가지 기능을 모두 포함하는 제품을 개발할 가능성이 높음
  - 예를 들어, ChatGPT가 에이전트 기능을 추가하면서도 기존 워크플로우 기반을 유지할 수 있음

### 과거

- (1) Pre-ChatGPT 시점은 전통적 소프트웨어가 시장을 지배하던 상황
- (2) ChatGPT 출시로 인해 최초의 의미 있는 수평적 AI 제품이 등장
- (3) GPT-3.5 API 등장 이후, 처음으로 AI에 특화된 여러 수직적 제품이 출시되기 시작

### 올해

- (4) 2025년에 모델 성능이 실용적인 에이전트로 활용될 만큼 안정화될 것이라는 예상
  - 지금까지는 연구 프로젝트나 제한적인 시험 용도로만 사용되던 에이전트가 본격적으로 도입될 전망
  - 기존 수직적 워크플로우 제품들도 AI 에이전트 형태로 전환될 가능성
- (5) 에이전트가 등장해도 2025년까지는 수직적 워크플로우가 지배적인 위치를 유지할 것으로 예상
  - 이미 도입된 툴을 바꾸기 꺼리는 사용자 습관과, 그동안 구축해놓은 엔지니어링 자산을 계속 활용하려는 개발자의 관성이 작용
- (6) ChatGPT, Claude, Gemini 같은 주요 수평적 AI 제품들이 기능을 확장하며 더 많은 수직적 분야를 커버할 것으로 전망
  - 수직적 AI 제품의 기존 특화 기능이 수평적 AI 제품에 빠르게 흡수될 가능성
  - 이미 ChatGPT가 데스크톱 앱과 연동을 시작한 상황

### 가까운 미래

- (7) 수평적 AI 에이전트와 인간 노동자의 능력 격차가 점점 좁혀질 것으로 예상
  - 전문가 수준에 이르지는 못하더라도, 일반적인 사무 작업을 상당히 자동화할 만한 성능을 확보할 것으로 관측
  - 이에 따라 수직적 AI 솔루션의 존재 이유가 줄어들 수 있음
  - 구체적인 예시:
    - 개인 사용자는 세금 신고나 취업 준비 같은 복잡 업무를 수평적 에이전트에게 맡길 가능성
    - 기업은 주니어급 인력을 상당 부분 대체하거나 감축할 가능성
    - 한 사람만으로도 유니콘 가치를 창출하는 사례가 등장할 가능성
- (8) 전통적 소프트웨어는 에이전트가 활용할 수 있는 인터페이스로서 가치를 계속 유지할 것으로 전망
  - 에이전트가 모든 소프트웨어를 직접 새로 만드는 것보다 기존 소프트웨어를 활용하는 편이 비용 효율적일 가능성
  - 특히 범용적·수평적 소프트웨어가 살아남을 확률이 높다는 분석
- (9) 생존하는 수직적 AI 제품은 2장에서 언급된 방어적 자원(독점 데이터, 특허 등)을 확보한 소수일 것으로 예상
  - 이들은 그 자원을 높은 가치로 매각할 수도 있을 가능성

### 2024 - 발전이 멈췄는가?

- 2024년에 AI 모델의 정체가 있었다는 주장은 설득력이 낮다는 평가
  - o3 출시 이전부터 GPT-4, Claude, Open Weight 모델 등 다양한 분야에서 모델 성능이 꾸준히 개선되어온 양상
  - ARC-AGI, GPQA Diamond 등에서의 벤치마크 점수가 급진적으로 향상되어 온 흐름
- Anthropic은 Claude 2에서 Claude 3, 그리고 Claude 3.5 Sonnet으로 빠르게 진화했고, 공개되지 않은 업그레이드를 사내에서 활용했다는 추측이 제기됨
- 이로 인해 2024년이 AI 모델 개선이 멈춘 해라는 주장에는 근거가 부족하다는 견해

### 잠재적 장애물

- **Model Stagnation**: 2024년에는 정체가 없었지만 2025년 이후 모델 발전이 멈출 수 있다는 우려
  - Ilya Sutskever가 NeurIPS에서 전통적 사전학습(Pre-training) 방식의 한계를 언급했으나, 시험 시점에서의 연산(Test-time compute) 등 다른 길이 존재함을 동시에 제안
  - 주요 AI 연구 기관과 기업들은 여전히 거대 컴퓨팅 자원에 적극 투자 중
- **Regulation**: 예상 밖의 규제가 등장하면 AI 발전에 제약이 생길 가능성
- **Trust Barriers**: 에이전트의 안정성과 신뢰성에 대한 사용자 우려가 존재
  - 역사적으로 엘리베이터 자동화에 대한 두려움이 결국 사라진 전례를 들어, 시간이 지나면 극복될 것이라는 관측
- **AI Labs Hesitate**: Anthropic이나 OpenAI 등이 실제 기술적 역량이 있어도 사용자 상호작용을 일부 제한적으로 두는 사례가 있을 수 있음
- **Expensive Inference**: o3 사례처럼 고성능 추론이 매우 높은 비용을 요구할 수 있음
  - 하지만 추론 비용이 시간이 지날수록 낮아지고 있고, 에이전트가 모든 작업에 고성능 추론을 동일하게 적용하지 않을 가능성도 큼
- 위와 같은 요소들을 종합했을 때, 기술 발전 예측에는 어려움이 따르지만 수직적 AI 스타트업에는 시간이 많지 않을 것으로 전망
- AI 모델이 고도화됨에 따라 기존 엔지니어링 기반의 가치가 빠르게 소멸될 수 있다는 U자형 가치 그래프가 제시됨

### 참고 사항

- o3에서 보여준 시험 시점 연산(Test-time compute) 확장은, 이미 기존 연구를 통해 예견되었던 결과라는 설명
- AlphaZero 사례에서 검증된 것처럼, 검증 가능한 환경에선 성능이 빠르게 초인적인 수준에 도달할 수 있다는 통찰
- o3가 코딩·수학 같은 영역에서는 뛰어나지만, 창의적 글쓰기 등 다른 영역에서는 o1과 큰 차이가 없다는 분석
- 향후 수직적 AI를 새로 개발하기보다는, 더 광범위하거나 독점적인 자원을 다루는 다른 방향성이 창업자들에게 더 유리할 수 있다는 시사점

---

## [챕터 4: 당신은 마법사입니다(You’re a wizard Harry)](https://lukaspetersson.com/blog/2025/wizard-vertical/)

### 창업자는 마법사와 같음

- 무에서 유를 창조하는 능력을 지님
- 새로운 회사를 시작하려면 참신한 사고가 필요함
- 폴 그레이엄(PG)의 말: "아이디어는 정확할 뿐만 아니라 참신해야 한다. 모두가 좋은 생각이라고 동의하는 일을 시작해서는 안 된다."
- 많은 창업자들이 동료들의 인상적인 수익 성장에 눈이 멀어 독립적인 사고를 잃고 있음
- 모두가 같은 일을 하고 그것이 효과가 있는 것처럼 보일 때, 독립적으로 생각하기 어려움
- 필자는 독립적으로 생각하려 노력하며, 이러한 아이디어들이 나쁘게 들리길 바람

### 수평적 에이전트의 미래와 경쟁

- AI 애플리케이션 계층을 지배할 수평적 에이전트는 AI 연구소에서 개발될 것으로 예상됨
- 모델 성능이 달라져 단일 승자가 나올 수도 있지만, Anthropic, OpenAI, GDM, xAI 간의 치열한 경쟁이 더 가능성이 높음
- 이는 단기적으로 최종 사용자에게 이익이 되는 가격 경쟁을 야기함
- AI 연구소가 단기적으로는 많은 금전적 가치를 포착하지 못하더라도, 여전히 매우 강력한 위치를 차지할 것으로 예상됨
- 따라서 창업자들은 자신의 스타트업을 이러한 연구소와의 관계 맥락에서 생각하는 것이 합리적임

### 고객으로서의 접근

- 챕터 2에서 논의한 바와 같이, LLM API를 사용하는 AI 수직 제품을 구축하는 것은 가능하지만, 이는 중요한 자원에 대한 독점적 접근이 있을 때만 가능함
- AI 수직 제품을 구축하려면, 그러한 자원을 찾는 데 엄청난 노력을 기울여야 함

### 경쟁자로서의 접근

- 수평적 에이전트가 미래라면, 왜 그것을 구축하지 않는가? 세 가지 접근 방식을 검토함
- **시장 선점**
  - AI 연구소는 모델이 충분히 신뢰할 수 있어 최소한의 엔지니어링 노력으로 수평적 에이전트를 만들 수 있을 때만 수직적 워크플로우와 진지하게 경쟁할 것임
  - 이전 모델에 엔지니어링 노력을 적용하여 이론적으로 연구소보다 먼저 시장에 진입할 수 있지만, 이는 확실하지 않음
  - Leopold Aschenbrenner는 이 노력이 다음 모델을 구축하는 것보다 더 오래 걸릴 수 있다고 생각함: "원격 근로자가 많은 작업을 자동화할 수 있을 때까지 시간이 걸릴 수 있으며, 그 동안 중간 모델은 아직 완전히 활용되고 통합되지 않을 수 있음"
  - 누가 먼저 시장에 진입하든, 이 우위는 오래 지속되지 않을 것으로 예상됨
- **에이전트 API 래퍼**
  - 룸메이트가 "세상에 UI 기술을 가진 사람이 없나요?"라고 물었음
  - 이는 두 가지 문제를 시사함: 1) API 비용으로 인해 마진이 지속 불가능함, 2) 연구소는 최고의 모델을 공개하지 않음 (ChatGPT는 검색, 웹 브라우징 등에 독점 모델을 사용함)
  - 현재 GPT API를 사용하여 ChatGPT와 직접 경쟁하는 사람은 없으며, 이 패턴이 수평적 에이전트에서도 반복될 것으로 예상됨
- **오픈 소스 모델**
  - 오픈 소스 모델은 또 다른 경로를 제공할 수 있음
  - Perplexity는 연구소와 수평적 제품에서 경쟁할 수 있음을 보여줌
  - 그러나 오픈 소스 모델은 단순한 벤치마크에서는 잘 수행되지만, 복잡한 에이전트 작업에서는 어려움을 겪음
  - Llama-3.1-405b는 MLE-bench에서 최첨단 모델보다 상당히 뒤처짐
  - Andon Labs에서 이러한 유형의 벤치마크를 전문으로 하며, 이는 우리가 보는 것과 일치함
  - Deepseek V3와 R1이 매우 인상적인 결과로 출시되었지만, o3도 마찬가지이며, Anthropic은 내부적으로 더 나은 버전을 가지고 있는 것으로 알려짐
  - 오픈 소스 모델이 최첨단에 가까워질 수는 있지만, 이를 능가할 것으로는 의심스러움
  - 그러나 수평적 게임에서 경쟁하기에 충분할 수 있음
  - 추론 비용은 여전히 매우 높을 것임

### 공급업체로서의 접근

- AI 연구소가 정말로 이렇게 강력해진다면, 그들에게 공급업체가 되는 것은 훌륭한 위치임
- 그들은 분명히 많은 컴퓨팅 파워와 전력이 필요할 것임
- Leo의 분석이 맞다면, 예상보다 더 많이 필요할 수 있음
- 이 기회는 산업 전문 지식을 필요로 하며, 이는 현재 AI 애플리케이션 계층에 있는 창업자들에게는 자연스럽지 않을 수 있음
- 그러나 당신이 마법사라는 것을 기억하라
- 연구소는 또한 제3자로부터 데이터를 구매함
- Scale AI는 이것이 훌륭한 비즈니스임을 증명하고 있음
- 그러나 AI 연구소가 "자기 학습"을 작동시킬 수 있을지는 의문임
- AlphaZero는 외부 데이터 없이 훈련되었으며, 이는 미래 AI 모델의 성배로 여겨짐
- 그들이 자기 학습을 작동시키지 못한다면, 대안은 여러 후속 훈련 데이터셋을 결합하는 것일 것임
- 이 세계에서는 데이터를 판매하는 것이 아마도 좋은 선택일 것임

### 생태계 기여자로서의 접근

- AI 연구소와의 관계에서 마지막으로 검토할 만한 것은 생태계 기여자가 되는 것임
- 이는 수평적 에이전트를 돕는 도구를 구축하는 것을 의미하지만, 중요한 것은 에이전트 자체와 분리되어야 함
- 챕터 3에서 보여주었듯이, 에이전트는 효율적인 인터페이스가 필요하기 때문에 전통적인 소프트웨어는 지속될 것임
- 에이전트가 자체 소프트웨어를 작성할 수 있지만, 추론 비용이 이를 비실용적으로 만들 수 있음
- 그러나 생태계 플레이어는 상품화될 위험이 있으며, 대부분의 가치는 다른 곳에서 포착될 수 있음
- 이는 수평적 에이전트를 실행하는 데 드는 **추론 비용(inference cost)** 이 얼마나 높은지에 따라 달라질 것임
  - 추론 비용이 낮다면, 에이전트가 스스로 필요한 소프트웨어를 생성하는 것이 더 일반적일 것임

### 만약 AI 수평적 에이전트가 늦게 도래한다면?

- **시간표(timeline)** 는 매우 중요함
  - 만약 수평적 에이전트가 **10년 뒤에야 경쟁력을 갖춘다면**, 지금 수직적 AI 워크플로우를 구축하는 것은 훌륭한 아이디어가 될 것임
  - 이 정도 시간이면 충분히 **크고 견고한 회사를 만들 수 있음**
- 그러나 AI 연구소의 발전 속도를 고려하면 **10년은 비현실적**
  - 그렇다면 **4년 후는 어떨까?**
  - 4년은 대기업을 만들기에는 부족할 수도 있지만, 충분한 반복(iteration) 기회를 제공함
  - **AI 애플리케이션 계층에서 시작하는 것이 이후 벤더나 생태계 플레이어로 전환하는 데 유리할 수도 있음**

### 에필로그: YC(Y Combinator)의 실수인가?

- 겉으로 보기엔 **YC가 잘못된 선택을 하는 것처럼 보일 수도 있음**
  - 현재 YC는 **AI 수직적 제품**에 대부분의 투자를 집중하고 있음
  - 하지만 **이 시장이 곧 사라질 가능성이 큼**
- 그러나 필자는 **VC(벤처 캐피털)에 대한 전문성이 부족**하므로 확실한 결론을 내릴 수 없음
  - 그저 **혼란스러워하며 고민을 공유하는 것일 뿐**
- YC는 **비교적 중립적인 투자 전략**을 취한다고 주장함
  - **똑똑한 사람들에게 투자하고, 그들이 최선의 아이디어를 찾길 바람**
  - 이는 훌륭한 전략이며, **수백 명의 창업자가 14명의 YC 파트너보다 미래를 더 잘 예측할 수도 있음**
- 그러나 필자는 **YC의 배치(batch) 시스템이 단기적 사고를 유도할 가능성이 있다고 우려함**
  - YC에서는 **주간 목표를 설정**하는 것이 매우 중요하며, **큰 그룹 내에서 진행되는 것이 동기부여에 좋음**
  - 하지만 **아이디어의 다양성이 충분하지 않으면, 단기적 사고를 유도할 수도 있음**
  - **AI 수직적 제품을 만들면 빠르게 5,000달러 MRR을 달성할 수 있음**
  - 그러나 **이것이 지속 가능한 비즈니스를 구축하는 방법일까?**
  - 필자가 지금 YC 배치에 있었다면, 아마도 **AI 수직적 제품을 만들고 싶은 유혹을 느꼈을 것**
  - 게다가 YC의 팟캐스트 **"The Light Cone"** 에서는 AI 수직적 제품을 옹호하는 내용이 많음
